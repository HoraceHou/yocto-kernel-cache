From 2e6d1149ec13ccbda8e7f638483d43bf83967956 Mon Sep 17 00:00:00 2001
From: Franck LENORMAND <franck.lenormand@nxp.com>
Date: Fri, 14 Sep 2018 10:59:52 +0200
Subject: [PATCH 4724/5242] MLK-19365: crypto: ccm: Cache aligned auth_data

commit  eede5a6e6e2699b4e73c2d87083070b8fe6324c3 from
https://source.codeaurora.org/external/imx/linux-imx.git

Generic GCM is likely to end up using a hardware accelerator to do
part of the job. Allocating hash, iv and result in a contiguous memory
area increases the risk of dma mapping multiple ranges on the same
cacheline. Also having dma and cpu written data on the same cacheline
will cause coherence issues.

Signed-off-by: Franck LENORMAND <franck.lenormand@nxp.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 crypto/ccm.c |   13 ++++++++++++-
 1 file changed, 12 insertions(+), 1 deletion(-)

diff --git a/crypto/ccm.c b/crypto/ccm.c
index 0a08334..aca9495 100644
--- a/crypto/ccm.c
+++ b/crypto/ccm.c
@@ -46,7 +46,18 @@ struct crypto_rfc4309_req_ctx {
 struct crypto_ccm_req_priv_ctx {
 	u8 odata[16];
 	u8 idata[16];
-	u8 auth_tag[16];
+
+	/*
+	 * We need to force auth_tag to be on its own cacheline.
+	 *
+	 * We put it on its cacheline with the macro ____cacheline_aligned.
+	 * The next fields must be on another cacheline so we add a dummy field
+	 * which is located on another cacheline to enforce that.
+	 */
+	u8 auth_tag[16] ____cacheline_aligned;
+
+	u8 dummy_align_auth_tag ____cacheline_aligned;
+
 	u32 flags;
 	struct scatterlist src[3];
 	struct scatterlist dst[3];
-- 
1.7.9.5

