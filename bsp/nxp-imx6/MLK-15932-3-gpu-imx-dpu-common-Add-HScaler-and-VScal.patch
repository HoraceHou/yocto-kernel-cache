From 469a3ed73f80d3be123eddd84ef6a3162a6e9a00 Mon Sep 17 00:00:00 2001
From: Liu Ying <victor.liu@nxp.com>
Date: Mon, 10 Jul 2017 11:23:32 +0800
Subject: [PATCH 2099/5242] MLK-15932-3 gpu: imx: dpu: common: Add HScaler and
 VScaler support

commit  053d65f5126344a8ddbf9525ac6ddcb07222e23a from
https://source.codeaurora.org/external/imx/linux-imx.git

This patch adds basic HScaler and VScaler support in the DPU core driver.
The two scaler units can be used in the display controller, blit engine
or capture controller.  Currently, we only support the display controller.

Signed-off-by: Liu Ying <victor.liu@nxp.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/gpu/imx/dpu/Makefile      |    3 +-
 drivers/gpu/imx/dpu/dpu-common.c  |   56 ++++-
 drivers/gpu/imx/dpu/dpu-hscaler.c |  374 +++++++++++++++++++++++++++++++++
 drivers/gpu/imx/dpu/dpu-prv.h     |    8 +
 drivers/gpu/imx/dpu/dpu-vscaler.c |  417 +++++++++++++++++++++++++++++++++++++
 include/video/dpu.h               |  103 +++++++++
 6 files changed, 958 insertions(+), 3 deletions(-)
 create mode 100644 drivers/gpu/imx/dpu/dpu-hscaler.c
 create mode 100644 drivers/gpu/imx/dpu/dpu-vscaler.c

diff --git a/drivers/gpu/imx/dpu/Makefile b/drivers/gpu/imx/dpu/Makefile
index df07880..364e764 100644
--- a/drivers/gpu/imx/dpu/Makefile
+++ b/drivers/gpu/imx/dpu/Makefile
@@ -2,4 +2,5 @@ obj-$(CONFIG_IMX_DPU_CORE) += imx-dpu-core.o
 
 imx-dpu-core-objs := dpu-common.o dpu-constframe.o dpu-disengcfg.o \
 		     dpu-extdst.o dpu-fetchdecode.o dpu-framegen.o \
-		     dpu-fetchlayer.o dpu-layerblend.o dpu-tcon.o
+		     dpu-fetchlayer.o dpu-hscaler.o dpu-layerblend.o \
+		     dpu-tcon.o dpu-vscaler.o
diff --git a/drivers/gpu/imx/dpu/dpu-common.c b/drivers/gpu/imx/dpu/dpu-common.c
index 0f47ff9..68af5ae 100644
--- a/drivers/gpu/imx/dpu/dpu-common.c
+++ b/drivers/gpu/imx/dpu/dpu-common.c
@@ -167,6 +167,12 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 static const unsigned long fl_pec_ofss_v1[] = {0xba0, 0xbb0};
 static const unsigned long fl_pec_ofss_v2[] = {0xac0};
 
+/* Horizontal Scaler Unit */
+static const unsigned long hs_ofss_v1[] = {0xbc00, 0xd000, 0x3000};
+static const unsigned long hs_ofss_v2[] = {0x9000, 0x9c00, 0x3000};
+static const unsigned long hs_pec_ofss_v1[] = {0xc00, 0xca0, 0x8e0};
+static const unsigned long hs_pec_ofss_v2[] = {0xb00, 0xb60, 0x8c0};
+
 /* Layer Blend Unit */
 static const unsigned long lb_ofss_v1[] = {0xdc00, 0xe000, 0xe400, 0xe800,
 					   0xec00, 0xf000, 0xf400};
@@ -179,6 +185,12 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 static const unsigned long tcon_ofss_v1[] = {0x12000, 0x13c00};
 static const unsigned long tcon_ofss_v2[] = {0xcc00, 0xe800};
 
+/* Vertical Scaler Unit */
+static const unsigned long vs_ofss_v1[] = {0xc000, 0xd400, 0x3400};
+static const unsigned long vs_ofss_v2[] = {0x9400, 0xa000, 0x3400};
+static const unsigned long vs_pec_ofss_v1[] = {0xc20, 0xcc0, 0x900};
+static const unsigned long vs_pec_ofss_v2[] = {0xb20, 0xb80, 0x8e0};
+
 static const struct dpu_unit cfs_v1 = {
 	.name = "ConstFrame",
 	.num = ARRAY_SIZE(cf_ids),
@@ -275,6 +287,22 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 	.ofss = fl_ofss_v2,
 };
 
+static const struct dpu_unit hss_v1 = {
+	.name = "HScaler",
+	.num = ARRAY_SIZE(hs_ids),
+	.ids = hs_ids,
+	.pec_ofss = hs_pec_ofss_v1,
+	.ofss = hs_ofss_v1,
+};
+
+static const struct dpu_unit hss_v2 = {
+	.name = "HScaler",
+	.num = ARRAY_SIZE(hs_ids),
+	.ids = hs_ids,
+	.pec_ofss = hs_pec_ofss_v2,
+	.ofss = hs_ofss_v2,
+};
+
 static const struct dpu_unit lbs_v1 = {
 	.name = "LayerBlend",
 	.num = ARRAY_SIZE(lb_ids),
@@ -307,6 +335,22 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 	.ofss = tcon_ofss_v2,
 };
 
+static const struct dpu_unit vss_v1 = {
+	.name = "VScaler",
+	.num = ARRAY_SIZE(vs_ids),
+	.ids = vs_ids,
+	.pec_ofss = vs_pec_ofss_v1,
+	.ofss = vs_ofss_v1,
+};
+
+static const struct dpu_unit vss_v2 = {
+	.name = "VScaler",
+	.num = ARRAY_SIZE(vs_ids),
+	.ids = vs_ids,
+	.pec_ofss = vs_pec_ofss_v2,
+	.ofss = vs_ofss_v2,
+};
+
 static const struct cm_reg_ofs cm_reg_ofs_v1 = {
 	.ipidentifier = 0,
 	.lockunlock = 0x80,
@@ -404,9 +448,9 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 /* FIXME: overkill for some N/As, revive them when needed */
 static const unsigned int sw2hw_block_id_map_v2[] = {
 	/*   0     1     2     3     4     5     6     7 */
-	  0x00,   NA,   NA,   NA,   NA,   NA,   NA,   NA,
+	  0x00,   NA,   NA,   NA,   NA,   NA,   NA, 0x07,
 	/*   8     9    10    11    12    13    14    15 */
-	    NA,   NA, 0x0a,   NA, 0x0c,   NA, 0x0e,   NA,
+	  0x08,   NA, 0x0a,   NA, 0x0c,   NA, 0x0e,   NA,
 	/*  16    17    18    19    20    21    22    23 */
 	  0x10,   NA, 0x12,   NA,   NA,   NA,   NA,   NA,
 	/*  24    25    26    27    28    29    30    31 */
@@ -431,8 +475,10 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 	.fds = &fds_v1,
 	.fgs = &fgs_v1,
 	.fls = &fls_v1,
+	.hss = &hss_v1,
 	.lbs = &lbs_v1,
 	.tcons = &tcons_v1,
+	.vss = &vss_v1,
 	.cm_reg_ofs = &cm_reg_ofs_v1,
 	.intsteer_map = intsteer_map_v1,
 	.intsteer_map_size = ARRAY_SIZE(intsteer_map_v1),
@@ -451,8 +497,10 @@ static inline void dpu_cm_write(struct dpu_soc *dpu, u32 value,
 	.fds = &fds_v2,
 	.fgs = &fgs_v2,
 	.fls = &fls_v2,
+	.hss = &hss_v2,
 	.lbs = &lbs_v2,
 	.tcons = &tcons_v2,
+	.vss = &vss_v2,
 	.cm_reg_ofs = &cm_reg_ofs_v2,
 	.intsteer_map = intsteer_map_v2,
 	.intsteer_map_size = ARRAY_SIZE(intsteer_map_v2),
@@ -512,8 +560,10 @@ static int dpu_submodules_init(struct dpu_soc *dpu,
 	DPU_UNITS_INIT(fd);
 	DPU_UNITS_INIT(fg);
 	DPU_UNITS_INIT(fl);
+	DPU_UNITS_INIT(hs);
 	DPU_UNITS_INIT(lb);
 	DPU_UNITS_INIT(tcon);
+	DPU_UNITS_INIT(vs);
 
 	return 0;
 }
@@ -1227,8 +1277,10 @@ static int dpu_probe(struct platform_device *pdev)
 	DPU_UNITS_ADDR_DBG(fd);
 	DPU_UNITS_ADDR_DBG(fg);
 	DPU_UNITS_ADDR_DBG(fl);
+	DPU_UNITS_ADDR_DBG(hs);
 	DPU_UNITS_ADDR_DBG(lb);
 	DPU_UNITS_ADDR_DBG(tcon);
+	DPU_UNITS_ADDR_DBG(vs);
 
 	dpu->cm_reg = devm_ioremap(dpu->dev, dpu_base + devtype->cm_ofs, SZ_1K);
 	if (!dpu->cm_reg)
diff --git a/drivers/gpu/imx/dpu/dpu-hscaler.c b/drivers/gpu/imx/dpu/dpu-hscaler.c
new file mode 100644
index 0000000..1ce92d6
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-hscaler.c
@@ -0,0 +1,374 @@
+/*
+ * Copyright 2017 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_DYNAMIC		0x8
+#define PIXENGCFG_DYNAMIC_SRC_SEL_MASK	0x3F
+
+#define SETUP1				0xC
+#define SCALE_FACTOR_MASK		0xFFFFF
+#define SCALE_FACTOR(n)			((n) & 0xFFFFF)
+#define SETUP2				0x10
+#define PHASE_OFFSET_MASK		0x1FFFFF
+#define PHASE_OFFSET(n)			((n) & 0x1FFFFF)
+#define CONTROL				0x14
+#define OUTPUT_SIZE_MASK		0x3FFF0000
+#define OUTPUT_SIZE(n)			((((n) - 1) << 16) & OUTPUT_SIZE_MASK)
+#define FILTER_MODE			0x100
+#define SCALE_MODE			0x10
+#define MODE				0x1
+
+static const hs_src_sel_t src_sels[3][6] = {
+	{
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__EXTSRC4,
+		HS_SRC_SEL__FETCHDECODE0,
+		HS_SRC_SEL__FETCHDECODE2,
+		HS_SRC_SEL__MATRIX4,
+		HS_SRC_SEL__VSCALER4,
+	}, {
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__EXTSRC5,
+		HS_SRC_SEL__FETCHDECODE1,
+		HS_SRC_SEL__FETCHDECODE3,
+		HS_SRC_SEL__MATRIX5,
+		HS_SRC_SEL__VSCALER5,
+	}, {
+		HS_SRC_SEL__DISABLE,
+		HS_SRC_SEL__MATRIX9,
+		HS_SRC_SEL__VSCALER9,
+		HS_SRC_SEL__FILTER9,
+	},
+};
+
+struct dpu_hscaler {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+	/* see DPU_PLANE_SRC_xxx */
+	unsigned int stream_id;
+};
+
+static inline u32 dpu_pec_hs_read(struct dpu_hscaler *hs,
+				  unsigned int offset)
+{
+	return readl(hs->pec_base + offset);
+}
+
+static inline void dpu_pec_hs_write(struct dpu_hscaler *hs, u32 value,
+				    unsigned int offset)
+{
+	writel(value, hs->pec_base + offset);
+}
+
+static inline u32 dpu_hs_read(struct dpu_hscaler *hs, unsigned int offset)
+{
+	return readl(hs->base + offset);
+}
+
+static inline void dpu_hs_write(struct dpu_hscaler *hs, u32 value,
+				unsigned int offset)
+{
+	writel(value, hs->base + offset);
+}
+
+int hscaler_pixengcfg_dynamic_src_sel(struct dpu_hscaler *hs, hs_src_sel_t src)
+{
+	struct dpu_soc *dpu = hs->dpu;
+	const unsigned int *block_id_map = dpu->devtype->sw2hw_block_id_map;
+	const unsigned int hs_id_array[] = {4, 5, 9};
+	int i, j;
+	u32 val, mapped_src;
+
+	for (i = 0; i < ARRAY_SIZE(hs_id_array); i++)
+		if (hs_id_array[i] == hs->id)
+			break;
+
+	if (WARN_ON(i == (ARRAY_SIZE(hs_id_array) + 1)))
+		return -EINVAL;
+
+	mutex_lock(&hs->mutex);
+	for (j = 0; j < ARRAY_SIZE(src_sels[0]); j++) {
+		if (src_sels[i][j] == src) {
+			mapped_src = block_id_map ? block_id_map[src] : src;
+			if (WARN_ON(mapped_src == NA))
+				return -EINVAL;
+
+			val = dpu_pec_hs_read(hs, PIXENGCFG_DYNAMIC);
+			val &= ~PIXENGCFG_DYNAMIC_SRC_SEL_MASK;
+			val |= mapped_src;
+			dpu_pec_hs_write(hs, val, PIXENGCFG_DYNAMIC);
+			mutex_unlock(&hs->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&hs->mutex);
+
+	dev_err(dpu->dev, "Invalid source for HScaler%d\n", hs->id);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(hscaler_pixengcfg_dynamic_src_sel);
+
+void hscaler_pixengcfg_clken(struct dpu_hscaler *hs, pixengcfg_clken_t clken)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_pec_hs_read(hs, PIXENGCFG_DYNAMIC);
+	val &= ~CLKEN_MASK;
+	val |= clken << CLKEN_MASK_SHIFT;
+	dpu_pec_hs_write(hs, val, PIXENGCFG_DYNAMIC);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_pixengcfg_clken);
+
+void hscaler_shden(struct dpu_hscaler *hs, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_hs_write(hs, val, STATICCONTROL);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_shden);
+
+void hscaler_setup1(struct dpu_hscaler *hs, u32 src, u32 dst)
+{
+	struct dpu_soc *dpu = hs->dpu;
+	u32 scale_factor;
+	u64 tmp64;
+
+	if (src == dst) {
+		scale_factor = 0x80000;
+	} else {
+		if (src > dst) {
+			tmp64 = (u64)((u64)dst * 0x80000);
+			do_div(tmp64, src);
+
+		} else {
+			tmp64 = (u64)((u64)src * 0x80000);
+			do_div(tmp64, dst);
+		}
+		scale_factor = (u32)tmp64;
+	}
+
+	WARN_ON(scale_factor > 0x80000);
+
+	mutex_lock(&hs->mutex);
+	dpu_hs_write(hs, SCALE_FACTOR(scale_factor), SETUP1);
+	mutex_unlock(&hs->mutex);
+
+	dev_dbg(dpu->dev, "Hscaler%d scale factor 0x%08x\n",
+						hs->id, scale_factor);
+}
+EXPORT_SYMBOL_GPL(hscaler_setup1);
+
+void hscaler_setup2(struct dpu_hscaler *hs, u32 phase_offset)
+{
+	mutex_lock(&hs->mutex);
+	dpu_hs_write(hs, PHASE_OFFSET(phase_offset), SETUP2);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_setup2);
+
+void hscaler_output_size(struct dpu_hscaler *hs, u32 line_num)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~OUTPUT_SIZE_MASK;
+	val |= OUTPUT_SIZE(line_num);
+	dpu_hs_write(hs, val, CONTROL);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_output_size);
+
+void hscaler_filter_mode(struct dpu_hscaler *hs, scaler_filter_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~FILTER_MODE;
+	val |= m;
+	dpu_hs_write(hs, val, CONTROL);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_filter_mode);
+
+void hscaler_scale_mode(struct dpu_hscaler *hs, scaler_scale_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~SCALE_MODE;
+	val |= m;
+	dpu_hs_write(hs, val, CONTROL);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_scale_mode);
+
+void hscaler_mode(struct dpu_hscaler *hs, scaler_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	val &= ~MODE;
+	val |= m;
+	dpu_hs_write(hs, val, CONTROL);
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(hscaler_mode);
+
+bool hscaler_is_enabled(struct dpu_hscaler *hs)
+{
+	u32 val;
+
+	mutex_lock(&hs->mutex);
+	val = dpu_hs_read(hs, CONTROL);
+	mutex_unlock(&hs->mutex);
+
+	return (val & MODE) == SCALER_ACTIVE;
+}
+EXPORT_SYMBOL_GPL(hscaler_is_enabled);
+
+dpu_block_id_t hscaler_get_block_id(struct dpu_hscaler *hs)
+{
+	switch (hs->id) {
+	case 4:
+		return ID_HSCALER4;
+	case 5:
+		return ID_HSCALER5;
+	case 9:
+		return ID_HSCALER9;
+	default:
+		WARN_ON(1);
+	}
+
+	return ID_NONE;
+}
+EXPORT_SYMBOL_GPL(hscaler_get_block_id);
+
+unsigned int hscaler_get_stream_id(struct dpu_hscaler *hs)
+{
+	return hs->stream_id;
+}
+EXPORT_SYMBOL_GPL(hscaler_get_stream_id);
+
+void hscaler_set_stream_id(struct dpu_hscaler *hs, unsigned int id)
+{
+	switch (id) {
+	case DPU_PLANE_SRC_TO_DISP_STREAM0:
+	case DPU_PLANE_SRC_TO_DISP_STREAM1:
+	case DPU_PLANE_SRC_DISABLED:
+		hs->stream_id = id;
+		break;
+	default:
+		WARN_ON(1);
+	}
+}
+EXPORT_SYMBOL_GPL(hscaler_set_stream_id);
+
+struct dpu_hscaler *dpu_hs_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_hscaler *hs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(hs_ids); i++)
+		if (hs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(hs_ids))
+		return ERR_PTR(-EINVAL);
+
+	hs = dpu->hs_priv[i];
+
+	mutex_lock(&hs->mutex);
+
+	if (hs->inuse) {
+		hs = ERR_PTR(-EBUSY);
+		goto out;
+	}
+
+	hs->inuse = true;
+out:
+	mutex_unlock(&hs->mutex);
+
+	return hs;
+}
+EXPORT_SYMBOL_GPL(dpu_hs_get);
+
+void dpu_hs_put(struct dpu_hscaler *hs)
+{
+	mutex_lock(&hs->mutex);
+
+	hs->inuse = false;
+
+	mutex_unlock(&hs->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_hs_put);
+
+int dpu_hs_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_hscaler *hs;
+	int i;
+
+	hs = devm_kzalloc(dpu->dev, sizeof(*hs), GFP_KERNEL);
+	if (!hs)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(hs_ids); i++)
+		if (hs_ids[i] == id)
+			break;
+
+	dpu->hs_priv[i] = hs;
+
+	hs->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_8);
+	if (!hs->pec_base)
+		return -ENOMEM;
+
+	hs->base = devm_ioremap(dpu->dev, base, SZ_1K);
+	if (!hs->base)
+		return -ENOMEM;
+
+	hs->dpu = dpu;
+	hs->id = id;
+
+	mutex_init(&hs->mutex);
+
+	hscaler_shden(hs, true);
+	hscaler_setup2(hs, 0);
+
+	return 0;
+}
diff --git a/drivers/gpu/imx/dpu/dpu-prv.h b/drivers/gpu/imx/dpu/dpu-prv.h
index 957a010..4f2f3c2 100644
--- a/drivers/gpu/imx/dpu/dpu-prv.h
+++ b/drivers/gpu/imx/dpu/dpu-prv.h
@@ -125,8 +125,10 @@ struct dpu_devtype {
 	const struct dpu_unit *fds;
 	const struct dpu_unit *fgs;
 	const struct dpu_unit *fls;
+	const struct dpu_unit *hss;
 	const struct dpu_unit *lbs;
 	const struct dpu_unit *tcons;
+	const struct dpu_unit *vss;
 	const struct cm_reg_ofs *cm_reg_ofs;
 	const unsigned int *intsteer_map;
 	const unsigned int intsteer_map_size;
@@ -166,8 +168,10 @@ struct dpu_soc {
 	struct dpu_fetchdecode	*fd_priv[4];
 	struct dpu_fetchlayer	*fl_priv[2];
 	struct dpu_framegen	*fg_priv[2];
+	struct dpu_hscaler	*hs_priv[3];
 	struct dpu_layerblend	*lb_priv[7];
 	struct dpu_tcon		*tcon_priv[2];
+	struct dpu_vscaler	*vs_priv[3];
 };
 
 #define DECLARE_DPU_UNIT_INIT_FUNC(block)			\
@@ -180,8 +184,10 @@ struct dpu_soc {
 DECLARE_DPU_UNIT_INIT_FUNC(fd);
 DECLARE_DPU_UNIT_INIT_FUNC(fg);
 DECLARE_DPU_UNIT_INIT_FUNC(fl);
+DECLARE_DPU_UNIT_INIT_FUNC(hs);
 DECLARE_DPU_UNIT_INIT_FUNC(lb);
 DECLARE_DPU_UNIT_INIT_FUNC(tcon);
+DECLARE_DPU_UNIT_INIT_FUNC(vs);
 
 static const unsigned int cf_ids[] = {0, 1, 4, 5};
 static const unsigned int dec_ids[] = {0, 1};
@@ -189,8 +195,10 @@ struct dpu_soc {
 static const unsigned int fd_ids[] = {0, 1, 2, 3};
 static const unsigned int fg_ids[] = {0, 1};
 static const unsigned int fl_ids[] = {0, 1};
+static const unsigned int hs_ids[] = {4, 5, 9};
 static const unsigned int lb_ids[] = {0, 1, 2, 3, 4, 5, 6};
 static const unsigned int tcon_ids[] = {0, 1};
+static const unsigned int vs_ids[] = {4, 5, 9};
 
 struct dpu_pixel_format {
 	u32 pixel_format;
diff --git a/drivers/gpu/imx/dpu/dpu-vscaler.c b/drivers/gpu/imx/dpu/dpu-vscaler.c
new file mode 100644
index 0000000..b31ad87
--- /dev/null
+++ b/drivers/gpu/imx/dpu/dpu-vscaler.c
@@ -0,0 +1,417 @@
+/*
+ * Copyright 2017 NXP
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <video/dpu.h>
+#include "dpu-prv.h"
+
+#define PIXENGCFG_DYNAMIC		0x8
+#define PIXENGCFG_DYNAMIC_SRC_SEL_MASK	0x3F
+
+#define SETUP1				0xC
+#define SCALE_FACTOR_MASK		0xFFFFF
+#define SCALE_FACTOR(n)			((n) & 0xFFFFF)
+#define SETUP2				0x10
+#define SETUP3				0x14
+#define SETUP4				0x18
+#define SETUP5				0x1C
+#define PHASE_OFFSET_MASK		0x1FFFFF
+#define PHASE_OFFSET(n)			((n) & 0x1FFFFF)
+#define CONTROL				0x20
+#define OUTPUT_SIZE_MASK		0x3FFF0000
+#define OUTPUT_SIZE(n)			((((n) - 1) << 16) & OUTPUT_SIZE_MASK)
+#define FIELD_MODE			0x3000
+#define FILTER_MODE			0x100
+#define SCALE_MODE			0x10
+#define MODE				0x1
+
+static const vs_src_sel_t src_sels[3][6] = {
+	{
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__EXTSRC4,
+		VS_SRC_SEL__FETCHDECODE0,
+		VS_SRC_SEL__FETCHDECODE2,
+		VS_SRC_SEL__MATRIX4,
+		VS_SRC_SEL__HSCALER4,
+	}, {
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__EXTSRC5,
+		VS_SRC_SEL__FETCHDECODE1,
+		VS_SRC_SEL__FETCHDECODE3,
+		VS_SRC_SEL__MATRIX5,
+		VS_SRC_SEL__HSCALER5,
+	}, {
+		VS_SRC_SEL__DISABLE,
+		VS_SRC_SEL__MATRIX9,
+		VS_SRC_SEL__HSCALER9,
+	},
+};
+
+struct dpu_vscaler {
+	void __iomem *pec_base;
+	void __iomem *base;
+	struct mutex mutex;
+	int id;
+	bool inuse;
+	struct dpu_soc *dpu;
+	/* see DPU_PLANE_SRC_xxx */
+	unsigned int stream_id;
+};
+
+static inline u32 dpu_pec_vs_read(struct dpu_vscaler *vs,
+				  unsigned int offset)
+{
+	return readl(vs->pec_base + offset);
+}
+
+static inline void dpu_pec_vs_write(struct dpu_vscaler *vs, u32 value,
+				    unsigned int offset)
+{
+	writel(value, vs->pec_base + offset);
+}
+
+static inline u32 dpu_vs_read(struct dpu_vscaler *vs, unsigned int offset)
+{
+	return readl(vs->base + offset);
+}
+
+static inline void dpu_vs_write(struct dpu_vscaler *vs, u32 value,
+				unsigned int offset)
+{
+	writel(value, vs->base + offset);
+}
+
+int vscaler_pixengcfg_dynamic_src_sel(struct dpu_vscaler *vs, vs_src_sel_t src)
+{
+	struct dpu_soc *dpu = vs->dpu;
+	const unsigned int *block_id_map = dpu->devtype->sw2hw_block_id_map;
+	const unsigned int vs_id_array[] = {4, 5, 9};
+	int i, j;
+	u32 val, mapped_src;
+
+	for (i = 0; i < ARRAY_SIZE(vs_id_array); i++)
+		if (vs_id_array[i] == vs->id)
+			break;
+
+	if (WARN_ON(i == (ARRAY_SIZE(vs_id_array) + 1)))
+		return -EINVAL;
+
+	mutex_lock(&vs->mutex);
+	for (j = 0; j < ARRAY_SIZE(src_sels[0]); j++) {
+		if (src_sels[i][j] == src) {
+			mapped_src = block_id_map ? block_id_map[src] : src;
+			if (WARN_ON(mapped_src == NA))
+				return -EINVAL;
+
+			val = dpu_pec_vs_read(vs, PIXENGCFG_DYNAMIC);
+			val &= ~PIXENGCFG_DYNAMIC_SRC_SEL_MASK;
+			val |= mapped_src;
+			dpu_pec_vs_write(vs, val, PIXENGCFG_DYNAMIC);
+			mutex_unlock(&vs->mutex);
+			return 0;
+		}
+	}
+	mutex_unlock(&vs->mutex);
+
+	dev_err(dpu->dev, "Invalid source for VScaler%d\n", vs->id);
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(vscaler_pixengcfg_dynamic_src_sel);
+
+void vscaler_pixengcfg_clken(struct dpu_vscaler *vs, pixengcfg_clken_t clken)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_pec_vs_read(vs, PIXENGCFG_DYNAMIC);
+	val &= ~CLKEN_MASK;
+	val |= clken << CLKEN_MASK_SHIFT;
+	dpu_pec_vs_write(vs, val, PIXENGCFG_DYNAMIC);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_pixengcfg_clken);
+
+void vscaler_shden(struct dpu_vscaler *vs, bool enable)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, STATICCONTROL);
+	if (enable)
+		val |= SHDEN;
+	else
+		val &= ~SHDEN;
+	dpu_vs_write(vs, val, STATICCONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_shden);
+
+void vscaler_setup1(struct dpu_vscaler *vs, u32 src, u32 dst)
+{
+	struct dpu_soc *dpu = vs->dpu;
+	u32 scale_factor;
+	u64 tmp64;
+
+	if (src == dst) {
+		scale_factor = 0x80000;
+	} else {
+		if (src > dst) {
+			tmp64 = (u64)((u64)dst * 0x80000);
+			do_div(tmp64, src);
+
+		} else {
+			tmp64 = (u64)((u64)src * 0x80000);
+			do_div(tmp64, dst);
+		}
+		scale_factor = (u32)tmp64;
+	}
+
+	WARN_ON(scale_factor > 0x80000);
+
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, SCALE_FACTOR(scale_factor), SETUP1);
+	mutex_unlock(&vs->mutex);
+
+	dev_dbg(dpu->dev, "Vscaler%d scale factor 0x%08x\n",
+						vs->id, scale_factor);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup1);
+
+void vscaler_setup2(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, PHASE_OFFSET(phase_offset), SETUP2);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup2);
+
+void vscaler_setup3(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, PHASE_OFFSET(phase_offset), SETUP3);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup3);
+
+void vscaler_setup4(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, PHASE_OFFSET(phase_offset), SETUP4);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup4);
+
+void vscaler_setup5(struct dpu_vscaler *vs, u32 phase_offset)
+{
+	mutex_lock(&vs->mutex);
+	dpu_vs_write(vs, PHASE_OFFSET(phase_offset), SETUP5);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_setup5);
+
+void vscaler_output_size(struct dpu_vscaler *vs, u32 line_num)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~OUTPUT_SIZE_MASK;
+	val |= OUTPUT_SIZE(line_num);
+	dpu_vs_write(vs, val, CONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_output_size);
+
+void vscaler_field_mode(struct dpu_vscaler *vs, scaler_field_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~FIELD_MODE;
+	val |= m;
+	dpu_vs_write(vs, val, CONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_field_mode);
+
+void vscaler_filter_mode(struct dpu_vscaler *vs, scaler_filter_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~FILTER_MODE;
+	val |= m;
+	dpu_vs_write(vs, val, CONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_filter_mode);
+
+void vscaler_scale_mode(struct dpu_vscaler *vs, scaler_scale_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~SCALE_MODE;
+	val |= m;
+	dpu_vs_write(vs, val, CONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_scale_mode);
+
+void vscaler_mode(struct dpu_vscaler *vs, scaler_mode_t m)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	val &= ~MODE;
+	val |= m;
+	dpu_vs_write(vs, val, CONTROL);
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(vscaler_mode);
+
+bool vscaler_is_enabled(struct dpu_vscaler *vs)
+{
+	u32 val;
+
+	mutex_lock(&vs->mutex);
+	val = dpu_vs_read(vs, CONTROL);
+	mutex_unlock(&vs->mutex);
+
+	return (val & MODE) == SCALER_ACTIVE;
+}
+EXPORT_SYMBOL_GPL(vscaler_is_enabled);
+
+dpu_block_id_t vscaler_get_block_id(struct dpu_vscaler *vs)
+{
+	switch (vs->id) {
+	case 4:
+		return ID_VSCALER4;
+	case 5:
+		return ID_VSCALER5;
+	case 9:
+		return ID_VSCALER9;
+	default:
+		WARN_ON(1);
+	}
+
+	return ID_NONE;
+}
+EXPORT_SYMBOL_GPL(vscaler_get_block_id);
+
+unsigned int vscaler_get_stream_id(struct dpu_vscaler *vs)
+{
+	return vs->stream_id;
+}
+EXPORT_SYMBOL_GPL(vscaler_get_stream_id);
+
+void vscaler_set_stream_id(struct dpu_vscaler *vs, unsigned int id)
+{
+	switch (id) {
+	case DPU_PLANE_SRC_TO_DISP_STREAM0:
+	case DPU_PLANE_SRC_TO_DISP_STREAM1:
+	case DPU_PLANE_SRC_DISABLED:
+		vs->stream_id = id;
+		break;
+	default:
+		WARN_ON(1);
+	}
+}
+EXPORT_SYMBOL_GPL(vscaler_set_stream_id);
+
+struct dpu_vscaler *dpu_vs_get(struct dpu_soc *dpu, int id)
+{
+	struct dpu_vscaler *vs;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(vs_ids); i++)
+		if (vs_ids[i] == id)
+			break;
+
+	if (i == ARRAY_SIZE(vs_ids))
+		return ERR_PTR(-EINVAL);
+
+	vs = dpu->vs_priv[i];
+
+	mutex_lock(&vs->mutex);
+
+	if (vs->inuse) {
+		vs = ERR_PTR(-EBUSY);
+		goto out;
+	}
+
+	vs->inuse = true;
+out:
+	mutex_unlock(&vs->mutex);
+
+	return vs;
+}
+EXPORT_SYMBOL_GPL(dpu_vs_get);
+
+void dpu_vs_put(struct dpu_vscaler *vs)
+{
+	mutex_lock(&vs->mutex);
+
+	vs->inuse = false;
+
+	mutex_unlock(&vs->mutex);
+}
+EXPORT_SYMBOL_GPL(dpu_vs_put);
+
+int dpu_vs_init(struct dpu_soc *dpu, unsigned int id,
+		unsigned long pec_base, unsigned long base)
+{
+	struct dpu_vscaler *vs;
+	int i;
+
+	vs = devm_kzalloc(dpu->dev, sizeof(*vs), GFP_KERNEL);
+	if (!vs)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(vs_ids); i++)
+		if (vs_ids[i] == id)
+			break;
+
+	dpu->vs_priv[i] = vs;
+
+	vs->pec_base = devm_ioremap(dpu->dev, pec_base, SZ_8);
+	if (!vs->pec_base)
+		return -ENOMEM;
+
+	vs->base = devm_ioremap(dpu->dev, base, SZ_1K);
+	if (!vs->base)
+		return -ENOMEM;
+
+	vs->dpu = dpu;
+	vs->id = id;
+
+	mutex_init(&vs->mutex);
+
+	vscaler_shden(vs, true);
+	vscaler_setup2(vs, 0);
+	vscaler_setup3(vs, 0);
+	vscaler_setup4(vs, 0);
+	vscaler_setup5(vs, 0);
+
+	return 0;
+}
diff --git a/include/video/dpu.h b/include/video/dpu.h
index 2dd96d5..149eb15 100644
--- a/include/video/dpu.h
+++ b/include/video/dpu.h
@@ -286,6 +286,23 @@ enum dpu_irq {
 } fgdm_t;
 
 typedef enum {
+	HS_SRC_SEL__DISABLE		= ID_NONE,
+	HS_SRC_SEL__MATRIX9		= ID_MATRIX9,
+	HS_SRC_SEL__VSCALER9		= ID_VSCALER9,
+	HS_SRC_SEL__FILTER9		= ID_FILTER9,
+	HS_SRC_SEL__EXTSRC4		= ID_EXTSRC4,
+	HS_SRC_SEL__EXTSRC5		= ID_EXTSRC5,
+	HS_SRC_SEL__FETCHDECODE2	= ID_FETCHDECODE2,
+	HS_SRC_SEL__FETCHDECODE3	= ID_FETCHDECODE3,
+	HS_SRC_SEL__FETCHDECODE0	= ID_FETCHDECODE0,
+	HS_SRC_SEL__FETCHDECODE1	= ID_FETCHDECODE1,
+	HS_SRC_SEL__MATRIX4		= ID_MATRIX4,
+	HS_SRC_SEL__VSCALER4		= ID_VSCALER4,
+	HS_SRC_SEL__MATRIX5		= ID_MATRIX5,
+	HS_SRC_SEL__VSCALER5		= ID_VSCALER5,
+} hs_src_sel_t;
+
+typedef enum {
 	/* common options */
 	LB_PRIM_SEL__DISABLE		= ID_NONE,
 	LB_PRIM_SEL__BLITBLEND9		= ID_BLITBLEND9,
@@ -344,6 +361,52 @@ enum dpu_irq {
 	LB_BLEND,
 } lb_mode_t;
 
+typedef enum {
+	/* Constant 0 indicates frame or top field. */
+	SCALER_ALWAYS0 = 0x0,
+	/* Constant 1 indicates bottom field. */
+	SCALER_ALWAYS1 = 0x1 << 12,
+	/* Output field polarity is taken from input field polarity. */
+	SCALER_INPUT = 0x2 << 12,
+	/* Output field polarity toggles, starting with 0 after reset. */
+	SCALER_TOGGLE = 0x3 << 12,
+} scaler_field_mode_t;
+
+typedef enum {
+	/* pointer-sampling */
+	SCALER_NEAREST = 0x0,
+	/* box filter */
+	SCALER_LINEAR = 0x100,
+} scaler_filter_mode_t;
+
+typedef enum {
+	SCLAER_DOWNSCALE = 0x0,
+	SCLAER_UPSCALE = 0x10,
+} scaler_scale_mode_t;
+
+typedef enum {
+	/* Pixel by-pass the scaler, all other settings are ignored. */
+	SCALER_NEUTRAL = 0x0,
+	/* Scaler is active. */
+	SCALER_ACTIVE = 0x1,
+} scaler_mode_t;
+
+typedef enum {
+	VS_SRC_SEL__DISABLE		= ID_NONE,
+	VS_SRC_SEL__MATRIX9		= ID_MATRIX9,
+	VS_SRC_SEL__HSCALER9		= ID_HSCALER9,
+	VS_SRC_SEL__EXTSRC4		= ID_EXTSRC4,
+	VS_SRC_SEL__EXTSRC5		= ID_EXTSRC5,
+	VS_SRC_SEL__FETCHDECODE2	= ID_FETCHDECODE2,
+	VS_SRC_SEL__FETCHDECODE3	= ID_FETCHDECODE3,
+	VS_SRC_SEL__FETCHDECODE0	= ID_FETCHDECODE0,
+	VS_SRC_SEL__FETCHDECODE1	= ID_FETCHDECODE1,
+	VS_SRC_SEL__MATRIX4		= ID_MATRIX4,
+	VS_SRC_SEL__HSCALER4		= ID_HSCALER4,
+	VS_SRC_SEL__MATRIX5		= ID_MATRIX5,
+	VS_SRC_SEL__HSCALER5		= ID_HSCALER5,
+} vs_src_sel_t;
+
 #define CLKEN_MASK		(0x3 << 24)
 #define CLKEN_MASK_SHIFT	24
 typedef enum {
@@ -465,6 +528,24 @@ void framegen_cfg_videomode(struct dpu_framegen *fg,
 struct dpu_framegen *dpu_fg_get(struct dpu_soc *dpu, int id);
 void dpu_fg_put(struct dpu_framegen *fg);
 
+/* Horizontal Scaler Unit */
+struct dpu_hscaler;
+int hscaler_pixengcfg_dynamic_src_sel(struct dpu_hscaler *hs, hs_src_sel_t src);
+void hscaler_pixengcfg_clken(struct dpu_hscaler *hs, pixengcfg_clken_t clken);
+void hscaler_shden(struct dpu_hscaler *hs, bool enable);
+void hscaler_setup1(struct dpu_hscaler *hs, unsigned int src, unsigned int dst);
+void hscaler_setup2(struct dpu_hscaler *hs, u32 phase_offset);
+void hscaler_output_size(struct dpu_hscaler *hs, u32 line_num);
+void hscaler_filter_mode(struct dpu_hscaler *hs, scaler_filter_mode_t m);
+void hscaler_scale_mode(struct dpu_hscaler *hs, scaler_scale_mode_t m);
+void hscaler_mode(struct dpu_hscaler *hs, scaler_mode_t m);
+bool hscaler_is_enabled(struct dpu_hscaler *hs);
+dpu_block_id_t hscaler_get_block_id(struct dpu_hscaler *hs);
+unsigned int hscaler_get_stream_id(struct dpu_hscaler *hs);
+void hscaler_set_stream_id(struct dpu_hscaler *hs, unsigned int id);
+struct dpu_hscaler *dpu_hs_get(struct dpu_soc *dpu, int id);
+void dpu_hs_put(struct dpu_hscaler *hs);
+
 /* Layer Blend Unit */
 struct dpu_layerblend;
 int layerblend_pixengcfg_dynamic_prim_sel(struct dpu_layerblend *lb,
@@ -493,6 +574,28 @@ void layerblend_pixengcfg_clken(struct dpu_layerblend *lb,
 struct dpu_tcon *dpu_tcon_get(struct dpu_soc *dpu, int id);
 void dpu_tcon_put(struct dpu_tcon *tcon);
 
+/* Vertical Scaler Unit */
+struct dpu_vscaler;
+int vscaler_pixengcfg_dynamic_src_sel(struct dpu_vscaler *vs, vs_src_sel_t src);
+void vscaler_pixengcfg_clken(struct dpu_vscaler *vs, pixengcfg_clken_t clken);
+void vscaler_shden(struct dpu_vscaler *vs, bool enable);
+void vscaler_setup1(struct dpu_vscaler *vs, unsigned int src, unsigned int dst);
+void vscaler_setup2(struct dpu_vscaler *vs, u32 phase_offset);
+void vscaler_setup3(struct dpu_vscaler *vs, u32 phase_offset);
+void vscaler_setup4(struct dpu_vscaler *vs, u32 phase_offset);
+void vscaler_setup5(struct dpu_vscaler *vs, u32 phase_offset);
+void vscaler_output_size(struct dpu_vscaler *vs, u32 line_num);
+void vscaler_field_mode(struct dpu_vscaler *vs, scaler_field_mode_t m);
+void vscaler_filter_mode(struct dpu_vscaler *vs, scaler_filter_mode_t m);
+void vscaler_scale_mode(struct dpu_vscaler *vs, scaler_scale_mode_t m);
+void vscaler_mode(struct dpu_vscaler *vs, scaler_mode_t m);
+bool vscaler_is_enabled(struct dpu_vscaler *vs);
+dpu_block_id_t vscaler_get_block_id(struct dpu_vscaler *vs);
+unsigned int vscaler_get_stream_id(struct dpu_vscaler *vs);
+void vscaler_set_stream_id(struct dpu_vscaler *vs, unsigned int id);
+struct dpu_vscaler *dpu_vs_get(struct dpu_soc *dpu, int id);
+void dpu_vs_put(struct dpu_vscaler *vs);
+
 /*
  * to avoid on-the-fly/hot plane resource migration
  * between two display interfaces
-- 
1.7.9.5

