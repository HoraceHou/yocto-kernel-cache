From 1ef3bc26d84092fdf04ae64edc4d61c7da5aafac Mon Sep 17 00:00:00 2001
From: Angela Czubak <aczubak@marvell.com>
Date: Fri, 31 May 2019 15:21:24 +0200
Subject: [PATCH 340/386] octeontx: fix ssow_reset_domain

Previous implementation of ssow_reset_domain might perform
SWTAG_UNTAG on a WQP that left over from an application belonging
to a domain that got destroyed. This WQP might therefore have
come from an SSO group that is not mapped in the domain being
reset now, thus triggering SSO_ERR2[WS_UNMAP].
To avoid such issue, first perform GET_WORK (which implicitly
untags a WQP on a workslot), then if the new work has atomic or
ordered tag perform SWTAG_UNTAG.
After all workslots performed untagging, all the SSO groups may
be drained using only one SSOW.

Change-Id: I0d8d05c08b3c7b7a1ffb88330dd51cbf3939a1b6
Signed-off-by: Angela Czubak <aczubak@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/10317
Tested-by: sa_ip-sw-jenkins <sa_ip-sw-jenkins@marvell.com>
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
[RH: Original patch taken from marvell 88F3720 board support SDK 10.0-PR2003]
Signed-off-by: Ruiqiang Hao <Ruiqiang.Hao@windriver.com>
---
 .../cavium/octeontx-83xx/ssowpf_main.c        | 69 ++++++++++++-------
 1 file changed, 44 insertions(+), 25 deletions(-)

diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/ssowpf_main.c b/drivers/net/ethernet/cavium/octeontx-83xx/ssowpf_main.c
index 15889f0f45b1..0830c4388819 100644
--- a/drivers/net/ethernet/cavium/octeontx-83xx/ssowpf_main.c
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/ssowpf_main.c
@@ -359,8 +359,7 @@ int ssow_reset_domain(u32 id, u16 domain_id, u64 grp_mask)
 {
 	struct ssowpf *ssow = NULL;
 	struct ssowpf *curr;
-	int i, ret = 0;
-	bool de_sched = false;
+	int i, first_ssow = -1, ret = 0;
 	int retry = 0;
 	u64 addr;
 	int count = 0;
@@ -382,12 +381,14 @@ int ssow_reset_domain(u32 id, u16 domain_id, u64 grp_mask)
 
 	/* 0. Clear any active TAG switches
 	 * 1. Loop thorugh SSO_ENT_GRP and clear NSCHED
-	 * 2. do get_work on all HWS until VHGRP_INT_CNT and AQ_CNT == 0
+	 * 2. do get_work on first HWS until VHGRP_INT_CNT and AQ_CNT == 0
 	 */
 
 	for (i = 0; i < ssow->total_vfs; i++) {
 		if (ssow->vf[i].domain.in_use &&
 		    ssow->vf[i].domain.domain_id == domain_id) {
+			if (first_ssow == -1)
+				first_ssow = i;
 			sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(i, 0),
 					 grp_mask);
 			sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(i, 1),
@@ -401,9 +402,18 @@ int ssow_reset_domain(u32 id, u16 domain_id, u64 grp_mask)
 					writeq_relaxed(0x0, reg_base +
 						SSOW_VF_VHWSX_OP_DESCHED(0));
 			} else {
-				reg = readq_relaxed(reg_base +
-						    SSOW_VF_VHWSX_WQP(0));
-				if (reg) {
+				/* Perform GET_WORK: it implicitly untags any
+				 * WQP attached to the workslot, and we are also
+				 * sure that the WQP we receive with it belongs
+				 * to GGRP mapped to this domain
+				 */
+				addr = ((u64)ssow->vf[i].domain.reg_base +
+					SSOW_VF_VHWSX_OP_GET_WORK0(0));
+				wqe.work0 = 0;
+				wqe.work1 = 0;
+				ssow_vf_get_work(addr, &wqe);
+
+				if (wqe.work1 != 0) {
 					reg = readq_relaxed(reg_base +
 							SSOW_VF_VHWSX_TAG(0));
 
@@ -412,29 +422,38 @@ int ssow_reset_domain(u32 id, u16 domain_id, u64 grp_mask)
 					      SSOW_VF_VHWSX_OP_SWTAG_UNTAG(0));
 				}
 			}
-
-			if (!de_sched) {
-				ssow_clear_nosched(id, &ssow->vf[i], grp_mask);
-				de_sched = true;
-			}
-
-			addr = ((u64)ssow->vf[i].domain.reg_base +
-					SSOW_VF_VHWSX_OP_GET_WORK0(0));
-			retry = 0;
-			do {
-				wqe.work0 = 0;
-				wqe.work1 = 0;
-				ssow_vf_get_work(addr, &wqe);
-				if (wqe.work1 == 0)
-					retry++;
-				count = __get_sso_group_pend(id, grp_mask);
-			} while (count && retry < 1000);
 			sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(i, 0), 0);
 			sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(i, 1), 0);
 		}
 	}
-	if (count)
-		dev_err(&ssow->pdev->dev, "Failed to reset vf[%d]\n", i);
+
+	if (first_ssow >= 0) {
+		sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(first_ssow, 0),
+				 grp_mask);
+		sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(first_ssow, 1),
+				 grp_mask);
+
+		ssow_clear_nosched(id, &ssow->vf[first_ssow], grp_mask);
+
+		addr = ((u64)ssow->vf[first_ssow].domain.reg_base +
+				SSOW_VF_VHWSX_OP_GET_WORK0(0));
+		retry = 0;
+		do {
+			wqe.work0 = 0;
+			wqe.work1 = 0;
+			ssow_vf_get_work(addr, &wqe);
+			if (wqe.work1 == 0)
+				retry++;
+			count = __get_sso_group_pend(id, grp_mask);
+		} while (count && retry < 1000);
+
+		sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(first_ssow, 0), 0);
+		sso_pf_set_value(id, SSO_PF_HWSX_SX_GRPMASK(first_ssow, 1), 0);
+
+		if (count)
+			dev_err(&ssow->pdev->dev, "Failed to reset vf[%d]\n",
+				first_ssow);
+	}
 
 	for (i = 0; i < ssow->total_vfs; i++) {
 		if (ssow->vf[i].domain.in_use &&
-- 
2.17.1

