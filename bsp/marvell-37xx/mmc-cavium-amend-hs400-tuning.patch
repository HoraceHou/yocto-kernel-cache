From 1c29bd2d73365855f32415bd1eae606595dc1101 Mon Sep 17 00:00:00 2001
From: Peter Swain <pswain@cavium.com>
Date: Fri, 25 Jan 2019 01:24:56 -0800
Subject: [PATCH 051/386] mmc: cavium: amend hs400 tuning

cmd_out/data_out taps are fixed, depending on ios.timing
cmd_in/data_in taps are probed, as before

modparam tune=N adjusts tuning to (last_good_tap - N)
Default value of 2 is recommended,
old behavior can be restored with tune=0

Use CMD21 tuning where applicable

Move some _host properties to _slot, because they're actually
related to the current slot. This avoids mis-associating IRQ
events with the wrong conversation.

Optionally walk clock rate down by 12.5% on each tuning failure
Paranoid timing on DMA teardown: watch _DEBUG and DMA_INT[DONE]
to avoid attributing the final teardown event to wrong request

Change-Id: I46499cd96ed5ae41e57b41525eb7f86f986001de
Signed-off-by: Peter Swain <pswain@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/5721
Tested-by: sa_ip-sw-jenkins
Reviewed-by: Sunil Kovvuri Goutham <Sunil.Goutham@cavium.com>
[RH: Original patch taken from marvell 88F3720 board support SDK 10.0-PR2003]
Signed-off-by: Ruiqiang Hao <Ruiqiang.Hao@windriver.com>
---
 drivers/mmc/host/cavium-thunderx.c |  20 +-
 drivers/mmc/host/cavium.c          | 283 +++++++++++++++++++++--------
 drivers/mmc/host/cavium.h          |  21 ++-
 3 files changed, 234 insertions(+), 90 deletions(-)

diff --git a/drivers/mmc/host/cavium-thunderx.c b/drivers/mmc/host/cavium-thunderx.c
index 4a16f22626c3..b8fb6be2e85f 100644
--- a/drivers/mmc/host/cavium-thunderx.c
+++ b/drivers/mmc/host/cavium-thunderx.c
@@ -32,6 +32,8 @@ static void thunder_mmc_int_enable(struct cvm_mmc_host *host, u64 val)
 {
 	writeq(val, host->base + MIO_EMM_INT(host));
 	writeq(val, host->base + MIO_EMM_INT_EN_SET(host));
+	writeq(MIO_EMM_DMA_INT_DMA,
+		host->dma_base + MIO_EMM_DMA_INT(host));
 }
 
 static int thunder_mmc_register_interrupts(struct cvm_mmc_host *host,
@@ -169,11 +171,14 @@ static int thunder_mmc_probe(struct pci_dev *pdev,
 	/*
 	 * Clear out any pending interrupts that may be left over from
 	 * bootloader. Writing 1 to the bits clears them.
+	 * Clear DMA FIFO after IRQ disable, then stub any dangling events
 	 */
-	writeq(0x1ff, host->base + MIO_EMM_INT(host));
-	writeq(0x1ff, host->base + MIO_EMM_DMA_INT_ENA_W1C(host));
-	/* Clear DMA FIFO */
-	writeq(BIT_ULL(16), host->base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(~0, host->base + MIO_EMM_INT(host));
+	writeq(~0, host->dma_base + MIO_EMM_DMA_INT_ENA_W1C(host));
+	writeq(~0, host->base + MIO_EMM_INT_EN_CLR(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(~0, host->dma_base + MIO_EMM_DMA_INT(host));
 
 	ret = thunder_mmc_register_interrupts(host, pdev);
 	if (ret)
@@ -230,15 +235,16 @@ static void thunder_mmc_remove(struct pci_dev *pdev)
 	u64 dma_cfg;
 	int i;
 
-	cancel_delayed_work(&host->periodic_work);
-
 	for (i = 0; i < CAVIUM_MAX_MMC; i++)
 		if (host->slot[i])
 			cvm_mmc_of_slot_remove(host->slot[i]);
 
 	dma_cfg = readq(host->dma_base + MIO_EMM_DMA_CFG(host));
-	dma_cfg &= ~MIO_EMM_DMA_CFG_EN;
+	dma_cfg |= MIO_EMM_DMA_CFG_CLR;
 	writeq(dma_cfg, host->dma_base + MIO_EMM_DMA_CFG(host));
+	do {
+		dma_cfg = readq(host->dma_base + MIO_EMM_DMA_CFG(host));
+	} while (dma_cfg & MIO_EMM_DMA_CFG_EN);
 
 	clk_disable_unprepare(host->clk);
 }
diff --git a/drivers/mmc/host/cavium.c b/drivers/mmc/host/cavium.c
index a05c39619ac5..c43691478623 100644
--- a/drivers/mmc/host/cavium.c
+++ b/drivers/mmc/host/cavium.c
@@ -77,7 +77,7 @@ static struct cvm_mmc_cr_type cvm_mmc_cr_types[] = {
 	{1, 1},		/* CMD18 */
 	{2, 1},		/* CMD19 */
 	{2, 1},		/* CMD20 */
-	{1, 1},		/* CMD21 */
+	{0, 0},		/* CMD21 */
 	{0, 0},		/* CMD22 */
 	{0, 1},		/* CMD23 */
 	{2, 1},		/* CMD24 */
@@ -122,6 +122,14 @@ static struct cvm_mmc_cr_type cvm_mmc_cr_types[] = {
 	{0, 0}		/* CMD63 */
 };
 
+static int tapdance = 2;
+module_param(tapdance, int, 0644);
+MODULE_PARM_DESC(tapdance, "adjust bus-timing: (0=mid-eye, positive=Nth_fastest_tap)");
+
+static bool ddr_cmd_taps;
+module_param(ddr_cmd_taps, bool, 0644);
+MODULE_PARM_DESC(ddr_cmd_taps, "reduce cmd_out_taps in DDR modes, as before");
+
 bool cvm_is_mmc_timing_ddr(struct cvm_mmc_slot *slot)
 {
 	if ((slot->mmc->ios.timing == MMC_TIMING_UHS_DDR50) ||
@@ -150,26 +158,16 @@ bool cvm_is_mmc(struct cvm_mmc_slot *slot)
 
 static void cvm_mmc_set_timing(struct cvm_mmc_slot *slot)
 {
-	u64 timing;
-
 	if (is_mmc_8xxx(slot->host))
 		return;
 
-	/*
-	 * slot->taps contains the DDR-style settings,
-	 * when in SDR mode the DATA_OUT tap must be squashed
-	 */
-	timing = slot->taps;
-
-	if (!cvm_is_mmc_timing_ddr(slot))
-		timing &= ~MIO_EMM_TIMING_DATA_OUT;
-
-	writeq(timing, slot->host->base + MIO_EMM_TIMING(slot->host));
+	writeq(slot->taps, slot->host->base + MIO_EMM_TIMING(slot->host));
 }
 
 static int cvm_mmc_configure_delay(struct cvm_mmc_slot *slot)
 {
 	struct cvm_mmc_host *host = slot->host;
+	struct mmc_host *mmc = slot->mmc;
 
 	if (is_mmc_8xxx(host)) {
 		/* MIO_EMM_SAMPLE is till T83XX */
@@ -178,16 +176,61 @@ static int cvm_mmc_configure_delay(struct cvm_mmc_slot *slot)
 			FIELD_PREP(MIO_EMM_SAMPLE_DAT_CNT, slot->data_cnt);
 		writeq(emm_sample, host->base + MIO_EMM_SAMPLE(host));
 	} else {
-		if (!slot->tuned) {
-			int half = MAX_NO_OF_TAPS / 2;
-
-			slot->taps =
-				FIELD_PREP(MIO_EMM_TIMING_CMD_IN, half) |
-				FIELD_PREP(MIO_EMM_TIMING_CMD_OUT, half) |
-				FIELD_PREP(MIO_EMM_TIMING_DATA_IN, half) |
-				FIELD_PREP(MIO_EMM_TIMING_DATA_OUT, half);
+		int half = MAX_NO_OF_TAPS / 2;
+		int cin = FIELD_GET(MIO_EMM_TIMING_CMD_IN, slot->taps);
+		int din = FIELD_GET(MIO_EMM_TIMING_DATA_IN, slot->taps);
+		int cout, dout;
+
+		if (!slot->taps)
+			cin = din = half;
+		/*
+		 * EMM_CMD hold time from rising edge of EMMC_CLK.
+		 * Typically 5.0 ns at frequencies < 26 MHz.
+		 * Typically 2.5 ns at frequencies <= 52 MHz.
+		 * Typically 0.4 ns at frequencies > 52 MHz.
+		 */
+		switch (mmc->ios.timing) {
+		case MMC_TIMING_LEGACY:
+		default:
+			cout = 63;
+			if (mmc->card && mmc_card_mmc(mmc->card))
+				cout = 39;
+			break;
+		case MMC_TIMING_UHS_SDR12:
+			cout = 39;
+			break;
+		case MMC_TIMING_MMC_HS:
+			cout = 32;
+			break;
+		case MMC_TIMING_SD_HS:
+		case MMC_TIMING_UHS_SDR25:
+		case MMC_TIMING_UHS_SDR50:
+			cout = 26;
+			break;
+		case MMC_TIMING_UHS_DDR50:
+		case MMC_TIMING_MMC_DDR52:
+			cout = 20;
+			break;
+		case MMC_TIMING_UHS_SDR104:
+		case MMC_TIMING_MMC_HS200:
+		case MMC_TIMING_MMC_HS400:
+			cout = 10;
+			break;
 		}
 
+		if (!cvm_is_mmc_timing_ddr(slot))
+			dout = cout;
+		else if (ddr_cmd_taps)
+			cout = dout = cout / 2;
+		else
+			dout = cout / 2;
+
+		slot->taps =
+			FIELD_PREP(MIO_EMM_TIMING_CMD_IN, cin) |
+			FIELD_PREP(MIO_EMM_TIMING_CMD_OUT, cout) |
+			FIELD_PREP(MIO_EMM_TIMING_DATA_IN, din) |
+			FIELD_PREP(MIO_EMM_TIMING_DATA_OUT, dout);
+
 		pr_debug("taps %llx\n", slot->taps);
 		cvm_mmc_set_timing(slot);
 	}
@@ -285,11 +328,11 @@ static void do_switch(struct cvm_mmc_host *host, u64 emm_switch)
 	 * Modes setting only taken from slot 0. Work around that hardware
 	 * issue by first switching to slot 0.
 	 */
-	bus_id = get_bus_id(emm_switch);
-	clear_bus_id(&emm_switch);
-	writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
-
-	set_bus_id(&emm_switch, bus_id);
+	if (bus_id && errata_29956(host)) {
+		clear_bus_id(&emm_switch);
+		writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
+		set_bus_id(&emm_switch, bus_id);
+	}
 	writeq(emm_switch, host->base + MIO_EMM_SWITCH(host));
 
 	/* wait for the switch to finish */
@@ -302,8 +345,9 @@ static void do_switch(struct cvm_mmc_host *host, u64 emm_switch)
 
 	check_switch_errors(host);
 
-	if (slot && (emm_switch & MIO_EMM_SWITCH_CLK)) {
-		slot->cmd6_pending = false;
+	if (slot) {
+		if (emm_switch & MIO_EMM_SWITCH_CLK)
+			slot->cmd6_pending = false;
 		slot->cached_switch = emm_switch;
 	}
 }
@@ -403,10 +447,11 @@ static void cvm_mmc_switch_to(struct cvm_mmc_slot *slot)
 	host->last_slot = slot->bus_id;
 }
 
-static void do_read(struct cvm_mmc_host *host, struct mmc_request *req,
+static void do_read(struct cvm_mmc_slot *slot, struct mmc_request *req,
 		    u64 dbuf)
 {
-	struct sg_mapping_iter *smi = &host->smi;
+	struct cvm_mmc_host *host = slot->host;
+	struct sg_mapping_iter *smi = &slot->smi;
 	int data_len = req->data->blocks * req->data->blksz;
 	int bytes_xfered, shift = -1;
 	u64 dat = 0;
@@ -473,7 +518,7 @@ static void set_cmd_response(struct cvm_mmc_host *host, struct mmc_request *req,
 	}
 }
 
-static int get_dma_dir(struct mmc_data *data)
+static inline int get_dma_dir(struct mmc_data *data)
 {
 	return (data->flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE : DMA_FROM_DEVICE;
 }
@@ -483,8 +528,8 @@ static int finish_dma_single(struct cvm_mmc_host *host, struct mmc_data *data)
 	data->bytes_xfered = data->blocks * data->blksz;
 	data->error = 0;
 
-	/* Clear and disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 1;
 }
@@ -493,6 +538,7 @@ static int finish_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 {
 	u64 fifo_cfg;
 	int count;
+	void __iomem *dma_intp = host->dma_base + MIO_EMM_DMA_INT(host);
 
 	/* Check if there are any pending requests left */
 	fifo_cfg = readq(host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
@@ -503,8 +549,16 @@ static int finish_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 	data->bytes_xfered = data->blocks * data->blksz;
 	data->error = 0;
 
-	/* Clear and disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+
+	/* on read, wait for internal buffer to flush out to mem */
+	if (get_dma_dir(data) == DMA_FROM_DEVICE) {
+		while (!(readq(dma_intp) & MIO_EMM_DMA_INT_DMA))
+			udelay(10);
+		writeq(MIO_EMM_DMA_INT_DMA, dma_intp);
+	}
+
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 1;
 }
@@ -547,11 +601,12 @@ static void cleanup_dma(struct cvm_mmc_host *host, u64 rsp_sts)
 irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 {
 	struct cvm_mmc_host *host = dev_id;
-	struct mmc_request *req;
-	struct mmc_host *mmc;
-	struct cvm_mmc_slot *slot;
+	struct mmc_request *req = NULL;
+	struct mmc_host *mmc = NULL;
+	struct cvm_mmc_slot *slot = NULL;
 	unsigned long flags = 0;
 	u64 emm_int, rsp_sts;
+	int bus_id;
 	bool host_done;
 
 	if (host->need_irq_handler_lock)
@@ -559,6 +614,12 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	else
 		__acquire(&host->irq_handler_lock);
 
+	rsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));
+	bus_id = get_bus_id(rsp_sts);
+	slot = host->slot[bus_id];
+	if (slot)
+		req = slot->current_req;
+
 	/* Clear interrupt bits (write 1 clears ). */
 	emm_int = readq(host->base + MIO_EMM_INT(host));
 	writeq(emm_int, host->base + MIO_EMM_INT(host));
@@ -566,20 +627,16 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	if (emm_int & MIO_EMM_INT_SWITCH_ERR)
 		check_switch_errors(host);
 
-	req = host->current_req;
 	if (!req)
 		goto out;
 
 	mmc = req->host;
-	slot = !mmc ? NULL : mmc_priv(mmc);
-
-	rsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));
 
 	/*
 	 * dma_pend means DMA has stalled with CRC errs.
 	 * start teardown, get irq on completion, mmc stack retries.
 	 */
-	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_PEND) && host->dma_active) {
+	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_PEND) && slot->dma_active) {
 		cleanup_dma(host, rsp_sts);
 		goto out;
 	}
@@ -589,15 +646,15 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 	 * the request and wait for the interrupt indicating that
 	 * the DMA is finished.
 	 */
-	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_VAL) && host->dma_active)
+	if ((rsp_sts & MIO_EMM_RSP_STS_DMA_VAL) && slot->dma_active)
 		goto out;
 
-	if (!host->dma_active && req->data &&
+	if (!slot->dma_active && req->data &&
 	    (emm_int & MIO_EMM_INT_BUF_DONE)) {
 		unsigned int type = (rsp_sts >> 7) & 3;
 
 		if (type == 1)
-			do_read(host, req, rsp_sts & MIO_EMM_RSP_STS_DBUF);
+			do_read(slot, req, rsp_sts & MIO_EMM_RSP_STS_DBUF);
 		else if (type == 2)
 			do_write(req);
 	}
@@ -616,7 +673,7 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 
 	req->cmd->error = check_status(rsp_sts);
 
-	if (host->dma_active && req->data)
+	if (slot->dma_active && req->data)
 		if (!finish_dma(host, req->data))
 			goto no_req_done;
 
@@ -636,7 +693,7 @@ irqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)
 		}
 	}
 
-	host->current_req = NULL;
+	slot->current_req = NULL;
 	req->done(req);
 
 no_req_done:
@@ -751,8 +808,8 @@ static u64 prepare_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)
 
 error:
 	WARN_ON_ONCE(1);
-	/* Disable FIFO */
-	writeq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
+	writeq(MIO_EMM_DMA_FIFO_CFG_CLR,
+		host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));
 	dma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));
 	return 0;
 }
@@ -837,9 +894,9 @@ static void cvm_mmc_dma_request(struct mmc_host *mmc,
 	}
 
 	mrq->host = mmc;
-	host->dma_active = true;
-	WARN_ON(host->current_req);
-	host->current_req = mrq;
+	WARN_ON(slot->current_req);
+	slot->current_req = mrq;
+	slot->dma_active = true;
 
 	int_enable_mask = MIO_EMM_INT_CMD_ERR | MIO_EMM_INT_DMA_DONE |
 			MIO_EMM_INT_DMA_ERR;
@@ -874,16 +931,17 @@ static void cvm_mmc_dma_request(struct mmc_host *mmc,
 	host->release_bus(host);
 }
 
-static void do_read_request(struct cvm_mmc_host *host, struct mmc_request *mrq)
+static void do_read_request(struct cvm_mmc_slot *slot, struct mmc_request *mrq)
 {
-	sg_miter_start(&host->smi, mrq->data->sg, mrq->data->sg_len,
+	sg_miter_start(&slot->smi, mrq->data->sg, mrq->data->sg_len,
 		       SG_MITER_ATOMIC | SG_MITER_TO_SG);
 }
 
-static void do_write_request(struct cvm_mmc_host *host, struct mmc_request *mrq)
+static void do_write_request(struct cvm_mmc_slot *slot, struct mmc_request *mrq)
 {
+	struct cvm_mmc_host *host = slot->host;
 	unsigned int data_len = mrq->data->blocks * mrq->data->blksz;
-	struct sg_mapping_iter *smi = &host->smi;
+	struct sg_mapping_iter *smi = &slot->smi;
 	unsigned int bytes_xfered;
 	int shift = 56;
 	u64 dat = 0;
@@ -990,22 +1048,22 @@ static void cvm_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 	mods = cvm_mmc_get_cr_mods(cmd);
 
-	WARN_ON(host->current_req);
+	WARN_ON(slot->current_req);
 	mrq->host = mmc;
-	host->current_req = mrq;
+	slot->current_req = mrq;
 
 	if (cmd->data) {
 		if (cmd->data->flags & MMC_DATA_READ)
-			do_read_request(host, mrq);
+			do_read_request(slot, mrq);
 		else
-			do_write_request(host, mrq);
+			do_write_request(slot, mrq);
 
 		if (cmd->data->timeout_ns)
 			set_wdog(slot, cmd->data->timeout_ns);
 	} else
 		set_wdog(slot, 0);
 
-	host->dma_active = false;
+	slot->dma_active = false;
 	host->int_enable(host, MIO_EMM_INT_CMD_DONE | MIO_EMM_INT_CMD_ERR);
 
 	if (cmd->opcode == MMC_SWITCH)
@@ -1077,7 +1135,7 @@ static int cvm_mmc_r1_cmd(struct mmc_host *mmc, u32 *statp, u32 opcode)
 	return cvm_mrq.cmd->error;
 }
 
-static int cvm_mmc_get_ext_csd(struct mmc_host *mmc, u32 *statp, u32 unused)
+static int cvm_mmc_data_tuning(struct mmc_host *mmc, u32 *statp, u32 opcode)
 {
 	int err = 0;
 	u8 *ext_csd;
@@ -1085,8 +1143,24 @@ static int cvm_mmc_get_ext_csd(struct mmc_host *mmc, u32 *statp, u32 unused)
 	static struct mmc_data data = {};
 	static struct mmc_request cvm_mrq = {};
 	static struct scatterlist sg;
+	struct cvm_mmc_slot *slot = mmc_priv(mmc);
 	struct mmc_card *card = mmc->card;
 
+	if (!(slot->cached_switch & MIO_EMM_SWITCH_HS400_TIMING)) {
+		struct cvm_mmc_host *host = slot->host;
+		int edetail = -EINVAL;
+		int core_opinion;
+
+		host->release_bus(host);
+		core_opinion =
+			mmc_send_tuning(mmc, opcode, &edetail);
+		host->acquire_bus(host);
+
+		/* only accept mmc/core opinion  when it's happy */
+		if (!core_opinion)
+			return core_opinion;
+	}
+
 	/* EXT_CSD supported only after ver 3 */
 	if (card && card->csd.mmca_vsn <= CSD_SPEC_VER_3)
 		return -EOPNOTSUPP;
@@ -1159,6 +1233,7 @@ struct adj {
 static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 {
 	int err, start_run = -1, best_run = 0, best_start = -1;
+	int last_good = -1;
 	bool prev_ok = false;
 	u64 timing, tap;
 	struct cvm_mmc_slot *slot = mmc_priv(mmc);
@@ -1176,6 +1251,8 @@ static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 			err = adj->test(mmc, NULL, opcode);
 
 			how[tap] = "-+"[!err];
+			if (!err)
+				last_good = tap;
 		} else {
 			/*
 			 * putting the end+1 case in loop simplifies
@@ -1204,13 +1281,17 @@ static int adjust_tuning(struct mmc_host *mmc, struct adj *adj, u32 opcode)
 	}
 
 	if (best_start < 0) {
-		dev_warn(host->dev, "%s tuning %s failed\n",
-			mmc_hostname(mmc), adj->name);
+		dev_warn(host->dev, "%s %lldMHz tuning %s failed\n",
+			mmc_hostname(mmc), slot->clock / 1000000, adj->name);
 		return -EINVAL;
 	}
 
 	tap = best_start + best_run / 2;
 	how[tap] = '@';
+	if (tapdance) {
+		tap = last_good - tapdance;
+		how[tap] = 'X';
+	}
 	dev_dbg(host->dev, "%s/%s %d/%lld/%d %s\n",
 		mmc_hostname(mmc), adj->name,
 		best_start, tap, best_start + best_run,
@@ -1327,17 +1408,17 @@ static void cvm_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		break;
 	case MMC_TIMING_MMC_HS:
 	case MMC_TIMING_SD_HS:
-		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS_TIMING, 1);
-		break;
 	case MMC_TIMING_UHS_SDR12:
 	case MMC_TIMING_UHS_SDR25:
 	case MMC_TIMING_UHS_SDR50:
 	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_UHS_DDR50:
+	case MMC_TIMING_MMC_DDR52:
+		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS_TIMING, 1);
+		break;
 	case MMC_TIMING_MMC_HS200:
 		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS200_TIMING, 1);
 		break;
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
 	case MMC_TIMING_MMC_HS400:
 		emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_HS400_TIMING, 1);
 		break;
@@ -1373,23 +1454,17 @@ static void cvm_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 static struct adj adj[] = {
 	{ "CMD_IN", MIO_EMM_TIMING_CMD_IN,
 		cvm_mmc_r1_cmd, MMC_SEND_STATUS, },
-	{ "CMD_OUT", MIO_EMM_TIMING_CMD_OUT,
-		cvm_mmc_r1_cmd, MMC_SEND_STATUS, },
 	{ "DATA_IN", MIO_EMM_TIMING_DATA_IN,
-		cvm_mmc_get_ext_csd, },
-	{ "DATA_OUT", MIO_EMM_TIMING_DATA_OUT,
-		cvm_mmc_r1_cmd, 0, true, },
+		cvm_mmc_data_tuning, },
 	{ NULL, },
 };
 
-static int cvm_execute_tuning(struct mmc_host *mmc, u32 opcode)
+static int cvm_scan_tuning(struct mmc_host *mmc, u32 opcode)
 {
 	struct cvm_mmc_slot *slot = mmc_priv(mmc);
 	struct adj *a;
 	int ret;
 
-	dev_info(slot->host->dev, "%s re-tuning\n", mmc_hostname(mmc));
-
 	for (a = adj; a->name; a++) {
 		if (a->ddr_only && !cvm_is_mmc_timing_ddr(slot))
 			continue;
@@ -1402,10 +1477,61 @@ static int cvm_execute_tuning(struct mmc_host *mmc, u32 opcode)
 	}
 
 	cvm_mmc_set_timing(slot);
-	slot->tuned = true;
 	return 0;
 }
 
+static int cvm_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	struct cvm_mmc_slot *slot = mmc_priv(mmc);
+	struct cvm_mmc_host *host = slot->host;
+	int clk_period, hz;
+
+	int ret;
+
+	do {
+		u64 emm_switch =
+			readq(host->base + MIO_EMM_MODE(host, slot->bus_id));
+
+		clk_period = FIELD_GET(MIO_EMM_SWITCH_CLK_LO, emm_switch);
+		dev_info(slot->host->dev, "%s re-tuning\n",
+			mmc_hostname(mmc));
+		ret = cvm_scan_tuning(mmc, opcode);
+		if (ret) {
+			int inc = clk_period >> 3;
+
+			if (!inc)
+				inc++;
+			clk_period += inc;
+			hz = host->sys_freq / (2 * clk_period);
+			pr_debug("clk_period %d += %d, now %d Hz\n",
+				clk_period - inc, inc, hz);
+
+			if (hz < 400000)
+				break;
+
+			slot->clock = hz;
+			mmc->ios.clock = hz;
+
+			emm_switch &= ~MIO_EMM_SWITCH_CLK_LO;
+			emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_CLK_LO,
+						clk_period);
+			emm_switch &= ~MIO_EMM_SWITCH_CLK_HI;
+			emm_switch |= FIELD_PREP(MIO_EMM_SWITCH_CLK_HI,
+						clk_period);
+			do_switch(host, emm_switch);
+		}
+	} while (ret);
+
+	return ret;
+}
+
+static int cvm_prepare_hs400_tuning(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct cvm_mmc_slot *slot = mmc_priv(mmc);
+
+	return cvm_mmc_configure_delay(slot);
+}
+
 static void cvm_mmc_reset(struct mmc_host *mmc)
 {
 	struct cvm_mmc_slot *slot = mmc_priv(mmc);
@@ -1431,6 +1557,7 @@ static const struct mmc_host_ops cvm_mmc_ops = {
 	.get_cd		= mmc_gpio_get_cd,
 	.hw_reset	= cvm_mmc_reset,
 	.execute_tuning = cvm_execute_tuning,
+	.prepare_hs400_tuning = cvm_prepare_hs400_tuning,
 };
 
 static void cvm_mmc_set_clock(struct cvm_mmc_slot *slot, unsigned int clock)
diff --git a/drivers/mmc/host/cavium.h b/drivers/mmc/host/cavium.h
index fe284207f506..5b2d67b3436e 100644
--- a/drivers/mmc/host/cavium.h
+++ b/drivers/mmc/host/cavium.h
@@ -106,9 +106,6 @@ struct cvm_mmc_host {
 	struct clk *clk;
 	int sys_freq;
 
-	struct mmc_request *current_req;
-	struct sg_mapping_iter smi;
-	bool dma_active;
 	bool use_sg;
 
 	bool has_ciu3;
@@ -125,7 +122,6 @@ struct cvm_mmc_host {
 	struct platform_device *slot_pdev[CAVIUM_MAX_MMC];
 	/* octtx2 specific */
 	unsigned int per_tap_delay; /* per tap delay in pico second */
-	struct delayed_work periodic_work;
 
 	void (*set_shared_power)(struct cvm_mmc_host *, int);
 	void (*acquire_bus)(struct cvm_mmc_host *);
@@ -140,13 +136,17 @@ struct cvm_mmc_host {
 struct cvm_mmc_slot {
 	struct mmc_host *mmc;		/* slot-level mmc_core object */
 	struct cvm_mmc_host *host;	/* common hw for all slots */
+	struct mmc_request *current_req;
 
 	u64 clock;
+	u32 ecount, gcount;
 
 	u64 cached_switch;
 	u64 cached_rca;
 
-	bool tuned;
+	struct sg_mapping_iter smi;
+	bool dma_active;
+
 	u64 taps;			/* otx2: MIO_EMM_TIMING */
 	unsigned int cmd_cnt;		/* otx: sample cmd in delay */
 	unsigned int data_cnt;		/* otx: sample data in delay */
@@ -237,6 +237,9 @@ struct cvm_mmc_cr_mods {
 #define MIO_EMM_INT_CMD_DONE		BIT_ULL(1)
 #define MIO_EMM_INT_BUF_DONE		BIT_ULL(0)
 
+#define MIO_EMM_DMA_INT_FIFO		BIT_ULL(1)
+#define MIO_EMM_DMA_INT_DMA		BIT_ULL(0)
+
 #define MIO_EMM_RSP_STS_BUS_ID		GENMASK_ULL(61, 60)
 #define MIO_EMM_RSP_STS_CMD_VAL		BIT_ULL(59)
 #define MIO_EMM_RSP_STS_SWITCH_VAL	BIT_ULL(58)
@@ -311,4 +314,12 @@ static inline bool is_mmc_otx2_A0(struct cvm_mmc_host *host)
 	return (pdev->revision == 0x00) &&
 		(chip_id == PCI_SUBSYS_DEVID_9XXX);
 }
+
+static inline bool errata_29956(struct cvm_mmc_host *host)
+{
+	/* Clock is not set properly when the
+	 * bus_id is non-zero.
+	 */
+	return is_mmc_otx2_A0(host);
+}
 #endif
-- 
2.17.1

