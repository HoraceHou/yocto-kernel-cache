From 3c8e5b94790a8e7d52112a3bba2c09dc4a9a3ff1 Mon Sep 17 00:00:00 2001
From: Yan Markman <ymarkman@marvell.com>
Date: Thu, 9 Aug 2018 12:48:25 +0300
Subject: [PATCH 0556/1051] net: mvpp2: use tx bulk writing to aggregated
 tx-queue

The traffic performance could be improved (up to 22%) by reducing
Aggregated TX-queue counter register (write a bulk of N instead of
one-by-one). This requires defer in xmit-procedure and bulk-timer.

This patch modifies the xmit-procedure to defer, accumulate N tx-packets
and write to Aggregated queue this bulk.
The 50uSec bulk timer is used to finalize the xmit in case of traffic
stop or gap.
The feature is enabled by default.

Change-Id: I3478b5c9ce0013279ccf0d86f38f8a625d74a2a4
Signed-off-by: Yan Markman <ymarkman@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/59486
Reviewed-by: Stefan Chulski <stefanc@marvell.com>
Tested-by: Stefan Chulski <stefanc@marvell.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../net/ethernet/marvell/mvpp2/mvpp2_main.c   | 21 ++++++++++++++++---
 1 file changed, 18 insertions(+), 3 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
index 5f214b60fb9f..106774f20c81 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
@@ -3427,14 +3427,27 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 	if (frags > 0) {
 		struct mvpp2_pcpu_stats *stats = per_cpu_ptr(port->stats, thread);
 		struct netdev_queue *nq = netdev_get_tx_queue(dev, txq_id);
+		struct mvpp2_port_pcpu *port_pcpu = this_cpu_ptr(port->pcpu);
+		bool deferred_tx;
 
 		txq_pcpu->reserved_num -= frags;
 		txq_pcpu->count += frags;
 		aggr_txq->count += frags;
 
-		/* Enable transmit */
-		wmb();
-		mvpp2_aggr_txq_pend_desc_add(port, frags);
+		/* Enable transmit; may be deferred with Bulk-timer */
+		deferred_tx = (frags == 1) &&
+			(aggr_txq->pending < (txq->done_pkts_coal / 2));
+
+		if (deferred_tx) {
+			aggr_txq->pending += frags;
+			mvpp2_bulk_timer_restart(port_pcpu);
+		} else {
+			port_pcpu->bulk_timer_scheduled = false;
+			port_pcpu->bulk_timer_restart_req = false;
+			frags += aggr_txq->pending;
+			aggr_txq->pending = 0;
+			mvpp2_aggr_txq_pend_desc_add(port, frags);
+		}
 
 		if (txq_pcpu->count >= txq_pcpu->stop_threshold)
 			netif_tx_stop_queue(nq);
@@ -3881,6 +3894,7 @@ static int mvpp2_stop(struct net_device *dev)
 	struct mvpp2_port *port = netdev_priv(dev);
 	struct mvpp2_port_pcpu *port_pcpu;
 	unsigned int thread;
+	int cpu;
 
 	mvpp2_stop_dev(port);
 
@@ -5153,6 +5167,7 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 	int features;
 	int phy_mode;
 	int err, i;
+	int cpu;
 
 	has_tx_irqs = mvpp2_port_has_irqs(priv, port_node, &flags);
 	if (!has_tx_irqs && queue_mode == MVPP2_QDIST_MULTI_MODE) {
-- 
2.17.1

