From b402ecb7f44bf60f085a0e58078927e9b1f80934 Mon Sep 17 00:00:00 2001
From: Yan Markman <ymarkman@marvell.com>
Date: Mon, 15 Oct 2018 19:41:23 +0300
Subject: [PATCH 0729/1051] net: mvpp2: reduce reading RXQ occupied status

Access to HW register has huge latency vs access to local percpu
RX-Queue structure.
Under high-loaded-cpu the number of RXed packets read from
RXQ occupied status register could be huge (200..300..500) whilst
only NAPI_POLL_WEIGHT=64 of them are handled in 1 napi cycle.
This situation is very frequent (hundreds per second).

In the case number of reads from RXQ occupied status register
may be reduced and replaced by reading from RXQ pending field.

Change-Id: Ib30461a060b95e2c247e6131115685fe702d3341
Signed-off-by: Yan Markman <ymarkman@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/60521
Reviewed-by: Igal Liberman <igall@marvell.com>
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/marvell/mvpp2/mvpp2.h    |  3 +++
 .../net/ethernet/marvell/mvpp2/mvpp2_main.c   | 19 +++++++++++++++----
 2 files changed, 18 insertions(+), 4 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2.h b/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
index e4584b797dee..95cc4ad7fc87 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
@@ -1116,6 +1116,9 @@ struct mvpp2_rx_queue {
 	/* Port's logic RXQ number to which physical RXQ is mapped */
 	u8 logic_rxq;
 
+	/* Num of RXed packets seen in HW but meanwhile not handled by SW */
+	u16 rx_pending;
+
 	/* Num of rx descriptors in the rx descriptor ring */
 	int size;
 
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
index be7a888dc968..56a2e9bd6cac 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
@@ -2275,6 +2275,7 @@ static int mvpp2_rxq_init(struct mvpp2_port *port,
 		return -ENOMEM;
 
 	rxq->last_desc = rxq->size - 1;
+	rxq->rx_pending = 0;
 
 	/* Zero occupied and non-occupied counters - direct access */
 	mvpp2_write(port->priv, MVPP2_RXQ_STATUS_REG(rxq->id), 0);
@@ -2310,6 +2311,7 @@ static void mvpp2_rxq_drop_pkts(struct mvpp2_port *port,
 {
 	int rx_received, i;
 
+	rxq->rx_pending = 0;
 	rx_received = mvpp2_rxq_received(port, rxq->id);
 	if (!rx_received)
 		return;
@@ -3431,10 +3433,19 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 	u32 rcvd_bytes = 0;
 	struct sk_buff *skb_all[rx_todo];
 
-	/* Get number of received packets and clamp the to-do */
-	rx_received = mvpp2_rxq_received(port, rxq->id);
-	if (rx_todo > rx_received)
-		rx_todo = rx_received;
+	if (rxq->rx_pending >= rx_todo) {
+		rx_received = rx_todo;
+		rxq->rx_pending -= rx_todo;
+	} else {
+		/* Get number of received packets and clamp the to-do */
+		rx_received = mvpp2_rxq_received(port, rxq->id);
+		if (rx_received < rx_todo) {
+			rx_todo = rx_received;
+			rxq->rx_pending = 0;
+		} else {
+			rxq->rx_pending = rx_received - rx_todo;
+		}
+	}
 
 	while (rx_done < rx_todo) {
 		struct mvpp2_rx_desc *rx_desc = mvpp2_rxq_next_desc_get(rxq);
-- 
2.17.1

