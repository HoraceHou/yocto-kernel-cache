From 6345ff5af12a408f30ad06f9a21de815888dea45 Mon Sep 17 00:00:00 2001
From: Marcin Wojtas <mw@semihalf.com>
Date: Fri, 8 Feb 2019 15:20:39 +0100
Subject: [PATCH 0986/1051] net: mvneta: improve Icache utilization in rx_swbm

Main RX processing (SWBM path) of the mvneta driver consist mainly
of the big loop (maximum of NAPI budget iterations) in which
packets are received from HW, put into skb and pushed further
to the kernel stack with napi_gro_receive routine.

The latter is of a significant size and called once per each received
packet, which cause inefficient Icache utilization and hence
performance downgrade. Prevent this effect by splitting the main
loop into two. The first loop does the packet reception, creates skb's
and stores in array. The second loop simply calls napi_gro_receive
for each socket buffer.

As a result during L3FWD test with 64B frames, there perf reports
29% L1-icache-load-misses events less in the system.

Change-Id: I40f4ebc7dd18c40239187bfa21c0ed3b9dcaae89
Signed-off-by: Marcin Wojtas <mw@semihalf.com>
Reviewed-on: https://sj1git1.cavium.com/3746
Tested-by: sa_ip-sw-jenkins
Reviewed-by: Stefan Chulski <Stefan.Chulski@cavium.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/marvell/mvneta.c | 10 ++++++----
 1 file changed, 6 insertions(+), 4 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvneta.c b/drivers/net/ethernet/marvell/mvneta.c
index 0a4633b69cf0..1a82133b3a44 100644
--- a/drivers/net/ethernet/marvell/mvneta.c
+++ b/drivers/net/ethernet/marvell/mvneta.c
@@ -1942,9 +1942,10 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			  struct mvneta_port *pp, int budget,
 			  struct mvneta_rx_queue *rxq)
 {
+	struct sk_buff *rcvd_skbs[NAPI_POLL_WEIGHT];
 	struct net_device *dev = pp->dev;
 	int rx_todo, rx_proc;
-	int refill = 0;
+	int refill = 0, i = 0;
 	u32 rcvd_pkts = 0;
 	u32 rcvd_bytes = 0;
 
@@ -2077,19 +2078,20 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			rxq->skb = NULL;
 			continue;
 		}
-		rcvd_pkts++;
 		rcvd_bytes += rxq->skb->len;
+		rcvd_skbs[rcvd_pkts++] = rxq->skb;
 
 		/* Linux processing */
 		rxq->skb->protocol = eth_type_trans(rxq->skb, dev);
 
-		napi_gro_receive(napi, rxq->skb);
-
 		/* clean uncomplete skb pointer in queue */
 		rxq->skb = NULL;
 		rxq->left_size = 0;
 	}
 
+	while (i < rcvd_pkts)
+		napi_gro_receive(napi, rcvd_skbs[i++]);
+
 	if (rcvd_pkts) {
 		struct mvneta_pcpu_stats *stats = this_cpu_ptr(pp->stats);
 
-- 
2.17.1

