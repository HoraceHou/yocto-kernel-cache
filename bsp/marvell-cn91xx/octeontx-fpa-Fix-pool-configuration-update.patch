From e73f5524df9cb819dfd272ecd7dae5856adfd5d2 Mon Sep 17 00:00:00 2001
From: Slawomir Rosek <slawomir.rosek@cavium.com>
Date: Tue, 27 Nov 2018 17:31:00 +0300
Subject: [PATCH 0766/1051] octeontx-fpa: Fix pool configuration update

Disable FPA pool before its configuration update.

Signed-off-by: Slawomir Rosek <slawomir.rosek@cavium.com>
Reviewed-by: Stanislaw Kardach <stanislaw.kardach@cavium.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/net/ethernet/cavium/octeontx-83xx/fpapf_main.c | 8 ++++++++
 drivers/net/ethernet/cavium/octeontx-83xx/fpavf_main.c | 3 +++
 2 files changed, 11 insertions(+)

diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/fpapf_main.c b/drivers/net/ethernet/cavium/octeontx-83xx/fpapf_main.c
index 73757bf21e34..a70be1dde8c1 100644
--- a/drivers/net/ethernet/cavium/octeontx-83xx/fpapf_main.c
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/fpapf_main.c
@@ -130,6 +130,14 @@ static int fpa_pf_receive_message(u32 id, u16 domain_id,
 	case FPA_CONFIGSET:
 		cfg = add_data;
 
+		dev_dbg(&fpa->pdev->dev, "Setup vf[%u] stack:[%llx-%llx] cfg:%llx\n",
+			vf->hardware_pool, cfg->pool_stack_base,
+			cfg->pool_stack_end - 1, cfg->pool_cfg);
+
+		/* Disable pool before configuration update */
+		fpa_reg_write(fpa, FPA_PF_POOLX_CFG(vf->hardware_pool), 0x0);
+
+		/* Update pool configuration and enable if required */
 		fpa_reg_write(fpa, FPA_PF_AURAX_CFG((vf->hardware_aura_set *
 				FPA_AURA_SET_SIZE) + cfg->aid),
 				cfg->aura_cfg);
diff --git a/drivers/net/ethernet/cavium/octeontx-83xx/fpavf_main.c b/drivers/net/ethernet/cavium/octeontx-83xx/fpavf_main.c
index 0bcc267de3fd..78e79f049bf3 100644
--- a/drivers/net/ethernet/cavium/octeontx-83xx/fpavf_main.c
+++ b/drivers/net/ethernet/cavium/octeontx-83xx/fpavf_main.c
@@ -236,6 +236,9 @@ static int fpa_vf_setup(struct fpavf *fpa, u64 num_buffers, u32 buf_len,
 		return -ENOMEM;
 	}
 
+	dev_dbg(&fpa->pdev->dev, "Alloc stack memory: iova [%llx-%llx]\n",
+		fpa->pool_iova, fpa->pool_iova + fpa->pool_size - 1);
+
 	fpa->num_buffers = num_buffers;
 	fpa->alloc_count = ((atomic_t) { (0) });
 	fpa->alloc_thold = (num_buffers * 10) / 100;
-- 
2.17.1

