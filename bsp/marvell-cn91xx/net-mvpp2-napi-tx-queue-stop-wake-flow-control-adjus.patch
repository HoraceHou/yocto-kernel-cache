From 9f1bd0423dc69c7c485f6e2641b125c87f01ab9e Mon Sep 17 00:00:00 2001
From: Marcin Wojtas <mw@semihalf.com>
Date: Thu, 27 Sep 2018 08:06:59 +0200
Subject: [PATCH 0562/1051] net: mvpp2: napi tx-queue stop-wake flow control
 adjust

Adjust the napi-stop/napi-wake tx-queue flow control to prevent
frequent packet-drops on Descriptor-reservation.

Change-Id: If4fc83420e47f8e14b6fc357f791aad546d5b360
Signed-off-by: Yan Markman <ymarkman@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/59493
Reviewed-by: Stefan Chulski <stefanc@marvell.com>
Tested-by: Stefan Chulski <stefanc@marvell.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../net/ethernet/marvell/mvpp2/mvpp2_main.c   | 33 +++++++++++--------
 1 file changed, 20 insertions(+), 13 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
index e2db65a23495..39c1ee1696af 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
@@ -1688,8 +1688,10 @@ static int mvpp2_txq_reserved_desc_num_proc(struct mvpp2_port *port,
 					    struct mvpp2_txq_pcpu *txq_pcpu,
 					    int num)
 {
-	int req, desc_count;
 	unsigned int thread;
+	struct netdev_queue *nq;
+	int req, desc_count, total;
+	struct mvpp2_txq_pcpu *txq_pcpu_aux;
 
 	if (txq_pcpu->reserved_num >= num)
 		return 0;
@@ -1697,23 +1699,27 @@ static int mvpp2_txq_reserved_desc_num_proc(struct mvpp2_port *port,
 	/* Not enough descriptors reserved! Update the reserved descriptor
 	 * count and check again.
 	 */
-
+	/* Count total used descriptors (already reserved + waiting
+	 * for transmit) and check limit before going with HW reservation.
+	 */
 	desc_count = 0;
-	/* Compute total of used descriptors */
 	for (thread = 0; thread < port->priv->nthreads; thread++) {
-		struct mvpp2_txq_pcpu *txq_pcpu_aux;
-
 		txq_pcpu_aux = per_cpu_ptr(txq->pcpu, thread);
 		desc_count += txq_pcpu_aux->count;
 		desc_count += txq_pcpu_aux->reserved_num;
 	}
-
 	req = max(MVPP2_CPU_DESC_CHUNK, num - txq_pcpu->reserved_num);
-	desc_count += req;
 
-	if (desc_count >
-	   (txq->size - (MVPP2_MAX_THREADS * MVPP2_CPU_DESC_CHUNK)))
-		return -ENOMEM;
+	total = desc_count + req;
+	if (likely((total + MVPP2_CPU_DESC_CHUNK) <= txq->size)) {
+		; /* goto reserve_in_hw */
+	} else if (total <= txq->size) {
+		 /* Pause the TX-Queue but continue with this packet */
+		nq = netdev_get_tx_queue(port->dev, txq->log_id);
+		netif_tx_stop_queue(nq);
+	} else {
+		return -ENOMEM; /* drop the packet */
+	}
 
 	txq_pcpu->reserved_num += mvpp2_txq_alloc_reserved_desc(port, txq, req);
 
@@ -3502,8 +3508,8 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 out:
 	if (frags > 0) {
 		struct mvpp2_pcpu_stats *stats = per_cpu_ptr(port->stats, thread);
-		struct netdev_queue *nq = netdev_get_tx_queue(dev, txq_id);
 		struct mvpp2_port_pcpu *port_pcpu = this_cpu_ptr(port->pcpu);
+		struct netdev_queue *nq;
 		bool deferred_tx;
 
 		txq_pcpu->reserved_num -= frags;
@@ -3525,9 +3531,10 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 			mvpp2_aggr_txq_pend_desc_add(port, frags);
 		}
 
-		if (txq_pcpu->count >= txq_pcpu->stop_threshold)
+		if (unlikely(txq_pcpu->count >= txq_pcpu->stop_threshold)) {
+			nq = netdev_get_tx_queue(dev, txq_id);
 			netif_tx_stop_queue(nq);
-
+		}
 		u64_stats_update_begin(&stats->syncp);
 		stats->tx_packets++;
 		stats->tx_bytes += skb->len;
-- 
2.17.1

