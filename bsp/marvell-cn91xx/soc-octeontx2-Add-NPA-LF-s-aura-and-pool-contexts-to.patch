From ab0ddaabc873f217e566376c7bece06f66ac2e1b Mon Sep 17 00:00:00 2001
From: Christina Jacob <cjacob@marvell.com>
Date: Thu, 16 Aug 2018 21:50:51 +0530
Subject: [PATCH 0091/1051] soc: octeontx2: Add NPA LF's aura and pool contexts
 to debugfs

To aid in debugging NPA related issues, add support to display
NPA LF's aura and pool contexts in debugfs. User can check
which contexts are enabled currently and dump current HW context.

Signed-off-by: Christina Jacob <cjacob@marvell.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 drivers/soc/marvell/octeontx2/rvu.h         |   3 +
 drivers/soc/marvell/octeontx2/rvu_debugfs.c | 371 +++++++++++++++++++-
 drivers/soc/marvell/octeontx2/rvu_npa.c     |   4 +-
 3 files changed, 375 insertions(+), 3 deletions(-)

diff --git a/drivers/soc/marvell/octeontx2/rvu.h b/drivers/soc/marvell/octeontx2/rvu.h
index b392102507e3..6ef50dc63b30 100644
--- a/drivers/soc/marvell/octeontx2/rvu.h
+++ b/drivers/soc/marvell/octeontx2/rvu.h
@@ -34,6 +34,7 @@
 #ifdef CONFIG_DEBUG_FS
 struct rvu_debugfs {
 	struct dentry *root;
+	struct dentry *npa;
 };
 #endif
 
@@ -343,6 +344,8 @@ int rvu_mbox_handler_CGX_INTLBK_DISABLE(struct rvu *rvu, struct msg_req *req,
 /* NPA APIs */
 int rvu_npa_init(struct rvu *rvu);
 void rvu_npa_lf_teardown(struct rvu *rvu, u16 pcifunc, int npalf);
+int rvu_npa_aq_enq_inst(struct rvu *rvu, struct npa_aq_enq_req *req,
+			struct npa_aq_enq_rsp *rsp);
 int rvu_mbox_handler_NPA_AQ_ENQ(struct rvu *rvu,
 				struct npa_aq_enq_req *req,
 				struct npa_aq_enq_rsp *rsp);
diff --git a/drivers/soc/marvell/octeontx2/rvu_debugfs.c b/drivers/soc/marvell/octeontx2/rvu_debugfs.c
index 7bf4a9ee8280..ce0c0cd208b3 100644
--- a/drivers/soc/marvell/octeontx2/rvu_debugfs.c
+++ b/drivers/soc/marvell/octeontx2/rvu_debugfs.c
@@ -103,10 +103,377 @@ static ssize_t rvu_dbg_rsrc_attach_status(struct file *filp,
 }
 RVU_DEBUG_FOPS(rsrc_status, rsrc_attach_status, NULL);
 
-void rvu_dbg_init(struct rvu *rvu)
+/* The 'qsize' entry dumps current Aura/Pool context Qsize
+ * and each context's current enable/disable status in a bitmap.
+ */
+static ssize_t rvu_dbg_npa_qsize_display(struct file *filp,
+					 const char __user *buffer,
+					 size_t count, loff_t *ppos)
+{
+	char *cmd_buf, *cmd_buf_tmp, *buf, *subtoken;
+	struct rvu *rvu = filp->private_data;
+	struct rvu_hwinfo *hw = rvu->hw;
+	struct rvu_block *block;
+	struct rvu_pfvf *pfvf;
+	int bytes_not_copied;
+	u64 pcifunc;
+	int npalf;
+	int ret;
+
+	/* don't allow partial writes */
+	if (*ppos != 0)
+		return 0;
+
+	cmd_buf = kzalloc(count + 1, GFP_KERNEL);
+	if (!cmd_buf)
+		return count;
+	bytes_not_copied = copy_from_user(cmd_buf, buffer, count);
+	if (bytes_not_copied) {
+		kfree(cmd_buf);
+		return -EFAULT;
+	}
+	cmd_buf[count] = '\0';
+
+	cmd_buf_tmp = strchr(cmd_buf, '\n');
+	if (cmd_buf_tmp) {
+		*cmd_buf_tmp = '\0';
+		count = cmd_buf_tmp - cmd_buf + 1;
+	}
+	subtoken = strsep(&cmd_buf, " ");
+	ret = subtoken ? kstrtoint(subtoken, 10, &npalf) : -EINVAL;
+	if (cmd_buf)
+		ret = -EINVAL;
+
+	if (!strncmp(subtoken, "help", 4) || (ret < 0)) {
+		pr_info("Use echo <npalf > qsize\n");
+		goto npa_qsize_display_done;
+	}
+
+	block = &hw->block[BLKTYPE_NPA];
+	if (npalf < 0 || npalf >= block->lf.max) {
+		pr_info("Invalid NPALF, valid range is 0-%d\n",
+			block->lf.max - 1);
+		goto npa_qsize_display_done;
+	}
+
+	pcifunc = block->fn_map[npalf];
+	if (!pcifunc) {
+		pr_info("This NPALF is not attached to any RVU PFFUNC\n");
+		goto npa_qsize_display_done;
+	}
+
+	pfvf = rvu_get_pfvf(rvu, pcifunc);
+	buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!buf) {
+		pr_info("failed to allocate memory\n");
+		goto npa_qsize_display_done;
+	}
+
+	if (!pfvf->aura_ctx) {
+		pr_info("Aura context is not initialized\n");
+	} else {
+		bitmap_print_to_pagebuf(false, buf, pfvf->aura_bmap,
+					pfvf->aura_ctx->qsize);
+		pr_info("Aura count  : %d\n", pfvf->aura_ctx->qsize);
+		pr_info("Aura context ena/dis bitmap : %s\n", buf);
+	}
+
+	if (!pfvf->pool_ctx) {
+		pr_info("Pool context is not initialized\n");
+	} else {
+		bitmap_print_to_pagebuf(false, buf, pfvf->pool_bmap,
+					pfvf->pool_ctx->qsize);
+		pr_info("Pool count  : %d\n", pfvf->pool_ctx->qsize);
+		pr_info("Pool context ena/dis bitmap : %s\n", buf);
+	}
+	kfree(buf);
+npa_qsize_display_done:
+	kfree(cmd_buf);
+	return count;
+}
+
+/* Dumps given NPA Aura's context */
+static void print_npa_aura_ctx(struct npa_aq_enq_rsp *rsp)
+{
+	struct npa_aura_s *aura = &rsp->aura;
+
+	pr_info("W0: Pool addr\t\t%llx\n", aura->pool_addr);
+
+	pr_info("W1: ena\t\t\t%d\nW1: pool caching\t\t%d\n",
+		aura->ena, aura->pool_caching);
+	pr_info("W1: pool way mask\t%d\nW1: avg con\t\t%d\n",
+		aura->pool_way_mask, aura->avg_con);
+	pr_info("W1: pool drop ena\t%d\nW1: aura drop ena\t%d\n",
+		aura->pool_drop_ena, aura->aura_drop_ena);
+	pr_info("W1: bp_ena\t\t%d\nW1: aura drop\t\t%d\n",
+		aura->aura_drop, aura->shift);
+	pr_info("W1: aura shift\t\t%d\nW1: avg_level\t\t%d\n",
+		aura->bp_ena, aura->avg_level);
+
+	pr_info("W2: count\t\t%llu\nW2: nix0_bpid\t\t%d\nW2: nix1_bpid\t\t%d\n",
+		(u64)aura->count, aura->nix0_bpid, aura->nix1_bpid);
+
+	pr_info("W3: limit\t\t%llu\nW3: bp\t\t\t%d\nW3: fc_ena\t\t%d\n",
+		(u64)aura->limit, aura->bp, aura->fc_ena);
+	pr_info("W3: fc_up_crossing\t%d\nW3: fc_stype\t\t%d\n",
+		aura->fc_up_crossing, aura->fc_stype);
+	pr_info("W3: fc_hyst_bits\t\t%d\n", aura->fc_hyst_bits);
+
+	pr_info("W4: fc_addr\t\t%llx\n", aura->fc_addr);
+
+	pr_info("W5: pool_drop\t\t%d\nW5: update_time\t\t%d\n",
+		aura->pool_drop, aura->update_time);
+	pr_info("W5: err_int \t\t%d\nW5: err_int_ena\t\t%d\n",
+		aura->err_int, aura->err_int_ena);
+	pr_info("W5: thresh_int\t\t%d\nW5: thresh_int_ena \t%d\n",
+		aura->thresh_int, aura->thresh_int_ena);
+	pr_info("W5: thresh_up\t\t%d\nW5: thresh_qint_idx\t%d\n",
+		aura->thresh_qint_idx, aura->err_qint_idx);
+	pr_info("W5: err_qint_idx \t\t%d\n", aura->thresh_up);
+
+	pr_info("W6: thresh\t\t%llu\n", (u64)aura->thresh);
+}
+
+/* Dumps given NPA Pool's context */
+static void print_npa_pool_ctx(struct npa_aq_enq_rsp *rsp)
+{
+	struct npa_pool_s *pool = &rsp->pool;
+
+	pr_info("W0: Stack base\t\t%llx\n", pool->stack_base);
+
+	pr_info("W1: ena \t\t\t%d\nW1: nat_align \t\t%d\n",
+		pool->ena, pool->nat_align);
+	pr_info("W1: stack_caching\t%d\nW1: stack_way_mask\t%d\n",
+		pool->stack_caching, pool->stack_way_mask);
+	pr_info("W1: buf_offset\t\t%d\nW1: buf_size\t\t%d\n",
+		pool->buf_offset, pool->buf_size);
+
+	pr_info("W2: stack_max_pages \t%d\nW2: stack_pages\t\t%d\n",
+		pool->stack_max_pages, pool->stack_pages);
+
+	pr_info("W3: op_pc \t\t%llu\n", (u64)pool->op_pc);
+
+	pr_info("W4: stack_offset\t\t%d\nW4: shift\t\t%d\nW4: avg_level\t\t%d\n",
+		pool->stack_offset, pool->shift, pool->avg_level);
+	pr_info("W4: avg_con \t\t%d\nW4: fc_ena\t\t%d\nW4: fc_stype\t\t%d\n",
+		pool->avg_con, pool->fc_ena, pool->fc_stype);
+	pr_info("W4: fc_hyst_bits\t\t%d\nW4: fc_up_crossing\t%d\n",
+		pool->fc_hyst_bits, pool->fc_up_crossing);
+	pr_info("W4: update_time\t\t%d\n", pool->update_time);
+
+	pr_info("W5: fc_addr\t\t%llx\n", pool->fc_addr);
+
+	pr_info("W6: ptr_start\t\t%llx\n", pool->ptr_start);
+
+	pr_info("W7: ptr_end\t\t%llx\n", pool->ptr_end);
+
+	pr_info("W8: err_int\t\t%d\nW8: err_int_ena\t\t%d\n",
+		pool->err_int, pool->err_int_ena);
+	pr_info("W8: thresh_int\t\t%d\n", pool->thresh_int);
+	pr_info("W8: thresh_int_ena\t%d\nW8: thresh_up\t\t%d\n",
+		pool->thresh_int_ena, pool->thresh_up);
+	pr_info("W8: thresh_qint_idx\t%d\nW8: err_qint_idx\t\t%d\n",
+		pool->thresh_qint_idx, pool->err_qint_idx);
+}
+
+/* Reads aura/pool's ctx from admin queue */
+static void read_npa_ctx(struct rvu *rvu, bool all,
+			 int npalf, int id, int ctype)
+{
+	void (*print_npa_ctx)(struct npa_aq_enq_rsp *rsp);
+	struct rvu_hwinfo *hw = rvu->hw;
+	struct npa_aq_enq_req aq_req;
+	struct npa_aq_enq_rsp rsp;
+	struct rvu_block *block;
+	struct rvu_pfvf *pfvf;
+	int aura, rc, max_id;
+	u64 pcifunc;
+	int blkaddr;
+
+	blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, 0);
+	if (blkaddr < 0)
+		return;
+
+	block = &hw->block[blkaddr];
+	if (npalf < 0 || npalf >= block->lf.max) {
+		pr_info("Invalid NPALF, valid range is 0-%d\n",
+			block->lf.max - 1);
+		return;
+	}
+
+	pcifunc = block->fn_map[npalf];
+	if (!pcifunc) {
+		pr_info("This NPALF is not attached to any RVU PFFUNC\n");
+		return;
+	}
+
+	pfvf = rvu_get_pfvf(rvu, pcifunc);
+	if (ctype == NPA_AQ_CTYPE_AURA && !pfvf->aura_ctx) {
+		pr_info("Aura context is not initialized\n");
+		return;
+	} else if (ctype == NPA_AQ_CTYPE_POOL && !pfvf->pool_ctx) {
+		pr_info("Pool context is not initialized\n");
+		return;
+	}
+
+	memset(&aq_req, 0, sizeof(struct npa_aq_enq_req));
+	aq_req.hdr.pcifunc = pcifunc;
+	aq_req.ctype = ctype;
+	aq_req.op = NPA_AQ_INSTOP_READ;
+	if (ctype == NPA_AQ_CTYPE_AURA) {
+		max_id =  pfvf->aura_ctx->qsize;
+		print_npa_ctx = print_npa_aura_ctx;
+	} else {
+		max_id =  pfvf->pool_ctx->qsize;
+		print_npa_ctx = print_npa_pool_ctx;
+	}
+
+	if (id < 0 || id >= max_id) {
+		pr_info("Invalid %s, valid range is 0-%d\n",
+			(ctype == NPA_AQ_CTYPE_AURA) ? "aura" : "pool",
+			max_id - 1);
+		return;
+	}
+
+	if (all)
+		id = 0;
+	else
+		max_id = id + 1;
+
+	for (aura = id; aura < max_id; aura++) {
+		aq_req.aura_id = aura;
+		pr_info("======%s : %d=======\n",
+			(ctype == NPA_AQ_CTYPE_AURA) ? "AURA" : "POOL",
+			aq_req.aura_id);
+		rc = rvu_npa_aq_enq_inst(rvu, &aq_req, &rsp);
+		if (rc) {
+			pr_info("Failed to read context\n");
+			return;
+		}
+		print_npa_ctx(&rsp);
+	}
+}
+
+static int parse_cmd_buffer_ctx(char *cmd_buf, size_t *count,
+				const char __user *buffer, int *npalf,
+				int *id, bool *all)
 {
+	int bytes_not_copied;
+	char *cmd_buf_tmp;
+	char *subtoken;
+	int ret;
+
+	bytes_not_copied = copy_from_user(cmd_buf, buffer, *count);
+	if (bytes_not_copied)
+		return -EFAULT;
+
+	cmd_buf[*count] = '\0';
+	cmd_buf_tmp = strchr(cmd_buf, '\n');
+
+	if (cmd_buf_tmp) {
+		*cmd_buf_tmp = '\0';
+		*count = cmd_buf_tmp - cmd_buf + 1;
+	}
+
+	subtoken = strsep(&cmd_buf, " ");
+	ret = subtoken ? kstrtoint(subtoken, 10, npalf) : -EINVAL;
+	if (ret < 0)
+		return ret;
+	subtoken = strsep(&cmd_buf, " ");
+	if (subtoken && strcmp(subtoken, "all") == 0) {
+		*all = true;
+	} else{
+		ret = subtoken ? kstrtoint(subtoken, 10, id) : -EINVAL;
+		if (ret < 0)
+			return ret;
+	}
+	if (cmd_buf)
+		return -EINVAL;
+	return ret;
+}
+
+static ssize_t rvu_dbg_npa_ctx_display(struct file *filp,
+				       const char __user *buffer,
+				       size_t count, loff_t *ppos, int ctype)
+{
+	char *cmd_buf, *ctype_string = (ctype ==  NPA_AQ_CTYPE_AURA) ?
+					"aura" : "pool";
+	struct rvu *rvu = filp->private_data;
+	int npalf, id = 0;
+	bool all = false;
+
+	if ((*ppos != 0) || !count)
+		return 0;
+
+	cmd_buf = kzalloc(count + 1, GFP_KERNEL);
+
+	if (!cmd_buf)
+		return count;
+	if (parse_cmd_buffer_ctx(cmd_buf, &count, buffer,
+				 &npalf, &id, &all) < 0) {
+		pr_info("Usage: echo <npalf> [%s number/all] > %s_ctx\n",
+			ctype_string, ctype_string);
+	} else {
+		read_npa_ctx(rvu, all, npalf, id, ctype);
+	}
+
+	kfree(cmd_buf);
+	return count;
+}
+RVU_DEBUG_FOPS(npa_qsize, NULL, npa_qsize_display);
+
+static ssize_t rvu_dbg_npa_aura_ctx_display(struct file *filp,
+					    const char __user *buffer,
+					    size_t count, loff_t *ppos)
+{
+	return  rvu_dbg_npa_ctx_display(filp, buffer, count, ppos,
+					NPA_AQ_CTYPE_AURA);
+}
+RVU_DEBUG_FOPS(npa_aura_ctx,  NULL, npa_aura_ctx_display);
+
+static ssize_t rvu_dbg_npa_pool_ctx_display(struct file *filp,
+					    const char __user *buffer,
+					    size_t count, loff_t *ppos)
+{
+	return  rvu_dbg_npa_ctx_display(filp, buffer, count, ppos,
+					NPA_AQ_CTYPE_POOL);
+}
+RVU_DEBUG_FOPS(npa_pool_ctx, NULL, npa_pool_ctx_display);
+
+static void rvu_dbg_npa_init(struct rvu *rvu)
+{
+	const struct device *dev = &rvu->pdev->dev;
 	struct dentry *pfile;
+
+	rvu->rvu_dbg.npa = debugfs_create_dir("npa", rvu->rvu_dbg.root);
+	if (!rvu->rvu_dbg.npa)
+		return;
+
+	pfile = debugfs_create_file("qsize", 0600, rvu->rvu_dbg.npa, rvu,
+				    &rvu_dbg_npa_qsize_fops);
+	if (!pfile)
+		goto create_failed;
+
+	pfile = debugfs_create_file("aura_ctx", 0600, rvu->rvu_dbg.npa, rvu,
+				    &rvu_dbg_npa_aura_ctx_fops);
+	if (!pfile)
+		goto create_failed;
+
+	pfile = debugfs_create_file("pool_ctx", 0600, rvu->rvu_dbg.npa, rvu,
+				    &rvu_dbg_npa_pool_ctx_fops);
+	if (!pfile)
+		goto create_failed;
+
+	return;
+create_failed:
+	dev_err(dev, "Failed to create debugfs dir/file for NPA\n");
+	debugfs_remove_recursive(rvu->rvu_dbg.npa);
+}
+
+void rvu_dbg_init(struct rvu *rvu)
+{
 	struct device *dev = &rvu->pdev->dev;
+	struct dentry *pfile;
 
 	rvu->rvu_dbg.root = debugfs_create_dir("octeontx2", NULL);
 	if (!rvu->rvu_dbg.root) {
@@ -118,6 +485,8 @@ void rvu_dbg_init(struct rvu *rvu)
 	if (!pfile)
 		goto create_failed;
 
+	rvu_dbg_npa_init(rvu);
+
 	return;
 
 create_failed:
diff --git a/drivers/soc/marvell/octeontx2/rvu_npa.c b/drivers/soc/marvell/octeontx2/rvu_npa.c
index 3066f2eff20e..eb18ca636d22 100644
--- a/drivers/soc/marvell/octeontx2/rvu_npa.c
+++ b/drivers/soc/marvell/octeontx2/rvu_npa.c
@@ -52,8 +52,8 @@ static int npa_aq_enqueue_wait(struct rvu *rvu, struct rvu_block *block,
 	return 0;
 }
 
-static int rvu_npa_aq_enq_inst(struct rvu *rvu, struct npa_aq_enq_req *req,
-			       struct npa_aq_enq_rsp *rsp)
+int rvu_npa_aq_enq_inst(struct rvu *rvu, struct npa_aq_enq_req *req,
+			struct npa_aq_enq_rsp *rsp)
 {
 	struct rvu_hwinfo *hw = rvu->hw;
 	u16 pcifunc = req->hdr.pcifunc;
-- 
2.17.1

