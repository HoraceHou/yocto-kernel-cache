From d2869de9d9189aa298d23162ac11188fdf3288c9 Mon Sep 17 00:00:00 2001
From: Christina Jacob <cjacob@marvell.com>
Date: Thu, 16 Aug 2018 15:54:17 +0530
Subject: [PATCH 0127/1051] net: octeontx2: Add basic ethtool support

This patch adds ethtool support for
 - Driver stats: Tx/Rx perqueue and CGX LMAC stats
 - Set/show Rx/Tx queue count
 - Set/show Rx/Tx ring sizes

Signed-off-by: Christina Jacob <cjacob@marvell.com>
[Kevin: The original patch got from Marvell sdk10.0_19.06]
Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 .../net/ethernet/marvell/octeontx2/Makefile   |   2 +-
 .../ethernet/marvell/octeontx2/otx2_common.c  |  92 +++++-
 .../ethernet/marvell/octeontx2/otx2_common.h  |  17 +-
 .../ethernet/marvell/octeontx2/otx2_ethtool.c | 287 ++++++++++++++++++
 .../net/ethernet/marvell/octeontx2/otx2_pf.c  |  21 +-
 .../ethernet/marvell/octeontx2/otx2_txrx.h    |  13 +
 6 files changed, 421 insertions(+), 11 deletions(-)
 create mode 100644 drivers/net/ethernet/marvell/octeontx2/otx2_ethtool.c

diff --git a/drivers/net/ethernet/marvell/octeontx2/Makefile b/drivers/net/ethernet/marvell/octeontx2/Makefile
index 3d4f219508fd..872b655dae01 100644
--- a/drivers/net/ethernet/marvell/octeontx2/Makefile
+++ b/drivers/net/ethernet/marvell/octeontx2/Makefile
@@ -5,6 +5,6 @@
 
 obj-$(CONFIG_OCTEONTX2_PF) += octeontx2_nicpf.o
 
-octeontx2_nicpf-y := otx2_pf.o otx2_common.o otx2_txrx.o
+octeontx2_nicpf-y := otx2_pf.o otx2_common.o otx2_txrx.o otx2_ethtool.o
 
 ccflags-y += -I$(srctree)/drivers/soc/marvell/octeontx2
diff --git a/drivers/net/ethernet/marvell/octeontx2/otx2_common.c b/drivers/net/ethernet/marvell/octeontx2/otx2_common.c
index 9af5b11cd942..e097a8e4d530 100644
--- a/drivers/net/ethernet/marvell/octeontx2/otx2_common.c
+++ b/drivers/net/ethernet/marvell/octeontx2/otx2_common.c
@@ -16,6 +16,11 @@
 #include "otx2_common.h"
 #include "otx2_struct.h"
 
+static inline void otx2_nix_rq_op_stats(struct queue_stats *stats,
+					struct otx2_nic *pfvf, int qidx);
+static inline void otx2_nix_sq_op_stats(struct queue_stats *stats,
+					struct otx2_nic *pfvf, int qidx);
+
 /* Sync MAC address with RVU */
 int otx2_hw_set_mac_addr(struct otx2_nic *pfvf, struct net_device *netdev)
 {
@@ -186,6 +191,41 @@ int otx2_rss_init(struct otx2_nic *pfvf)
 	return otx2_set_flowkey_cfg(pfvf);
 }
 
+void otx2_update_lmac_stats(struct otx2_nic *pfvf)
+{
+	struct msg_req *req;
+
+	if (!netif_running(pfvf->netdev))
+		return;
+	req = otx2_mbox_alloc_msg_CGX_STATS(&pfvf->mbox);
+	if (!req)
+		return;
+
+	otx2_sync_mbox_msg(&pfvf->mbox);
+}
+
+int otx2_update_rq_stats(struct otx2_nic *pfvf, int qidx)
+{
+	struct otx2_rcv_queue *rq = &pfvf->qset.rq[qidx];
+
+	if (!pfvf->qset.rq)
+		return 0;
+
+	otx2_nix_rq_op_stats(&rq->stats, pfvf, qidx);
+	return 1;
+}
+
+int otx2_update_sq_stats(struct otx2_nic *pfvf, int qidx)
+{
+	struct otx2_snd_queue *sq = &pfvf->qset.sq[qidx];
+
+	if (!pfvf->qset.sq)
+		return 0;
+
+	otx2_nix_sq_op_stats(&sq->stats, pfvf, qidx);
+	return 1;
+}
+
 void otx2_get_dev_stats(struct otx2_nic *pfvf)
 {
 	struct otx2_dev_stats *dev_stats = &pfvf->hw.dev_stats;
@@ -451,18 +491,22 @@ static int otx2_sq_init(struct otx2_nic *pfvf, u16 qidx)
 		return err;
 
 	sq->sqe_base = sq->sqe->base;
-	sq->sg = kcalloc((SQ_QLEN + 1), sizeof(struct sg_list), GFP_KERNEL);
+	sq->sg = kcalloc((qset->sqe_cnt + 1),
+			 sizeof(struct sg_list), GFP_KERNEL);
 	if (!sq->sg)
 		return -ENOMEM;
 
 	sq->head = 0;
 	sq->num_sqbs = (pfvf->hw.sqb_size / sq->sqe_size) - 1;
-	sq->num_sqbs = (SQ_QLEN + sq->num_sqbs) / sq->num_sqbs;
+	sq->num_sqbs = (qset->sqe_cnt + sq->num_sqbs) / sq->num_sqbs;
 	sq->aura_id = pool_id;
 	sq->aura_fc_addr = pool->fc_addr->base;
 	sq->lmt_addr = (__force u64 *)(pfvf->reg_base + LMT_LF_LMTLINEX(qidx));
 	sq->io_addr = (__force u64)(pfvf->reg_base + NIX_LF_OP_SENDX(0));
 
+	sq->stats.bytes = 0;
+	sq->stats.pkts = 0;
+
 	/* Get memory to put this msg */
 	aq = otx2_mbox_alloc_msg_NIX_AQ_ENQ(&pfvf->mbox);
 	if (!aq)
@@ -495,7 +539,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 	int err, pool_id;
 
 	cq = &qset->cq[qidx];
-	cq->cqe_cnt = Q_COUNT(Q_SIZE_4K);
+	cq->cqe_cnt = qset->cqe_cnt;
 	cq->cqe_size = pfvf->qset.xqe_size;
 
 	/* Allocate memory for CQEs */
@@ -520,7 +564,7 @@ static int otx2_cq_init(struct otx2_nic *pfvf, u16 qidx)
 		return -ENOMEM;
 
 	aq->cq.ena = 1;
-	aq->cq.qsize = Q_SIZE_4K;
+	aq->cq.qsize = Q_SIZE(cq->cqe_cnt, 4);
 	aq->cq.caching = 1;
 	aq->cq.base = cq->cqe->iova;
 	aq->cq.cint_idx = (qidx < pfvf->hw.rx_queues) ? qidx
@@ -745,6 +789,7 @@ static int otx2_pool_init(struct otx2_nic *pfvf, u16 pool_id,
 
 int otx2_sq_aura_pool_init(struct otx2_nic *pfvf)
 {
+	struct otx2_qset *qset = &pfvf->qset;
 	int pool_id, stack_pages, num_sqbs;
 	struct otx2_hw *hw = &pfvf->hw;
 	struct otx2_pool *pool;
@@ -757,7 +802,7 @@ int otx2_sq_aura_pool_init(struct otx2_nic *pfvf)
 	 * Last SQE is used for pointing to next SQB.
 	 */
 	num_sqbs = (hw->sqb_size / 128) - 1;
-	num_sqbs = (SQ_QLEN + num_sqbs) / num_sqbs;
+	num_sqbs = (qset->sqe_cnt + num_sqbs) / num_sqbs;
 
 	/* Get no of stack pages needed */
 	stack_pages =
@@ -951,7 +996,44 @@ void otx2_ctx_disable(struct mbox *mbox, int type, bool npa)
 	WARN_ON(otx2_sync_mbox_msg(mbox));
 }
 
+static inline void otx2_nix_rq_op_stats(struct queue_stats *stats,
+					struct otx2_nic *pfvf, int qidx)
+{
+	u64 incr = (u64)qidx << 32;
+	atomic64_t *ptr;
+
+	ptr = (__force atomic64_t *)(pfvf->reg_base + NIX_LF_RQ_OP_OCTS);
+	stats->bytes = atomic64_fetch_add_relaxed(incr, ptr);
+
+	ptr = (__force atomic64_t *)(pfvf->reg_base + NIX_LF_RQ_OP_PKTS);
+	stats->pkts = atomic64_fetch_add_relaxed(incr, ptr);
+}
+
+static inline void otx2_nix_sq_op_stats(struct queue_stats *stats,
+					struct otx2_nic *pfvf, int qidx)
+{
+	u64 incr = (u64)qidx << 32;
+	atomic64_t *ptr;
+
+	ptr = (__force atomic64_t *)(pfvf->reg_base + NIX_LF_SQ_OP_OCTS);
+	stats->bytes = atomic64_fetch_add_relaxed(incr, ptr);
+
+	ptr = (__force atomic64_t *)(pfvf->reg_base + NIX_LF_SQ_OP_PKTS);
+	stats->pkts = atomic64_fetch_add_relaxed(incr, ptr);
+}
+
 /* Mbox message handlers */
+void mbox_handler_CGX_STATS(struct otx2_nic *pfvf,
+			    struct cgx_stats_rsp *rsp)
+{
+	int id;
+
+	for (id = 0; id < CGX_RX_STATS_COUNT; id++)
+		pfvf->hw.cgx_rx_stats[id] = rsp->rx_stats[id];
+	for (id = 0; id < CGX_TX_STATS_COUNT; id++)
+		pfvf->hw.cgx_tx_stats[id] = rsp->tx_stats[id];
+}
+
 void mbox_handler_NIX_TXSCH_ALLOC(struct otx2_nic *pf,
 				  struct nix_txsch_alloc_rsp *rsp)
 {
diff --git a/drivers/net/ethernet/marvell/octeontx2/otx2_common.h b/drivers/net/ethernet/marvell/octeontx2/otx2_common.h
index df888e209e64..fe90386b25fd 100644
--- a/drivers/net/ethernet/marvell/octeontx2/otx2_common.h
+++ b/drivers/net/ethernet/marvell/octeontx2/otx2_common.h
@@ -122,6 +122,9 @@ struct otx2_hw {
 	/* For TSO segmentation */
 	u8			lso_tsov4_idx;
 	u8			lso_tsov6_idx;
+
+	u64			cgx_rx_stats[CGX_RX_STATS_COUNT];
+	u64			cgx_tx_stats[CGX_TX_STATS_COUNT];
 };
 
 struct otx2_nic {
@@ -322,5 +325,17 @@ void mbox_handler_NIX_LF_ALLOC(struct otx2_nic *pfvf,
 			       struct nix_lf_alloc_rsp *rsp);
 void mbox_handler_NIX_TXSCH_ALLOC(struct otx2_nic *pf,
 				  struct nix_txsch_alloc_rsp *rsp);
-
+void mbox_handler_CGX_STATS(struct otx2_nic *pfvf,
+			    struct cgx_stats_rsp *rsp);
+
+/* Device stats APIs */
+void otx2_update_lmac_stats(struct otx2_nic *pfvf);
+int otx2_update_rq_stats(struct otx2_nic *pfvf, int qidx);
+int otx2_update_sq_stats(struct otx2_nic *pfvf, int qidx);
+void otx2_set_ethtool_ops(struct net_device *netdev);
+
+int otx2_open(struct net_device *netdev);
+int otx2_stop(struct net_device *netdev);
+int otx2_set_real_num_queues(struct net_device *netdev,
+			     int tx_queues, int rx_queues);
 #endif /* OTX2_COMMON_H */
diff --git a/drivers/net/ethernet/marvell/octeontx2/otx2_ethtool.c b/drivers/net/ethernet/marvell/octeontx2/otx2_ethtool.c
new file mode 100644
index 000000000000..8bcf6c516d3c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/octeontx2/otx2_ethtool.c
@@ -0,0 +1,287 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Marvell OcteonTx2 RVU Ethernet driver
+ *
+ * Copyright (C) 2018 Marvell International Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/pci.h>
+#include <linux/net_tstamp.h>
+#include <linux/ethtool.h>
+#include <linux/stddef.h>
+#include <linux/etherdevice.h>
+#include <linux/log2.h>
+
+#include "otx2_common.h"
+
+#define DRV_NAME	"octeontx2-nicpf"
+#define DRV_VERSION	"1.0"
+
+struct otx2_stat {
+	char name[ETH_GSTRING_LEN];
+	unsigned int index;
+};
+
+#define OTX2_DEV_STAT(stat) { \
+	.name = #stat, \
+	.index = offsetof(struct otx2_dev_stats, stat) / sizeof(u64), \
+}
+
+static const struct otx2_stat otx2_dev_stats[] = {
+	OTX2_DEV_STAT(rx_bytes),
+	OTX2_DEV_STAT(rx_frames),
+	OTX2_DEV_STAT(rx_ucast_frames),
+	OTX2_DEV_STAT(rx_bcast_frames),
+	OTX2_DEV_STAT(rx_mcast_frames),
+	OTX2_DEV_STAT(rx_drops),
+
+	OTX2_DEV_STAT(tx_bytes),
+	OTX2_DEV_STAT(tx_frames),
+	OTX2_DEV_STAT(tx_ucast_frames),
+	OTX2_DEV_STAT(tx_bcast_frames),
+	OTX2_DEV_STAT(tx_mcast_frames),
+	OTX2_DEV_STAT(tx_drops),
+};
+
+static const struct otx2_stat otx2_queue_stats[] = {
+	{ "bytes", 0 },
+	{ "frames", 1 },
+};
+
+static const unsigned int otx2_n_dev_stats = ARRAY_SIZE(otx2_dev_stats);
+static const unsigned int otx2_n_queue_stats = ARRAY_SIZE(otx2_queue_stats);
+
+static void otx2_get_drvinfo(struct net_device *netdev,
+			     struct ethtool_drvinfo *info)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+
+	strlcpy(info->driver, DRV_NAME, sizeof(info->driver));
+	strlcpy(info->version, DRV_VERSION, sizeof(info->version));
+	strlcpy(info->bus_info, pci_name(pfvf->pdev), sizeof(info->bus_info));
+}
+
+static void otx2_get_qset_strings(struct otx2_nic *pfvf, u8 **data, int qset)
+{
+	int start_qidx = qset * pfvf->hw.rx_queues;
+	int qidx, stats;
+
+	for (qidx = 0; qidx < pfvf->hw.rx_queues; qidx++) {
+		for (stats = 0; stats < otx2_n_queue_stats; stats++) {
+			sprintf(*data, "rxq%d: %s", qidx + start_qidx,
+				otx2_queue_stats[stats].name);
+			*data += ETH_GSTRING_LEN;
+		}
+	}
+	for (qidx = 0; qidx < pfvf->hw.tx_queues; qidx++) {
+		for (stats = 0; stats < otx2_n_queue_stats; stats++) {
+			sprintf(*data, "txq%d: %s", qidx + start_qidx,
+				otx2_queue_stats[stats].name);
+			*data += ETH_GSTRING_LEN;
+		}
+	}
+}
+
+static void otx2_get_strings(struct net_device *netdev, u32 sset, u8 *data)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+	int stats;
+
+	if (sset != ETH_SS_STATS)
+		return;
+
+	for (stats = 0; stats < otx2_n_dev_stats; stats++) {
+		memcpy(data, otx2_dev_stats[stats].name, ETH_GSTRING_LEN);
+		data += ETH_GSTRING_LEN;
+	}
+	otx2_get_qset_strings(pfvf, &data, 0);
+
+	for (stats = 0; stats < CGX_RX_STATS_COUNT; stats++) {
+		sprintf(data, "cgx_rxstat%d: ", stats);
+		data += ETH_GSTRING_LEN;
+	}
+
+	for (stats = 0; stats < CGX_TX_STATS_COUNT; stats++) {
+		sprintf(data, "cgx_txstat%d: ", stats);
+		data += ETH_GSTRING_LEN;
+	}
+}
+
+static void otx2_get_qset_stats(struct otx2_nic *pfvf,
+				struct ethtool_stats *stats, u64 **data)
+{
+	int stat, qidx;
+
+	if (!pfvf)
+		return;
+	for (qidx = 0; qidx < pfvf->hw.rx_queues; qidx++) {
+		if (!otx2_update_rq_stats(pfvf, qidx)) {
+			for (stat = 0; stat < otx2_n_queue_stats; stat++)
+				*((*data)++) = 0;
+			continue;
+		}
+		for (stat = 0; stat < otx2_n_queue_stats; stat++)
+			*((*data)++) = ((u64 *)&pfvf->qset.rq[qidx].stats)
+				[otx2_queue_stats[stat].index];
+	}
+
+	for (qidx = 0; qidx < pfvf->hw.tx_queues; qidx++) {
+		if (!otx2_update_sq_stats(pfvf, qidx)) {
+			for (stat = 0; stat < otx2_n_queue_stats; stat++)
+				*((*data)++) = 0;
+			continue;
+		}
+		for (stat = 0; stat < otx2_n_queue_stats; stat++)
+			*((*data)++) = ((u64 *)&pfvf->qset.sq[qidx].stats)
+				[otx2_queue_stats[stat].index];
+	}
+}
+
+/* Get device and per queue statistics */
+static void otx2_get_ethtool_stats(struct net_device *netdev,
+				   struct ethtool_stats *stats, u64 *data)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+	int stat;
+
+	otx2_get_dev_stats(pfvf);
+	for (stat = 0; stat < otx2_n_dev_stats; stat++)
+		*(data++) = ((u64 *)&pfvf->hw.dev_stats)
+				[otx2_dev_stats[stat].index];
+	otx2_get_qset_stats(pfvf, stats, &data);
+	otx2_update_lmac_stats(pfvf);
+	for (stat = 0; stat < CGX_RX_STATS_COUNT; stat++)
+		*(data++) = pfvf->hw.cgx_rx_stats[stat];
+	for (stat = 0; stat < CGX_TX_STATS_COUNT; stat++)
+		*(data++) = pfvf->hw.cgx_tx_stats[stat];
+}
+
+static int otx2_get_sset_count(struct net_device *netdev, int sset)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+	int qstats_count;
+
+	if (sset != ETH_SS_STATS)
+		return -EINVAL;
+
+	qstats_count = otx2_n_queue_stats *
+		       (pfvf->hw.rx_queues + pfvf->hw.tx_queues);
+	return otx2_n_dev_stats + qstats_count +
+		CGX_RX_STATS_COUNT + CGX_TX_STATS_COUNT;
+}
+
+/* Get no of queues device supports and current queue count */
+static void otx2_get_channels(struct net_device *dev,
+			      struct ethtool_channels *channel)
+{
+	struct otx2_nic *pfvf = netdev_priv(dev);
+
+	memset(channel, 0, sizeof(*channel));
+	channel->max_rx = pfvf->hw.max_queues;
+	channel->max_tx = pfvf->hw.max_queues;
+
+	channel->rx_count = pfvf->hw.rx_queues;
+	channel->tx_count = pfvf->hw.tx_queues;
+}
+
+/* Set no of Tx, Rx queues to be used */
+static int otx2_set_channels(struct net_device *dev,
+			     struct ethtool_channels *channel)
+{
+	struct otx2_nic *pfvf = netdev_priv(dev);
+	bool if_up = netif_running(dev);
+	int err = 0;
+
+	if (!channel->rx_count || !channel->tx_count)
+		return -EINVAL;
+	if (channel->rx_count > pfvf->hw.max_queues)
+		return -EINVAL;
+	if (channel->tx_count > pfvf->hw.max_queues)
+		return -EINVAL;
+
+	if (if_up)
+		otx2_stop(dev);
+
+	pfvf->hw.rx_queues = channel->rx_count;
+	pfvf->hw.tx_queues = channel->tx_count;
+	err = otx2_set_real_num_queues(dev, pfvf->hw.tx_queues,
+				       pfvf->hw.rx_queues);
+	pfvf->qset.cq_cnt = pfvf->hw.tx_queues +  pfvf->hw.rx_queues;
+	if (err)
+		return err;
+
+	if (if_up)
+		otx2_open(dev);
+
+	netdev_info(dev, "Setting num Tx rings to %d, Rx rings to %d success\n",
+		    pfvf->hw.tx_queues, pfvf->hw.rx_queues);
+
+	return err;
+}
+
+static void otx2_get_ringparam(struct net_device *netdev,
+			       struct ethtool_ringparam *ring)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+	struct otx2_qset *qs = &pfvf->qset;
+
+	ring->rx_max_pending = Q_COUNT(Q_SIZE_MAX);
+	ring->rx_pending = qs->cqe_cnt;
+	ring->tx_max_pending = Q_COUNT(Q_SIZE_MAX);
+	ring->tx_pending = qs->sqe_cnt;
+}
+
+static int otx2_set_ringparam(struct net_device *netdev,
+			      struct ethtool_ringparam *ring)
+{
+	struct otx2_nic *pfvf = netdev_priv(netdev);
+	bool if_up = netif_running(netdev);
+	struct otx2_qset *qs = &pfvf->qset;
+	u32 rx_count, tx_count;
+	u32 tx_size, rx_size;
+
+	if (ring->rx_mini_pending || ring->rx_jumbo_pending)
+		return -EINVAL;
+
+	if (if_up)
+		otx2_stop(netdev);
+
+	rx_count = clamp_t(u32, ring->rx_pending,
+			   Q_COUNT(Q_SIZE_MIN), Q_COUNT(Q_SIZE_MAX));
+	tx_count = clamp_t(u32, ring->tx_pending,
+			   Q_COUNT(Q_SIZE_MIN), Q_COUNT(Q_SIZE_MAX));
+
+	if (tx_count == qs->sqe_cnt && rx_count == qs->cqe_cnt)
+		return 0;
+
+	/* Permitted lengths are 16 64 256 1K 4K 16K 64K 256K 1M  */
+	tx_size = Q_SIZE(tx_count, 3);
+	rx_size = Q_SIZE(rx_count, 3);
+
+	/* Assigned to the nearest possible exponent. */
+	qs->sqe_cnt = Q_COUNT(tx_size);
+	qs->cqe_cnt = Q_COUNT(rx_size);
+
+	if (if_up)
+		otx2_open(netdev);
+	return 0;
+}
+
+static const struct ethtool_ops otx2_ethtool_ops = {
+	.get_drvinfo		= otx2_get_drvinfo,
+	.get_strings		= otx2_get_strings,
+	.get_ethtool_stats	= otx2_get_ethtool_stats,
+	.get_sset_count		= otx2_get_sset_count,
+	.set_channels		= otx2_set_channels,
+	.get_channels		= otx2_get_channels,
+	.get_ringparam		= otx2_get_ringparam,
+	.set_ringparam		= otx2_set_ringparam,
+};
+
+void otx2_set_ethtool_ops(struct net_device *netdev)
+{
+	netdev->ethtool_ops = &otx2_ethtool_ops;
+}
diff --git a/drivers/net/ethernet/marvell/octeontx2/otx2_pf.c b/drivers/net/ethernet/marvell/octeontx2/otx2_pf.c
index 5ad1e732ac62..fb1b2e9f6b2f 100644
--- a/drivers/net/ethernet/marvell/octeontx2/otx2_pf.c
+++ b/drivers/net/ethernet/marvell/octeontx2/otx2_pf.c
@@ -70,6 +70,9 @@ static void otx2_process_pfaf_mbox_msg(struct otx2_nic *pf,
 		mbox_handler_NIX_TXSCH_ALLOC(pf,
 					     (struct nix_txsch_alloc_rsp *)msg);
 		break;
+	case MBOX_MSG_CGX_STATS:
+		mbox_handler_CGX_STATS(pf, (struct cgx_stats_rsp *)msg);
+		break;
 	default:
 		if (msg->rc)
 			dev_err(pf->dev,
@@ -373,8 +376,8 @@ static int otx2_cgx_config_loopback(struct otx2_nic *pf, bool enable)
 	return otx2_sync_mbox_msg(&pf->mbox);
 }
 
-static int otx2_set_real_num_queues(struct net_device *netdev,
-				    int tx_queues, int rx_queues)
+int otx2_set_real_num_queues(struct net_device *netdev,
+			     int tx_queues, int rx_queues)
 {
 	int err;
 
@@ -568,7 +571,7 @@ static netdev_tx_t otx2_xmit(struct sk_buff *skb, struct net_device *netdev)
 	return NETDEV_TX_OK;
 }
 
-static int otx2_open(struct net_device *netdev)
+int otx2_open(struct net_device *netdev)
 {
 	struct otx2_nic *pf = netdev_priv(netdev);
 	struct otx2_cq_poll *cq_poll = NULL;
@@ -590,6 +593,10 @@ static int otx2_open(struct net_device *netdev)
 	if (!qset->napi)
 		return -ENOMEM;
 
+	qset->cqe_cnt = qset->cqe_cnt ? qset->cqe_cnt : Q_COUNT(Q_SIZE_4K);
+	qset->sqe_cnt = qset->sqe_cnt ? qset->sqe_cnt : Q_COUNT(Q_SIZE_1K);
+
+	err = -ENOMEM;
 	qset->cq = kcalloc(pf->qset.cq_cnt,
 			   sizeof(struct otx2_cq_queue), GFP_KERNEL);
 	if (!qset->cq)
@@ -600,6 +607,11 @@ static int otx2_open(struct net_device *netdev)
 	if (!qset->sq)
 		goto freemem;
 
+	qset->rq = kcalloc(pf->hw.rx_queues,
+			   sizeof(struct otx2_rcv_queue), GFP_KERNEL);
+	if (!qset->rq)
+		goto freemem;
+
 	err = otx2_init_hw_resources(pf);
 	if (err)
 		goto freemem;
@@ -696,7 +708,7 @@ static int otx2_open(struct net_device *netdev)
 	return err;
 }
 
-static int otx2_stop(struct net_device *netdev)
+int otx2_stop(struct net_device *netdev)
 {
 	struct otx2_nic *pf = netdev_priv(netdev);
 	struct otx2_cq_poll *cq_poll = NULL;
@@ -927,6 +939,7 @@ static int otx2_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 		goto err_detach_rsrc;
 	}
 
+	otx2_set_ethtool_ops(netdev);
 	return 0;
 
 err_detach_rsrc:
diff --git a/drivers/net/ethernet/marvell/octeontx2/otx2_txrx.h b/drivers/net/ethernet/marvell/octeontx2/otx2_txrx.h
index 33a93b914555..041e3de2d860 100644
--- a/drivers/net/ethernet/marvell/octeontx2/otx2_txrx.h
+++ b/drivers/net/ethernet/marvell/octeontx2/otx2_txrx.h
@@ -32,6 +32,15 @@
 #define OTX2_MAX_GSO_SEGS	255
 #define OTX2_MAX_FRAGS_IN_SQE	9
 
+struct queue_stats {
+	u64	bytes;
+	u64	pkts;
+};
+
+struct otx2_rcv_queue {
+	struct queue_stats	stats;
+};
+
 struct sg_list {
 	u16	num_segs;
 	u64	skb;
@@ -50,6 +59,7 @@ struct otx2_snd_queue {
 	void			*sqe_base;
 	struct qmem		*sqe;
 	struct sg_list		*sg;
+	struct queue_stats	stats;
 };
 
 struct otx2_cq_poll {
@@ -83,11 +93,14 @@ struct otx2_cq_queue {
 struct otx2_qset {
 #define OTX2_MAX_CQ_CNT		64
 	u16			cq_cnt;
+	u16			cqe_cnt;
+	u16			sqe_cnt;
 	u16			xqe_size;
 	struct otx2_pool	*pool;
 	struct otx2_cq_poll	*napi;
 	struct otx2_cq_queue	*cq;
 	struct otx2_snd_queue	*sq;
+	struct otx2_rcv_queue	*rq;
 };
 
 /* Translate IOVA to physical address */
-- 
2.17.1

