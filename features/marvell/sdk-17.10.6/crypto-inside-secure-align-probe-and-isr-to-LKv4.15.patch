From ffe94229d91e0ebd3b76422f69f74fbd18f8d541 Mon Sep 17 00:00:00 2001
From: Ofer Heifetz <oferh@marvell.com>
Date: Mon, 15 Jan 2018 14:27:08 +0200
Subject: [PATCH 1297/1345] crypto: inside-secure: align probe and isr to
 LKv4.15

commit  84384aa2981f58cea2413b5805218c0718af39e4 from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

this sync includes:
- name change of some functions
- removal of RDR interrupt handling, it is not used
- fixed error case handling in probe

Change-Id: I7b60a6fa6ac720d0e2a0302c7c91f481906110b5
Signed-off-by: Ofer Heifetz <oferh@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/49103
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Reviewed-by: Hanna Hawa <hannah@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/51678
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/crypto/inside-secure/safexcel.c |  107 ++++++++++++-------------------
 drivers/crypto/inside-secure/safexcel.h |   76 +++++++++++-----------
 2 files changed, 78 insertions(+), 105 deletions(-)

diff --git a/drivers/crypto/inside-secure/safexcel.c b/drivers/crypto/inside-secure/safexcel.c
index 74a6133..47c2e3d 100644
--- a/drivers/crypto/inside-secure/safexcel.c
+++ b/drivers/crypto/inside-secure/safexcel.c
@@ -997,12 +997,12 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 }
 
 /* dequeue from Crypto API FIFO and insert requests into HW ring */
-static void safexcel_handle_queued_work(struct work_struct *work)
+static void safexcel_dequeue_work(struct work_struct *work)
 {
-	struct safexcel_work_data *data = container_of(work, struct safexcel_work_data, work);
-	struct safexcel_crypto_priv *priv = data->priv;
+	struct safexcel_work_data *data =
+			container_of(work, struct safexcel_work_data, work);
 
-	safexcel_dequeue(priv, data->ring);
+	safexcel_dequeue(data->priv, data->ring);
 }
 
 struct safexcel_ring_irq_data {
@@ -1010,54 +1010,17 @@ struct safexcel_ring_irq_data {
 	int ring;
 };
 
-/* threaded irq handler that handles all results from a ring */
-static irqreturn_t safexcel_irq_ring_thread_handler(int irq, void *data)
-{
-	struct safexcel_ring_irq_data *irq_data = data;
-	struct safexcel_crypto_priv *priv = irq_data->priv;
-	int ring = irq_data->ring;
-
-	/* handle all ring results */
-	safexcel_handle_result_descriptor(priv, ring);
-
-	/* schedule enqueue worker */
-	queue_work(priv->ring[ring].workqueue,
-		   &priv->ring[ring].work_data.work);
-
-	return IRQ_HANDLED;
-}
-
-/* Ring IRQ handler */
 static irqreturn_t safexcel_irq_ring(int irq, void *data)
 {
 	struct safexcel_ring_irq_data *irq_data = data;
 	struct safexcel_crypto_priv *priv = irq_data->priv;
-	int ring = irq_data->ring;
+	int ring = irq_data->ring, rc = IRQ_NONE;
 	u32 status, stat;
-	int rc = IRQ_NONE;
 
 	status = readl(EIP197_HIA_AIC_R(priv) + EIP197_HIA_AIC_R_ENABLED_STAT(ring));
-
 	if (!status)
 		return rc;
 
-	/* CDR interrupts */
-	if (status & EIP197_CDR_IRQ(ring)) {
-		stat = readl_relaxed(EIP197_HIA_CDR(priv, ring) + EIP197_HIA_xDR_STAT);
-
-		if (unlikely(stat & EIP197_xDR_ERR)) {
-			/*
-			 * Fatal error, the CDR is unusable and must be
-			 * reinitialized. This should not happen under
-			 * normal circumstances.
-			 */
-			dev_err(priv->dev, "CDR: fatal error.");
-		}
-
-		/* ACK the interrupts */
-		writel_relaxed(stat & 0xff, EIP197_HIA_CDR(priv, ring) + EIP197_HIA_xDR_STAT);
-	}
-
 	/* RDR interrupts */
 	if (status & EIP197_RDR_IRQ(ring)) {
 		stat = readl(EIP197_HIA_RDR(priv, ring) + EIP197_HIA_xDR_STAT);
@@ -1069,10 +1032,9 @@ static irqreturn_t safexcel_irq_ring(int irq, void *data)
 			 * normal circumstances.
 			 */
 			dev_err(priv->dev, "RDR: fatal error.");
-		}
-
-		if (stat & EIP197_xDR_THRESH)
+		} else if (likely(stat & EIP197_xDR_THRESH)) {
 			rc = IRQ_WAKE_THREAD;
+		}
 
 		/* ACK the interrupts */
 		writel(stat & 0xff,
@@ -1085,10 +1047,24 @@ static irqreturn_t safexcel_irq_ring(int irq, void *data)
 	return rc;
 }
 
+static irqreturn_t safexcel_irq_ring_thread(int irq, void *data)
+{
+	struct safexcel_ring_irq_data *irq_data = data;
+	struct safexcel_crypto_priv *priv = irq_data->priv;
+	int ring = irq_data->ring;
+
+	safexcel_handle_result_descriptor(priv, ring);
+
+	queue_work(priv->ring[ring].workqueue,
+		   &priv->ring[ring].work_data.work);
+
+	return IRQ_HANDLED;
+}
+
 /* Register ring interrupts */
 static int safexcel_request_ring_irq(struct platform_device *pdev, const char *name,
-				     irq_handler_t irq_handler,
-				     irq_handler_t irq_thread_handler,
+				     irq_handler_t handler,
+				     irq_handler_t threaded_handler,
 				     struct safexcel_ring_irq_data *ring_irq_priv)
 {
 	int ret, irq = platform_get_irq_byname(pdev, name);
@@ -1098,8 +1074,8 @@ static int safexcel_request_ring_irq(struct platform_device *pdev, const char *n
 		return irq;
 	}
 
-	ret = devm_request_threaded_irq(&pdev->dev, irq, irq_handler,
-					irq_thread_handler, IRQF_ONESHOT,
+	ret = devm_request_threaded_irq(&pdev->dev, irq, handler,
+					threaded_handler, IRQF_ONESHOT,
 					dev_name(&pdev->dev), ring_irq_priv);
 	if (ret) {
 		dev_err(&pdev->dev, "unable to request IRQ %d\n", irq);
@@ -1323,13 +1299,12 @@ static int safexcel_probe(struct platform_device *pdev)
 						     &priv->ring[i].cdr,
 						     &priv->ring[i].rdr);
 		if (ret)
-			goto err_pool;
+			goto err_clk;
 
-		ring_irq = devm_kzalloc(dev, sizeof(struct safexcel_ring_irq_data),
-					GFP_KERNEL);
+		ring_irq = devm_kzalloc(dev, sizeof(*ring_irq), GFP_KERNEL);
 		if (!ring_irq) {
 			ret = -ENOMEM;
-			goto err_pool;
+			goto err_clk;
 		}
 
 		ring_irq->priv = priv;
@@ -1337,43 +1312,43 @@ static int safexcel_probe(struct platform_device *pdev)
 
 		snprintf(irq_name, 6, "ring%d", i);
 		irq = safexcel_request_ring_irq(pdev, irq_name, safexcel_irq_ring,
-						safexcel_irq_ring_thread_handler,
+						safexcel_irq_ring_thread,
 						ring_irq);
-
-		if (irq < 0)
-			goto err_pool;
+		if (irq < 0) {
+			ret = irq;
+			goto err_clk;
+		}
 
 		priv->ring[i].work_data.priv = priv;
 		priv->ring[i].work_data.ring = i;
-		INIT_WORK(&priv->ring[i].work_data.work, safexcel_handle_queued_work);
+		INIT_WORK(&priv->ring[i].work_data.work, safexcel_dequeue_work);
 
 		snprintf(wq_name, 9, "wq_ring%d", i);
 		priv->ring[i].workqueue = create_singlethread_workqueue(wq_name);
 		if (!priv->ring[i].workqueue) {
 			ret = -ENOMEM;
-			goto err_pool;
+			goto err_clk;
 		}
 
 		priv->ring[i].egress_cnt = 0;
 		priv->ring[i].busy = 0;
 
-		priv->ring[i].req = NULL;
-		priv->ring[i].backlog = NULL;
+		crypto_init_queue(&priv->ring[i].queue,
+				  EIP197_DEFAULT_RING_SIZE);
 
 		INIT_LIST_HEAD(&priv->ring[i].list);
 		spin_lock_init(&priv->ring[i].lock);
 		spin_lock_init(&priv->ring[i].egress_lock);
 		spin_lock_init(&priv->ring[i].queue_lock);
-		crypto_init_queue(&priv->ring[i].queue, EIP197_DEFAULT_RING_SIZE);
 	}
-	atomic_set(&priv->ring_used, 0);
 
 	platform_set_drvdata(pdev, priv);
+	atomic_set(&priv->ring_used, 0);
 
 	ret = safexcel_hw_init(priv);
 	if (ret) {
 		dev_err(priv->dev, "EIP h/w init failed (%d)\n", ret);
-		goto err_pool;
+		goto err_clk;
 	}
 
 	/*
@@ -1389,14 +1364,12 @@ static int safexcel_probe(struct platform_device *pdev)
 		ret = safexcel_register_algorithms(priv);
 		if (ret) {
 			dev_err(dev, "Failed to register algorithms (%d)\n", ret);
-			goto err_pool;
+			goto err_clk;
 		}
 	}
 
 	return 0;
 
-err_pool:
-	dmam_pool_destroy(priv->context_pool);
 err_clk:
 	clk_disable_unprepare(priv->clk);
 	return ret;
diff --git a/drivers/crypto/inside-secure/safexcel.h b/drivers/crypto/inside-secure/safexcel.h
index 7df628e..c34a589 100644
--- a/drivers/crypto/inside-secure/safexcel.h
+++ b/drivers/crypto/inside-secure/safexcel.h
@@ -241,53 +241,53 @@
 #define EIP197_PE_ICE_RAM_CTRL_FPP_PROG_EN		BIT(1)
 
 /* EIP197_HIA_xDR_DESC_SIZE */
-#define EIP197_xDR_DESC_MODE_64BIT			BIT(31)
-#define EIP197_xDR_DESC_CD_OFFSET			16
+#define EIP197_xDR_DESC_MODE_64BIT		BIT(31)
+#define EIP197_xDR_DESC_CD_OFFSET		16
 
 /* EIP197_DIA_xDR_CFG */
-#define EIP197_XDR_CD_FETCH_THRESH			16
+#define EIP197_XDR_CD_FETCH_THRESH		16
 
 /* EIP197_HIA_xDR_DMA_CFG */
-#define EIP197_HIA_xDR_WR_RES_BUF			BIT(22)
-#define EIP197_HIA_xDR_WR_CTRL_BUF			BIT(23)
-#define EIP197_HIA_xDR_WR_OWN_BUF			BIT(24)
-#define EIP197_HIA_xDR_CFG_xD_PROT(n)			(((n) & 0xf) << 4)
-#define EIP197_HIA_xDR_CFG_DATA_PROT(n)			(((n) & 0xf) << 12)
-#define EIP197_HIA_xDR_CFG_ACD_PROT(n)			(((n) & 0xf) << 20)
-#define EIP197_HIA_xDR_CFG_WR_CACHE(n)			(((n) & 0x7) << 25)
-#define EIP197_HIA_xDR_CFG_RD_CACHE(n)			(((n) & 0x7) << 29)
+#define EIP197_HIA_xDR_WR_RES_BUF		BIT(22)
+#define EIP197_HIA_xDR_WR_CTRL_BUF		BIT(23)
+#define EIP197_HIA_xDR_WR_OWN_BUF		BIT(24)
+#define EIP197_HIA_xDR_CFG_xD_PROT(n)		(((n) & 0xf) << 4)
+#define EIP197_HIA_xDR_CFG_DATA_PROT(n)		(((n) & 0xf) << 12)
+#define EIP197_HIA_xDR_CFG_ACD_PROT(n)		(((n) & 0xf) << 20)
+#define EIP197_HIA_xDR_CFG_WR_CACHE(n)		(((n) & 0x7) << 25)
+#define EIP197_HIA_xDR_CFG_RD_CACHE(n)		(((n) & 0x7) << 29)
 
 /* EIP197_HIA_CDR_THRESH */
-#define EIP197_HIA_CDR_THRESH_PROC_PKT(n)		((n) << 0)
-#define EIP197_HIA_CDR_THRESH_PROC_MODE			BIT(22)
-#define EIP197_HIA_CDR_THRESH_PKT_MODE			BIT(23)
-#define EIP197_HIA_CDR_THRESH_TIMEOUT(n)		((n) << 24) /* x256 clk cycles */
+#define EIP197_HIA_CDR_THRESH_PROC_PKT(n)	(n)
+#define EIP197_HIA_CDR_THRESH_PROC_MODE		BIT(22)
+#define EIP197_HIA_CDR_THRESH_PKT_MODE		BIT(23)
+#define EIP197_HIA_CDR_THRESH_TIMEOUT(n)	((n) << 24) /* x256 clk cycles */
 
 /* EIP197_HIA_RDR_THRESH */
-#define EIP197_HIA_RDR_THRESH_PROC_PKT(n)		(GENMASK(15, 0) & (n))
-#define EIP197_HIA_RDR_THRESH_PKT_MODE			BIT(23)
-#define EIP197_HIA_RDR_THRESH_TIMEOUT(n)		((n) << 24) /* x256 clk cycles */
+#define EIP197_HIA_RDR_THRESH_PROC_PKT(n)	(GENMASK(15, 0) & (n))
+#define EIP197_HIA_RDR_THRESH_PKT_MODE		BIT(23)
+#define EIP197_HIA_RDR_THRESH_TIMEOUT(n)	((n) << 24) /* x256 clk cycles */
 
 /* EIP197_HIA_xDR_PREP_COUNT */
-#define EIP197_xDR_PREP_CLR_COUNT			BIT(31)
+#define EIP197_xDR_PREP_CLR_COUNT		BIT(31)
 #define EIP197_xDR_PREP_xD_COUNT_INCR_OFFSET		2
 #define EIP197_xDR_PREP_RD_COUNT_INCR_MASK		(GENMASK(14, 0))
 
 /* EIP197_HIA_xDR_PROC_COUNT */
-#define EIP197_xDR_PROC_xD_PKT_OFFSET			24
-#define EIP197_xDR_PROC_xD_PKT_MASK			(GENMASK(6, 0))
-#define EIP197_xDR_PROC_xD_COUNT(n)			((n) << 2)
-#define EIP197_xDR_PROC_xD_PKT(n)			((n) << EIP197_xDR_PROC_xD_PKT_OFFSET)
-#define EIP197_xDR_PROC_CLR_COUNT			BIT(31)
+#define EIP197_xDR_PROC_xD_PKT_OFFSET		24
+#define EIP197_xDR_PROC_xD_PKT_MASK		GENMASK(6, 0)
+#define EIP197_xDR_PROC_xD_COUNT(n)		((n) << 2)
+#define EIP197_xDR_PROC_xD_PKT(n)		((n) << 24)
+#define EIP197_xDR_PROC_CLR_COUNT		BIT(31)
 
 /* EIP197_HIA_xDR_STAT */
-#define EIP197_xDR_DMA_ERR				BIT(0)
-#define EIP197_xDR_PREP_CMD_THRES			BIT(1)
-#define EIP197_xDR_ERR					BIT(2)
-#define EIP197_xDR_THRESH				BIT(4)
-#define EIP197_xDR_TIMEOUT				BIT(5)
-#define EIP197_CDR_INTR_MASK				(GENMASK(5, 0))
-#define EIP197_RDR_INTR_MASK				(GENMASK(7, 0))
+#define EIP197_xDR_DMA_ERR			BIT(0)
+#define EIP197_xDR_PREP_CMD_THRES		BIT(1)
+#define EIP197_xDR_ERR				BIT(2)
+#define EIP197_xDR_THRESH			BIT(4)
+#define EIP197_xDR_TIMEOUT			BIT(5)
+#define EIP197_CDR_INTR_MASK		GENMASK(5, 0)
+#define EIP197_RDR_INTR_MASK		GENMASK(7, 0)
 
 #define EIP197_HIA_RA_PE_CTRL_RESET			BIT(31)
 #define EIP197_HIA_RA_PE_CTRL_EN			BIT(30)
@@ -295,15 +295,15 @@
 /* Register offsets */
 
 /* EIP197_HIA_DSE_THR_STAT */
-#define EIP197_DSE_THR_RDR_ID_MASK		(GENMASK(15, 12))
+#define EIP197_DSE_THR_RDR_ID_MASK		GENMASK(15, 12)
 
 /* EIP197_HIA_OPTIONS */
 #define EIP197_xDR_HDW_OFFSET			25
-#define EIP197_xDR_HDW_MASK			(GENMASK(27, 25))
-#define EIP197_N_RINGS_MASK			(GENMASK(3, 0))
+#define EIP197_xDR_HDW_MASK			GENMASK(27, 25)
+#define EIP197_N_RINGS_MASK			GENMASK(3, 0)
 #define EIP197_N_PES_OFFSET			4
-#define EIP197_N_PES_MASK			(GENMASK(4, 0))
-#define EIP97_N_PES_MASK			(GENMASK(2, 0))
+#define EIP197_N_PES_MASK			GENMASK(4, 0)
+#define EIP97_N_PES_MASK			GENMASK(2, 0)
 
 /* EIP197_HIA_AIC_R_ENABLE_CTRL */
 #define EIP197_CDR_IRQ(n)			BIT((n) * 2)
@@ -508,8 +508,8 @@ struct safexcel_control_data_desc {
 #define EIP197_OPTION_MAGIC_VALUE	BIT(0)
 #define EIP197_OPTION_64BIT_CTX		BIT(1)
 #define EIP197_OPTION_CTX_CTRL_IN_CMD	BIT(8)
-#define EIP197_OPTION_4_TOKEN_IV_CMD	(GENMASK(11, 9))
-#define EIP197_OPTION_2_TOKEN_IV_CMD	(GENMASK(11, 10))
+#define EIP197_OPTION_4_TOKEN_IV_CMD	GENMASK(11, 9)
+#define EIP197_OPTION_2_TOKEN_IV_CMD	GENMASK(11, 10)
 #define EIP197_TYPE_EXTENDED		0x3
 
 /* Basic Command Descriptor format */
-- 
1.7.9.5

