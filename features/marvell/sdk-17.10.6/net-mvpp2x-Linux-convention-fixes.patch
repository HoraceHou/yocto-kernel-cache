From 04d2c201c2f5196433c5cd87059af5037694f81e Mon Sep 17 00:00:00 2001
From: Stefan Chulski <stefanc@marvell.com>
Date: Wed, 7 Dec 2016 13:08:59 +0200
Subject: [PATCH 0639/1345] net: mvpp2x: Linux convention fixes

commit  0c208db94b25adf95fbac3ba711adbc3e9b65f73 from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

- Linux convention fixes, no functionality changes

Change-Id: Ie2f4d183e301f868479c81ffa047716c6aca1a6e
Signed-off-by: Stefan Chulski <stefanc@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/34441
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Hanna Hawa <hannah@marvell.com>
Reviewed-by: Omri Itach <omrii@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.c |   49 +--
 drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.h |   14 +-
 .../ethernet/marvell/mvpp2x/mv_gop110_hw_type.h    |    1 -
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h      |   21 +-
 .../net/ethernet/marvell/mvpp2x/mv_pp2x_debug.c    |    2 +-
 .../net/ethernet/marvell/mvpp2x/mv_pp2x_ethtool.c  |   65 ++-
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.c   |  361 ++++++++---------
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.h   |  117 +++---
 .../net/ethernet/marvell/mvpp2x/mv_pp2x_hw_type.h  |  120 +++---
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c |  428 +++++++++-----------
 10 files changed, 536 insertions(+), 642 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.c b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.c
index 9c3c448..dde8f80 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.c
@@ -40,7 +40,6 @@ void mv_gop110_register_bases_dump(struct gop_hw *gop)
 	pr_info("  %-32s: 0x%p\n", "XPCS", gop->gop_110.xpcs_base);
 	pr_info("  %-32s: 0x%p\n", "PTP", gop->gop_110.ptp.base);
 	pr_info("  %-32s: 0x%p\n", "RFU1", gop->gop_110.rfu1_base);
-
 }
 EXPORT_SYMBOL(mv_gop110_register_bases_dump);
 
@@ -494,9 +493,9 @@ int mv_gop110_gmac_link_status(struct gop_hw *gop, int mac_num,
 			pstatus->autoneg_fc = MV_PORT_FC_AN_ASYM;
 		else
 			pstatus->autoneg_fc = MV_PORT_FC_AN_SYM;
-		}
-	else
+	} else {
 		pstatus->autoneg_fc = MV_PORT_FC_AN_NO;
+	}
 
 	return 0;
 }
@@ -1195,7 +1194,7 @@ bool mv_gop110_port_autoneg_status(struct gop_hw *gop, struct mv_mac_data *mac)
 		reg_val = mv_gop110_gmac_read(gop, mac->gop_index, MV_GMAC_PORT_AUTO_NEG_CFG_REG);
 
 		if (reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_FDX_AN_OFFS &&
-			reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK)
+		    reg_val & MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK)
 			return true;
 		else
 			return false;
@@ -1216,7 +1215,7 @@ void mv_gop110_gmac_set_autoneg(struct gop_hw *gop, struct mv_mac_data *mac, boo
 	int mac_num = mac->gop_index;
 
 	reg_val = mv_gop110_gmac_read(gop, mac_num,
-				MV_GMAC_PORT_AUTO_NEG_CFG_REG);
+				      MV_GMAC_PORT_AUTO_NEG_CFG_REG);
 
 	if (auto_neg) {
 		reg_val |= MV_GMAC_PORT_AUTO_NEG_CFG_EN_AN_SPEED_MASK;
@@ -1229,10 +1228,9 @@ void mv_gop110_gmac_set_autoneg(struct gop_hw *gop, struct mv_mac_data *mac, boo
 		}
 
 	mv_gop110_gmac_write(gop, mac_num,
-				MV_GMAC_PORT_AUTO_NEG_CFG_REG, reg_val);
+			     MV_GMAC_PORT_AUTO_NEG_CFG_REG, reg_val);
 }
 
-
 int mv_gop110_port_regs(struct gop_hw *gop, struct mv_mac_data *mac)
 {
 	int port_num = mac->gop_index;
@@ -2355,12 +2353,12 @@ int mv_gop110_mpcs_mode(struct gop_hw *gop)
 	reg_addr = PCS_CLOCK_RESET;
 	val = mv_gop110_mpcs_global_read(gop, reg_addr);
 	U32_SET_FIELD(val, CLK_DIVISION_RATIO_MASK,
-			1 << CLK_DIVISION_RATIO_OFFSET);
+		      1 << CLK_DIVISION_RATIO_OFFSET);
 
 	mv_gop110_mpcs_global_write(gop, reg_addr, val);
 
 	U32_SET_FIELD(val, CLK_DIV_PHASE_SET_MASK,
-			0 << CLK_DIV_PHASE_SET_OFFSET);
+		      0 << CLK_DIV_PHASE_SET_OFFSET);
 	U32_SET_FIELD(val, MAC_CLK_RESET_MASK, 1 << MAC_CLK_RESET_OFFSET);
 	U32_SET_FIELD(val, RX_SD_CLK_RESET_MASK, 1 << RX_SD_CLK_RESET_OFFSET);
 	U32_SET_FIELD(val, TX_SD_CLK_RESET_MASK, 1 << TX_SD_CLK_RESET_OFFSET);
@@ -2390,7 +2388,6 @@ void mv_gop110_mpcs_clock_reset(struct gop_hw *gop, enum mv_reset reset)
 	mv_gop110_mpcs_global_write(gop, reg_addr, val);
 }
 
-
 u64 mv_gop110_mib_read64(struct gop_hw *gop, int port, unsigned int offset)
 {
 	u64 val, val2;
@@ -2486,7 +2483,6 @@ void mv_gop110_mib_counters_show(struct gop_hw *gop, int port)
 
 void mv_gop110_mib_counters_stat_update(struct gop_hw *gop, int port, struct gop_stat *gop_statistics)
 {
-
 	u64 val;
 
 	gop_statistics->rx_byte += mv_gop110_mib_read64(gop, port,
@@ -2564,7 +2560,6 @@ void mv_gop110_mib_counters_stat_update(struct gop_hw *gop, int port, struct gop
 							MV_MIB_LATE_COLLISION);
 }
 
-
 void mv_gop110_netc_active_port(struct gop_hw *gop, u32 port, u32 val)
 {
 	u32 reg;
@@ -2625,8 +2620,6 @@ static void mv_gop110_netc_rxaui1_enable(struct gop_hw *gop, u32 port, u32 val)
 	mv_gop110_rfu1_write(gop, SD1_CONTROL_1_REG, reg);
 }
 
-
-
 static void mv_gop110_netc_mii_mode(struct gop_hw *gop, u32 port, u32 val)
 {
 	u32 reg;
@@ -2642,8 +2635,6 @@ static void mv_gop110_netc_mii_mode(struct gop_hw *gop, u32 port, u32 val)
 	mv_gop110_rfu1_write(gop, MV_NETCOMP_CONTROL_0, reg);
 }
 
-
-
 static void mv_gop110_netc_gop_reset(struct gop_hw *gop, u32 val)
 {
 	u32 reg;
@@ -2690,7 +2681,7 @@ static void mv_gop110_netc_port_rf_reset(struct gop_hw *gop, u32 port, u32 val)
 }
 
 static void mv_gop110_netc_gbe_sgmii_mode_select(struct gop_hw *gop, u32 port,
-						u32 val)
+						 u32 val)
 {
 	u32 reg, mask, offset;
 
@@ -2751,7 +2742,7 @@ static void mv_gop110_netc_mac_to_xgmii(struct gop_hw *gop, u32 port,
 		mv_gop110_netc_bus_width_select(gop, 1);
 		/* Select RGMII mode */
 		mv_gop110_netc_gbe_sgmii_mode_select(gop, port,
-							MV_NETC_GBE_XMII);
+						     MV_NETC_GBE_XMII);
 		break;
 	case MV_NETC_SECOND_PHASE:
 		/* De-assert the relevant port HB reset */
@@ -2770,7 +2761,7 @@ static void mv_gop110_netc_mac_to_sgmii(struct gop_hw *gop, u32 port,
 		/* Select SGMII mode */
 		if (port >= 1)
 			mv_gop110_netc_gbe_sgmii_mode_select(gop, port,
-			MV_NETC_GBE_SGMII);
+							     MV_NETC_GBE_SGMII);
 
 		/* Configure the sample stages */
 		mv_gop110_netc_sample_stages_timing(gop, 0);
@@ -2808,7 +2799,7 @@ static void mv_gop110_netc_mac_to_rxaui(struct gop_hw *gop, u32 port,
 }
 
 static void mv_gop110_netc_mac_to_xaui(struct gop_hw *gop, u32 port,
-					enum mv_netc_phase phase)
+				       enum mv_netc_phase phase)
 {
 	switch (phase) {
 	case MV_NETC_FIRST_PHASE:
@@ -2822,7 +2813,6 @@ static void mv_gop110_netc_mac_to_xaui(struct gop_hw *gop, u32 port,
 	}
 }
 
-
 int mv_gop110_netc_init(struct gop_hw *gop,
 			u32 net_comp_config, enum mv_netc_phase phase)
 {
@@ -2841,9 +2831,9 @@ int mv_gop110_netc_init(struct gop_hw *gop,
 		mv_gop110_netc_mac_to_sgmii(gop, 2, phase);
 	else
 		mv_gop110_netc_mac_to_xgmii(gop, 2, phase);
-	if (c & MV_NETC_GE_MAC3_SGMII)
+	if (c & MV_NETC_GE_MAC3_SGMII) {
 		mv_gop110_netc_mac_to_sgmii(gop, 3, phase);
-	else {
+	} else {
 		mv_gop110_netc_mac_to_xgmii(gop, 3, phase);
 		if (c & MV_NETC_GE_MAC3_RGMII)
 			mv_gop110_netc_mii_mode(gop, 3, MV_NETC_GBE_RGMII);
@@ -2867,7 +2857,6 @@ int mv_gop110_netc_init(struct gop_hw *gop,
 
 void mv_gop110_netc_xon_set(struct gop_hw *gop, enum mv_gop_port port, bool en)
 {
-
 	u32 reg;
 
 	reg = mv_gop110_rfu1_read(gop, MV_NETCOMP_PORTS_CONTROL_0);
@@ -2891,7 +2880,6 @@ void mv_gop110_netc_xon_set(struct gop_hw *gop, enum mv_gop_port port, bool en)
 	}
 
 	mv_gop110_rfu1_write(gop, MV_NETCOMP_PORTS_CONTROL_0, reg);
-
 }
 EXPORT_SYMBOL(mv_gop110_netc_xon_set);
 
@@ -2902,9 +2890,9 @@ void mv_gop110_fca_send_periodic(struct gop_hw *gop, int mac_num, bool en)
 	val = mv_gop110_fca_read(gop, mac_num, FCA_CONTROL_REG);
 
 	U32_SET_FIELD(val, FCA_PORT_TYPE_MASK,
-			      FCA_PORT_TYPE_B << FCA_PORT_TYPE_OFFSET);
+		      FCA_PORT_TYPE_B << FCA_PORT_TYPE_OFFSET);
 	U32_SET_FIELD(val, FCA_SEND_PERIODIC_MASK,
-			      en << FCA_SEND_PERIODIC_OFFSET);
+		      en << FCA_SEND_PERIODIC_OFFSET);
 	mv_gop110_fca_write(gop, mac_num, FCA_CONTROL_REG, val);
 }
 
@@ -2915,7 +2903,7 @@ void mv_gop110_fca_enable_periodic(struct gop_hw *gop, int mac_num, bool en)
 	val = mv_gop110_fca_read(gop, mac_num, FCA_CONTROL_REG);
 
 	U32_SET_FIELD(val, FCA_ENABLE_PERIODIC_MASK,
-			      en << FCA_ENABLE_PERIODIC_OFFSET);
+		      en << FCA_ENABLE_PERIODIC_OFFSET);
 	mv_gop110_fca_write(gop, mac_num, FCA_CONTROL_REG, val);
 }
 
@@ -2949,13 +2937,12 @@ void mv_gop110_fca_tx_enable(struct gop_hw *gop, int mac_num, bool en)
 	val = mv_gop110_fca_read(gop, mac_num, FCA_CONTROL_REG);
 
 	U32_SET_FIELD(val, FCA_PORT_TYPE_MASK,
-			      FCA_PORT_TYPE_B << FCA_PORT_TYPE_OFFSET);
+		      FCA_PORT_TYPE_B << FCA_PORT_TYPE_OFFSET);
 	U32_SET_FIELD(val, FCA_BYPASS_MASK,
-			      en << FCA_BYPASS_OFFSET);
+		      en << FCA_BYPASS_OFFSET);
 	mv_gop110_fca_write(gop, mac_num, FCA_CONTROL_REG, val);
 }
 
-
 bool mv_gop110_check_fca_tx_state(struct gop_hw *gop, int mac_num)
 {
 	int val;
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.h b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.h
index cd7a27d..d77be0e 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw.h
@@ -245,14 +245,14 @@ static inline u32 mv_gop110_xlg_mac_read(struct gop_hw *gop, int mac_num,
 					 u32 offset)
 {
 	return(mv_gop_gen_read(gop->gop_110.xlg_mac.base,
-	       mac_num * gop->gop_110.xlg_mac.obj_size + offset));
+			       mac_num * gop->gop_110.xlg_mac.obj_size + offset));
 }
 
 static inline void mv_gop110_xlg_mac_write(struct gop_hw *gop, int mac_num,
 					   u32 offset, u32 data)
 {
 	mv_gop_gen_write(gop->gop_110.xlg_mac.base,
-		mac_num * gop->gop_110.xlg_mac.obj_size + offset, data);
+			 mac_num * gop->gop_110.xlg_mac.obj_size + offset, data);
 }
 
 static inline void mv_gop110_xlg_mac_print(struct gop_hw *gop, char *reg_name,
@@ -267,7 +267,7 @@ static inline u32 mv_gop110_xmib_mac_read(struct gop_hw *gop, int mac_num,
 					  u32 offset)
 {
 	return(mv_gop_gen_read(gop->gop_110.xmib.base,
-	       mac_num * gop->gop_110.xmib.obj_size + offset));
+			       mac_num * gop->gop_110.xmib.obj_size + offset));
 }
 
 static inline void mv_gop110_xmib_mac_write(struct gop_hw *gop, int mac_num,
@@ -330,7 +330,7 @@ static inline u32 mv_gop110_gmac_read(struct gop_hw *gop, int mac_num,
 				      u32 offset)
 {
 	return(mv_gop_gen_read(gop->gop_110.gmac.base,
-	       mac_num * gop->gop_110.gmac.obj_size + offset));
+			       mac_num * gop->gop_110.gmac.obj_size + offset));
 }
 
 static inline void mv_gop110_gmac_write(struct gop_hw *gop, int mac_num,
@@ -411,13 +411,15 @@ static inline u32 mv_gop110_rfu1_read(struct gop_hw *gop, u32 offset)
 {
 	return mv_gop_gen_read(gop->gop_110.rfu1_base, offset);
 }
+
 static inline void mv_gop110_rfu1_write(struct gop_hw *gop, u32 offset,
-		u32 data)
+					u32 data)
 {
 	mv_gop_gen_write(gop->gop_110.rfu1_base, offset, data);
 }
+
 static inline void mv_gop110_rfu1_print(struct gop_hw *gop, char *reg_name,
-		u32 reg)
+					u32 reg)
 {
 	pr_info("  %-32s: 0x%x = 0x%08x\n", reg_name, reg,
 		mv_gop110_rfu1_read(gop, reg));
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw_type.h b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw_type.h
index 542ef9e..f30f7d2 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw_type.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_gop110_hw_type.h
@@ -1847,7 +1847,6 @@
 #define MV_MIB_COLLISION			0x78
 #define MV_MIB_LATE_COLLISION			0x7c
 
-
 /******************************************************************************/
 /* System Soft Reset 1 */
 #define MV_GOP_SOFT_RESET_1_REG		0x8
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
index ec6a312..27a6bd3 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
@@ -84,7 +84,6 @@
 
 #define SRAM_BIT_TO_BYTE(_bit_) HW_BYTE_OFFS((_bit_) / 8)
 
-
 #define TCAM_DATA_BYTE_OFFS_LE(_offs_)		(((_offs_) - \
 	((_offs_) % 2)) * 2 + ((_offs_) % 2))
 #define TCAM_DATA_MASK_OFFS_LE(_offs_) (((_offs_) * 2) - ((_offs_) % 2)  + 2)
@@ -106,16 +105,14 @@
 #define __FILENAME__ (strrchr(__FILE__, '/') ? \
 	strrchr(__FILE__, '/') + 1 : __FILE__)
 
-
 #ifdef MVPP2_VERBOSE
 #define MVPP2_PRINT_LINE() \
 	pr_info("Passed: %s(%d)\n", __func__, __LINE__)
 
 #define MVPP2_PRINT_VAR(var) \
-	pr_info("%s(%d): "#var"=0x%lx\n", __func__, __LINE__,\
-		(u64)var)
+	pr_info("%s (%d): " #var "=0x%lx\n", __func__, __LINE__, (u64)var)
 #define MVPP2_PRINT_VAR_NAME(var, name) \
-	pr_info("%s(%d): %s=0x%lx\n", __func__, __LINE__, name, var)
+	pr_info("%s (%d): %s = 0x%lx\n", __func__, __LINE__, name, var)
 #else
 #define MVPP2_PRINT_LINE()
 #define MVPP2_PRINT_VAR(var)
@@ -161,7 +158,6 @@
 #define RX_TRUE_SIZE(total_size)	roundup_pow_of_two(total_size)
 extern  u32 debug_param;
 
-
 /* Convert cpu_id to sw_thread_id */
 #define QV_THR_2_CPU(sw_thread_id)	(sw_thread_id - first_addr_space)
 #define QV_CPU_2_THR(cpu_id)		(first_addr_space + cpu_id)
@@ -270,11 +266,10 @@ struct mv_mac_data {
 #define MV_EMAC_F_SGMII2_5_BIT	2
 #define MV_EMAC_F_PORT_UP_BIT	3
 
-#define MV_EMAC_F_LINK_UP	(1 << MV_EMAC_F_LINK_UP_BIT)
-#define MV_EMAC_F_INIT		(1 << MV_EMAC_F_INIT_BIT)
-#define MV_EMAC_F_SGMII2_5	(1 << MV_EMAC_F_SGMII2_5_BIT)
-#define MV_EMAC_F_PORT_UP	(1 << MV_EMAC_F_PORT_UP_BIT)
-
+#define MV_EMAC_F_LINK_UP	BIT(MV_EMAC_F_LINK_UP_BIT)
+#define MV_EMAC_F_INIT		BIT(MV_EMAC_F_INIT_BIT)
+#define MV_EMAC_F_SGMII2_5	BIT(MV_EMAC_F_SGMII2_5_BIT)
+#define MV_EMAC_F_PORT_UP	BIT(MV_EMAC_F_PORT_UP_BIT)
 
 #define MVPP2_NO_LINK_IRQ	0
 
@@ -778,11 +773,11 @@ struct mv_pp2x_pool_attributes {
 char *mv_pp2x_pool_description_get(enum mv_pp2x_bm_pool_log_num  log_id);
 
 void mv_pp2x_bm_bufs_free(struct device *dev, struct mv_pp2x *priv,
-			struct mv_pp2x_bm_pool *bm_pool, int buf_num);
+			  struct mv_pp2x_bm_pool *bm_pool, int buf_num);
 int mv_pp2x_bm_bufs_add(struct mv_pp2x_port *port,
 			struct mv_pp2x_bm_pool *bm_pool, int buf_num);
 int mv_pp2x_bm_pool_ext_add(struct device *dev, struct mv_pp2x *priv,
-			u32 *pool_num, u32 pkt_size);
+			    u32 *pool_num, u32 pkt_size);
 int mv_pp2x_bm_pool_destroy(struct device *dev, struct mv_pp2x *priv,
 			    struct mv_pp2x_bm_pool *bm_pool);
 int mv_pp2x_swf_bm_pool_assign(struct mv_pp2x_port *port, u32 rxq,
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_debug.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_debug.c
index e4b5151..83cfb1d 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_debug.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_debug.c
@@ -54,7 +54,7 @@ void mv_pp2x_skb_dump(struct sk_buff *skb, int size, int access)
 
 	if ((access != 4) && (access != 2) && (access != 1)) {
 		pr_err("%d wrong access size. Access must be 1 or 2 or 4\n",
-				access);
+		       access);
 		return;
 	}
 	mem_addr = round_down((uintptr_t)addr, 4);
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_ethtool.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_ethtool.c
index ffa7427..542d1de 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_ethtool.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_ethtool.c
@@ -70,7 +70,7 @@
 };
 
 int mv_pp2x_check_speed_duplex_valid(struct ethtool_cmd *cmd,
-					struct mv_port_link_status *pstatus)
+				     struct mv_port_link_status *pstatus)
 {
 	switch (cmd->duplex) {
 	case DUPLEX_FULL:
@@ -80,9 +80,9 @@ int mv_pp2x_check_speed_duplex_valid(struct ethtool_cmd *cmd,
 		pstatus->duplex = MV_PORT_DUPLEX_HALF;
 		break;
 	case DUPLEX_UNKNOWN:
-		if (cmd->speed == SPEED_1000)
+		if (cmd->speed == SPEED_1000) {
 			pstatus->duplex = MV_PORT_DUPLEX_FULL;
-		else {
+		} else {
 			pstatus->duplex = MV_PORT_DUPLEX_FULL;
 			pr_err("Unknown duplex configuration, full duplex set\n");
 		}
@@ -112,9 +112,8 @@ int mv_pp2x_check_speed_duplex_valid(struct ethtool_cmd *cmd,
 }
 
 int mv_pp2x_autoneg_gmac_check_valid(struct mv_mac_data *mac, struct gop_hw *gop,
-			struct ethtool_cmd *cmd, struct mv_port_link_status *pstatus)
+				     struct ethtool_cmd *cmd, struct mv_port_link_status *pstatus)
 {
-
 	int port_num = mac->gop_index;
 	int err;
 
@@ -137,7 +136,6 @@ int mv_pp2x_autoneg_gmac_check_valid(struct mv_mac_data *mac, struct gop_hw *gop
 
 int mv_pp2x_autoneg_xlg_check_valid(struct mv_mac_data *mac, struct ethtool_cmd *cmd)
 {
-
 	int port_num = mac->gop_index;
 
 	if (cmd->autoneg) {
@@ -149,30 +147,30 @@ int mv_pp2x_autoneg_xlg_check_valid(struct mv_mac_data *mac, struct ethtool_cmd
 }
 
 void mv_pp2x_ethtool_valid_coalesce(struct ethtool_coalesce *c,
-				struct mv_pp2x_port *port)
+				    struct mv_pp2x_port *port)
 {
 	u64 val;
 
 	if (c->rx_max_coalesced_frames > MVPP2_MAX_OCCUPIED_THRESH)
 		pr_err("RX coalesced frames value too high, rounded to %d\n",
-			MVPP2_MAX_OCCUPIED_THRESH);
+		       MVPP2_MAX_OCCUPIED_THRESH);
 
 	if (c->tx_max_coalesced_frames > MVPP2_MAX_TRANSMITTED_THRESH) {
 		pr_err("TX coalesced frames value too high, rounded to %d\n",
-			MVPP2_MAX_TRANSMITTED_THRESH);
+		       MVPP2_MAX_TRANSMITTED_THRESH);
 		c->tx_max_coalesced_frames = MVPP2_MAX_TRANSMITTED_THRESH;
 	}
 
 	val = (port->priv->hw.tclk / USEC_PER_SEC) * c->rx_coalesce_usecs;
 	if (val > MVPP2_MAX_ISR_RX_THRESHOLD)
 		pr_err("RX coalesced time value too high, rounded to %ld usecs\n",
-			(MVPP2_MAX_ISR_RX_THRESHOLD * USEC_PER_SEC)
+		       (MVPP2_MAX_ISR_RX_THRESHOLD * USEC_PER_SEC)
 			/ port->priv->hw.tclk);
 
 	val = (port->priv->hw.tclk / USEC_PER_SEC) * c->tx_coalesce_usecs;
 	if (val > MVPP22_MAX_ISR_TX_THRESHOLD) {
 		pr_err("TX coalesced time value too high, rounded to %ld usecs\n",
-			(MVPP22_MAX_ISR_TX_THRESHOLD * USEC_PER_SEC)
+		       (MVPP22_MAX_ISR_TX_THRESHOLD * USEC_PER_SEC)
 			/ port->priv->hw.tclk);
 		c->tx_coalesce_usecs =
 			(MVPP22_MAX_ISR_TX_THRESHOLD * USEC_PER_SEC)
@@ -184,9 +182,8 @@ void mv_pp2x_ethtool_valid_coalesce(struct ethtool_coalesce *c,
 
 /* Ethtool statistic */
 static void mv_pp2x_eth_tool_get_ethtool_stats(struct net_device *dev,
-	struct ethtool_stats *stats, u64 *data)
+					       struct ethtool_stats *stats, u64 *data)
 {
-
 	struct mv_pp2x_port *port = netdev_priv(dev);
 	struct mv_mac_data *mac = &port->mac_data;
 	struct gop_hw *gop = &port->priv->hw.gop;
@@ -224,13 +221,11 @@ static void mv_pp2x_eth_tool_get_ethtool_stats(struct net_device *dev,
 	data[i++] = gop_statistics->tx_crc_sent;
 	data[i++] = gop_statistics->collision;
 	data[i++] = gop_statistics->late_collision;
-
 }
 
 static void mv_pp2x_eth_tool_get_strings(struct net_device *dev,
-					u32 stringset, u8 *data)
+					 u32 stringset, u8 *data)
 {
-
 	switch (stringset) {
 	case ETH_SS_TEST:
 		memcpy(data, *mv_pp2x_gstrings_test, sizeof(mv_pp2x_gstrings_test));
@@ -241,12 +236,10 @@ static void mv_pp2x_eth_tool_get_strings(struct net_device *dev,
 	default:
 		break;
 		}
-
 }
 
 static int mv_pp2x_eth_tool_get_sset_count(struct net_device *dev, int sset)
 {
-
 	switch (sset) {
 	case ETH_SS_TEST:
 		return MV_PP2_TEST_LEN;
@@ -255,7 +248,6 @@ static int mv_pp2x_eth_tool_get_sset_count(struct net_device *dev, int sset)
 	default:
 		return -EOPNOTSUPP;
 	}
-
 }
 
 /* Restart autonegotiation function */
@@ -303,7 +295,7 @@ int mv_pp2x_eth_tool_nway_reset(struct net_device *dev)
 
 /* Get pause fc settings for ethtools */
 static void mv_pp2x_get_pauseparam(struct net_device *dev,
-					struct ethtool_pauseparam *pause)
+				   struct ethtool_pauseparam *pause)
 {
 	struct mv_pp2x_port *port = netdev_priv(dev);
 	struct mv_port_link_status status;
@@ -352,7 +344,7 @@ static void mv_pp2x_get_pauseparam(struct net_device *dev,
 
 /* Set pause fc settings for ethtools */
 static int mv_pp2x_set_pauseparam(struct net_device *dev,
-					struct ethtool_pauseparam *pause)
+				  struct ethtool_pauseparam *pause)
 {
 	struct mv_pp2x_port *port = netdev_priv(dev);
 	struct mv_mac_data *mac = &port->mac_data;
@@ -425,9 +417,9 @@ static int mv_pp2x_set_pauseparam(struct net_device *dev,
 		else
 			mv_gop110_xlg_mac_fc_set(gop, gop_port, MV_PORT_FC_RX_DISABLE);
 
-		if (pause->tx_pause)
+		if (pause->tx_pause) {
 			mv_gop110_fca_tx_enable(gop, gop_port, false);
-		else	{
+		} else	{
 			mv_gop110_xlg_mac_fc_set(gop, gop_port, MV_PORT_FC_TX_DISABLE);
 			mv_gop110_fca_tx_enable(gop, gop_port, true);
 			}
@@ -463,7 +455,7 @@ static int mv_pp2x_ethtool_get_settings(struct net_device *dev,
 		mv_gop110_port_link_status(&port->priv->hw.gop,
 					   &port->mac_data, &status);
 
-		if (status.linkup == true) {
+		if (status.linkup) {
 			switch (status.speed) {
 			case MV_PORT_SPEED_10000:
 				cmd->speed = SPEED_10000;
@@ -521,7 +513,7 @@ static int mv_pp2x_ethtool_get_settings(struct net_device *dev,
 
 			/* check if speed and duplex are AN */
 			if (mv_gop110_port_autoneg_status(&port->priv->hw.gop,
-					   &port->mac_data)) {
+							  &port->mac_data)) {
 				cmd->autoneg = AUTONEG_ENABLE;
 			} else {
 				cmd->autoneg = AUTONEG_DISABLE;
@@ -535,9 +527,8 @@ static int mv_pp2x_ethtool_get_settings(struct net_device *dev,
 }
 
 void mv_pp2x_ethtool_set_gmac_config(struct mv_port_link_status status, struct gop_hw *gop,
-			int gop_port, struct mv_mac_data *mac, struct ethtool_cmd *cmd)
+				     int gop_port, struct mv_mac_data *mac, struct ethtool_cmd *cmd)
 {
-
 	mv_gop110_force_link_mode_set(gop, mac, false, true);
 	mv_gop110_gmac_set_autoneg(gop, mac, cmd->autoneg);
 	if (cmd->autoneg)
@@ -549,24 +540,22 @@ void mv_pp2x_ethtool_set_gmac_config(struct mv_port_link_status status, struct g
 
 int mv_pp2x_get_new_comphy_mode(struct ethtool_cmd *cmd, int port_id)
 {
-
 	if (cmd->speed == SPEED_10000 && port_id == 0)
 		return COMPHY_DEF(COMPHY_SFI_MODE, port_id);
 	else if (cmd->speed == SPEED_2500)
 		return COMPHY_DEF(COMPHY_HS_SGMII_MODE, port_id);
 	else if (cmd->speed == SPEED_1000 || cmd->speed == SPEED_100 ||
-			cmd->speed == SPEED_10)
+		 cmd->speed == SPEED_10)
 		return COMPHY_DEF(COMPHY_SGMII_MODE, port_id);
 	else
 		return -EINVAL;
-
 }
 
 void mv_pp2x_set_new_phy_mode(struct ethtool_cmd *cmd, struct mv_mac_data *mac)
 {
-	if (cmd->speed == SPEED_10000)
+	if (cmd->speed == SPEED_10000) {
 		mac->phy_mode = PHY_INTERFACE_MODE_SFI;
-	else if (cmd->speed == SPEED_2500) {
+	} else if (cmd->speed == SPEED_2500) {
 		mac->phy_mode = PHY_INTERFACE_MODE_SGMII;
 		mac->speed = SPEED_2500;
 		mac->flags |= MV_EMAC_F_SGMII2_5;
@@ -577,7 +566,6 @@ void mv_pp2x_set_new_phy_mode(struct ethtool_cmd *cmd, struct mv_mac_data *mac)
 	}
 }
 
-
 /* Set settings (phy address, speed) for ethtools */
 static int mv_pp2x_ethtool_set_settings(struct net_device *dev,
 					struct ethtool_cmd *cmd)
@@ -715,7 +703,7 @@ static int mv_pp2x_ethtool_set_coalesce(struct net_device *dev,
 
 		txq->pkts_coal = c->tx_max_coalesced_frames;
 	}
-	if (port->priv->pp2xdata->interrupt_tx_done == true) {
+	if (port->priv->pp2xdata->interrupt_tx_done) {
 		mv_pp2x_tx_done_time_coal_set(port, port->tx_time_coal);
 		on_each_cpu(mv_pp2x_tx_done_pkts_coal_set, port, 1);
 	}
@@ -884,7 +872,7 @@ static int mv_pp2x_ethtool_get_rxnfc(struct net_device *dev,
 }
 
 static int mv_pp2x_set_rss_hash_opt(struct mv_pp2x_port *port,
-				struct ethtool_rxnfc *nfc)
+				    struct ethtool_rxnfc *nfc)
 {
 	if (nfc->data & ~(RXH_IP_SRC | RXH_IP_DST |
 			  RXH_L4_B_0_1 | RXH_L4_B_2_3))
@@ -944,7 +932,6 @@ static int mv_pp2x_ethtool_set_rxnfc(struct net_device *dev, struct ethtool_rxnf
 	return ret;
 }
 
-
 static int mv_pp2x_ethtool_get_rxfh(struct net_device *dev, u32 *indir, u8 *key,
 				    u8 *hfunc)
 {
@@ -1076,7 +1063,7 @@ static u64 mv_pp2x_eth_tool_link_test(struct mv_pp2x_port *port)
 	pr_info("Link testing starting\n");
 
 	mv_gop110_port_link_status(&port->priv->hw.gop,
-					&port->mac_data, &status);
+				   &port->mac_data, &status);
 
 	if (status.linkup)
 		return 0;
@@ -1098,7 +1085,7 @@ static bool mv_pp2x_reg_pattern_test(void *reg, u32 offset, u32 mask, u32 write)
 		read = mv_gop_gen_read(reg, offset);
 		if (read != (write & test[i] & mask)) {
 			pr_err("pattern test reg %p(test 0x%08X write 0x%08X mask 0x%08X) failed: ",
-			      reg, test[i], write, mask);
+			       reg, test[i], write, mask);
 			pr_err("got 0x%08X expected 0x%08X\n", read, (write & test[i] & mask));
 			mv_gop_gen_write(reg, offset, old);
 			return true;
@@ -1173,7 +1160,7 @@ static u64 mv_pp2x_eth_tool_reg_test(struct mv_pp2x_port *port)
 }
 
 static void mv_pp2x_eth_tool_diag_test(struct net_device *netdev,
-	struct ethtool_test *test, u64 *data)
+				       struct ethtool_test *test, u64 *data)
 {
 	struct mv_pp2x_port *port = netdev_priv(netdev);
 	int i;
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.c
index 00e2862..cac96df 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.c
@@ -36,7 +36,7 @@
 
 int mv_pp2x_ptr_validate(const void *ptr)
 {
-	if (ptr == NULL) {
+	if (!ptr) {
 		pr_err("%s: null pointer.\n", __func__);
 		return MV_ERROR;
 	}
@@ -48,7 +48,7 @@ int mv_pp2x_range_validate(int value, int min, int max)
 {
 	if (((value) > (max)) || ((value) < (min))) {
 		pr_err("%s: value 0x%X (%d) is out of range [0x%X , 0x%X].\n",
-			__func__, (value), (value), (min), (max));
+		       __func__, (value), (value), (min), (max));
 		return MV_ERROR;
 	}
 	return MV_OK;
@@ -609,7 +609,6 @@ void mv_pp2x_prs_tcam_ai_update(struct mv_pp2x_prs_entry *pe,
 	int i, ai_idx = MVPP2_PRS_TCAM_AI_BYTE;
 
 	for (i = 0; i < MVPP2_PRS_AI_BITS; i++) {
-
 		if (!(enable & BIT(i)))
 			continue;
 
@@ -669,7 +668,7 @@ void mv_pp2x_prs_sram_ri_update(struct mv_pp2x_prs_entry *pe,
 			mv_pp2x_prs_sram_bits_clear(pe, ri_off + i, 1);
 
 		mv_pp2x_prs_sram_bits_set(pe,
-			MVPP2_PRS_SRAM_RI_CTRL_OFFS + i, 1);
+					  MVPP2_PRS_SRAM_RI_CTRL_OFFS + i, 1);
 	}
 }
 EXPORT_SYMBOL(mv_pp2x_prs_sram_ri_update);
@@ -688,7 +687,6 @@ void mv_pp2x_prs_sram_ai_update(struct mv_pp2x_prs_entry *pe,
 	int ai_off = MVPP2_PRS_SRAM_AI_OFFS;
 
 	for (i = 0; i < MVPP2_PRS_SRAM_AI_CTRL_BITS; i++) {
-
 		if (!(mask & BIT(i)))
 			continue;
 
@@ -698,7 +696,7 @@ void mv_pp2x_prs_sram_ai_update(struct mv_pp2x_prs_entry *pe,
 			mv_pp2x_prs_sram_bits_clear(pe, ai_off + i, 1);
 
 		mv_pp2x_prs_sram_bits_set(pe,
-			MVPP2_PRS_SRAM_AI_CTRL_OFFS + i, 1);
+					  MVPP2_PRS_SRAM_AI_CTRL_OFFS + i, 1);
 	}
 }
 EXPORT_SYMBOL(mv_pp2x_prs_sram_ai_update);
@@ -740,11 +738,11 @@ static void mv_pp2x_prs_sram_shift_set(struct mv_pp2x_prs_entry *pe, int shift,
 	/* Set sign */
 	if (shift < 0) {
 		mv_pp2x_prs_sram_bits_set(pe,
-			MVPP2_PRS_SRAM_SHIFT_SIGN_BIT, 1);
+					  MVPP2_PRS_SRAM_SHIFT_SIGN_BIT, 1);
 		shift = 0 - shift;
 	} else {
 		mv_pp2x_prs_sram_bits_clear(pe,
-			MVPP2_PRS_SRAM_SHIFT_SIGN_BIT, 1);
+					    MVPP2_PRS_SRAM_SHIFT_SIGN_BIT, 1);
 	}
 
 	/* Set value */
@@ -896,7 +894,7 @@ static void mv_pp2x_prs_mac_drop_all_set(struct mv_pp2x_hw *hw,
 
 		/* Non-promiscuous mode for all ports - DROP unknown packets */
 		mv_pp2x_prs_sram_ri_update(&pe, MVPP2_PRS_RI_DROP_MASK,
-					 MVPP2_PRS_RI_DROP_MASK);
+					   MVPP2_PRS_RI_DROP_MASK);
 
 		mv_pp2x_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
 		mv_pp2x_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
@@ -919,7 +917,7 @@ void mv_pp2x_prs_mac_promisc_set(struct mv_pp2x_hw *hw, int port, bool add)
 {
 	struct mv_pp2x_prs_entry pe;
 
-	/* Promiscous mode - Accept unknown packets */
+	/* Promiscuous mode - Accept unknown packets */
 
 	if (hw->prs_shadow[MVPP2_PE_MAC_PROMISCUOUS].valid) {
 		/* Entry exist - update port only */
@@ -936,11 +934,11 @@ void mv_pp2x_prs_mac_promisc_set(struct mv_pp2x_hw *hw, int port, bool add)
 
 		/* Set result info bits */
 		mv_pp2x_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L2_UCAST,
-					 MVPP2_PRS_RI_L2_CAST_MASK);
+					   MVPP2_PRS_RI_L2_CAST_MASK);
 
 		/* Shift to ethertype */
 		mv_pp2x_prs_sram_shift_set(&pe, 2 * ETH_ALEN,
-					 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+					   MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
 
 		/* Mask all ports */
 		mv_pp2x_prs_tcam_port_map_set(&pe, 0);
@@ -989,7 +987,7 @@ void mv_pp2x_prs_mac_multi_set(struct mv_pp2x_hw *hw, int port, int index,
 
 		/* Shift to ethertype */
 		mv_pp2x_prs_sram_shift_set(&pe, 2 * ETH_ALEN,
-					 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+					   MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
 
 		/* Mask all ports */
 		mv_pp2x_prs_tcam_port_map_set(&pe, 0);
@@ -1039,7 +1037,7 @@ static void mv_pp2x_prs_dsa_tag_set(struct mv_pp2x_hw *hw, int port, bool add,
 		if (tagged) {
 			/* Set tagged bit in DSA tag */
 			mv_pp2x_prs_tcam_data_byte_set(&pe, 0,
-					MVPP2_PRS_TCAM_DSA_TAGGED_BIT,
+						       MVPP2_PRS_TCAM_DSA_TAGGED_BIT,
 					MVPP2_PRS_TCAM_DSA_TAGGED_BIT);
 			/* Clear all ai bits for next iteration */
 			mv_pp2x_prs_sram_ai_update(&pe, 0,
@@ -1109,7 +1107,7 @@ static void mv_pp2x_prs_dsa_tag_ethertype_set(struct mv_pp2x_hw *hw, int port,
 		if (tagged) {
 			/* Set tagged bit in DSA tag */
 			mv_pp2x_prs_tcam_data_byte_set(&pe,
-						     MVPP2_ETH_TYPE_LEN + 2 + 3,
+						       MVPP2_ETH_TYPE_LEN + 2 + 3,
 						 MVPP2_PRS_TCAM_DSA_TAGGED_BIT,
 						 MVPP2_PRS_TCAM_DSA_TAGGED_BIT);
 			/* Clear all ai bits for next iteration */
@@ -1301,8 +1299,8 @@ static struct mv_pp2x_prs_entry *mv_pp2x_prs_double_vlan_find(
 		pe->index = tid;
 		mv_pp2x_prs_hw_read(hw, pe);
 
-		match = mv_pp2x_prs_tcam_data_cmp(pe, 0, swab16(tpid1))
-			&& mv_pp2x_prs_tcam_data_cmp(pe, 4, swab16(tpid2));
+		match = mv_pp2x_prs_tcam_data_cmp(pe, 0, swab16(tpid1))	&&
+			mv_pp2x_prs_tcam_data_cmp(pe, 4, swab16(tpid2));
 
 		if (!match)
 			continue;
@@ -1549,9 +1547,9 @@ static int mv_pp2x_prs_ip6_proto(struct mv_pp2x_hw *hw, unsigned short proto,
 				    MVPP2_PRS_SRAM_OP_SEL_UDF_ADD);
 
 	mv_pp2x_prs_tcam_data_byte_set(&pe, 0, proto,
-			MVPP2_PRS_TCAM_PROTO_MASK);
+				       MVPP2_PRS_TCAM_PROTO_MASK);
 	mv_pp2x_prs_tcam_ai_update(&pe, MVPP2_PRS_IPV6_NO_EXT_AI_BIT,
-				 MVPP2_PRS_IPV6_NO_EXT_AI_BIT);
+				   MVPP2_PRS_IPV6_NO_EXT_AI_BIT);
 	/* Unmask all ports */
 	mv_pp2x_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
 
@@ -1572,7 +1570,7 @@ static int mv_pp2x_prs_ip6_cast(struct mv_pp2x_hw *hw, unsigned short l3_cast)
 		return -EINVAL;
 
 	tid = mv_pp2x_prs_tcam_first_free(hw, MVPP2_PE_FIRST_FREE_TID,
-					MVPP2_PE_LAST_FREE_TID);
+					  MVPP2_PE_LAST_FREE_TID);
 	if (tid < 0)
 		return tid;
 
@@ -1664,7 +1662,7 @@ static void mv_pp2x_prs_mh_init(struct mv_pp2x_hw *hw)
 	pe.index = MVPP2_PE_MH_DEFAULT;
 	mv_pp2x_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_MH);
 	mv_pp2x_prs_sram_shift_set(&pe, MVPP2_MH_SIZE,
-				 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+				   MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
 	mv_pp2x_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_MAC);
 
 	/* Unmask all ports */
@@ -2406,7 +2404,7 @@ static bool mv_pp2x_prs_mac_range_equals(struct mv_pp2x_prs_entry *pe,
 
 	for (index = 0; index < ETH_ALEN; index++) {
 		mv_pp2x_prs_tcam_data_byte_get(pe, index, &tcam_byte,
-			&tcam_mask);
+					       &tcam_mask);
 		if (tcam_mask != mask[index])
 			return false;
 
@@ -2750,15 +2748,15 @@ int mv_pp2x_prs_def_flow(struct mv_pp2x_port *port)
 }
 
 /* Set prs dedicated flow for the port */
-int mv_pp2x_prs_flow_id_gen(struct mv_pp2x_port *port, u32 flowId,
-			    u32 res, u32 resMask)
+int mv_pp2x_prs_flow_id_gen(struct mv_pp2x_port *port, u32 flow_id,
+			    u32 res, u32 res_mask)
 {
 	struct mv_pp2x_prs_entry *pe;
 	struct mv_pp2x_hw *hw = &port->priv->hw;
 	int tid;
 	unsigned int pmap = 0;
 
-	pe = mv_pp2x_prs_flow_find(hw, flowId, res, resMask);
+	pe = mv_pp2x_prs_flow_find(hw, flow_id, res, res_mask);
 
 	/* Such entry not exist */
 	if (!pe) {
@@ -2768,7 +2766,7 @@ int mv_pp2x_prs_flow_id_gen(struct mv_pp2x_port *port, u32 flowId,
 
 		/* Go through the all entires from last to first */
 		tid = mv_pp2x_prs_tcam_first_free(hw,
-			MVPP2_PE_LAST_FREE_TID,
+						  MVPP2_PE_LAST_FREE_TID,
 			MVPP2_PE_FIRST_FREE_TID);
 		if (tid < 0) {
 			kfree(pe);
@@ -2778,14 +2776,14 @@ int mv_pp2x_prs_flow_id_gen(struct mv_pp2x_port *port, u32 flowId,
 		mv_pp2x_prs_tcam_lu_set(pe, MVPP2_PRS_LU_FLOWS);
 		pe->index = tid;
 
-		mv_pp2x_prs_sram_ai_update(pe, flowId, MVPP2_PRS_FLOW_ID_MASK);
+		mv_pp2x_prs_sram_ai_update(pe, flow_id, MVPP2_PRS_FLOW_ID_MASK);
 		mv_pp2x_prs_sram_bits_set(pe, MVPP2_PRS_SRAM_LU_DONE_BIT, 1);
 
 		/* Update shadow table */
 		mv_pp2x_prs_shadow_set(hw, pe->index, MVPP2_PRS_LU_FLOWS);
 
 		/*update result data and mask*/
-		mv_pp2x_prs_tcam_data_dword_set(pe, 0, res, resMask);
+		mv_pp2x_prs_tcam_data_dword_set(pe, 0, res, res_mask);
 	} else {
 		pmap = mv_pp2x_prs_tcam_port_map_get(pe);
 	}
@@ -2803,7 +2801,7 @@ int mv_pp2x_prs_flow_set(struct mv_pp2x_port *port)
 
 	for (index = 0; index < MVPP2_PRS_FL_TCAM_NUM; index++) {
 		ret = mv_pp2x_prs_flow_id_gen(port,
-			mv_pp2x_prs_flow_id_array[index].flow_id,
+					      mv_pp2x_prs_flow_id_array[index].flow_id,
 			mv_pp2x_prs_flow_id_array[index].prs_result.ri,
 			mv_pp2x_prs_flow_id_array[index].prs_result.ri_mask);
 		if (ret)
@@ -2922,7 +2920,7 @@ int mv_pp2x_cls_sw_flow_hek_num_set(struct mv_pp2x_cls_flow_entry *fe,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(num_of_fields, 0,
-	    MVPP2_CLS_FLOWS_TBL_FIELDS_MAX) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_FIELDS_MAX) == MV_ERROR)
 		return MV_ERROR;
 
 	fe->data[1] &= ~MVPP2_FLOW_FIELDS_NUM_MASK;
@@ -2941,7 +2939,7 @@ int mv_pp2x_cls_sw_flow_hek_set(struct mv_pp2x_cls_flow_entry *fe,
 	num_of_fields = ((fe->data[1] &
 		MVPP2_FLOW_FIELDS_NUM_MASK) >> MVPP2_FLOW_FIELDS_NUM);
 
-	if (num_of_fields < (field_index+1)) {
+	if (num_of_fields < (field_index + 1)) {
 		pr_debug("%s:num of heks=%d ,idx(%d) out of range\n",
 			 __func__, num_of_fields, field_index);
 		return -1;
@@ -2986,7 +2984,7 @@ static void mv_pp2x_cls_flow_cos(struct mv_pp2x_hw *hw,
 	}
 	hek_num = 0;
 	if ((lkpid == MVPP2_PRS_FL_NON_IP_UNTAG &&
-		cos_type == MVPP2_COS_TYPE_DEF) ||
+	     cos_type == MVPP2_COS_TYPE_DEF) ||
 	    (lkpid == MVPP2_PRS_FL_NON_IP_TAG &&
 		cos_type == MVPP2_COS_TYPE_VLAN))
 		is_last = 1;
@@ -3057,7 +3055,7 @@ static void mv_pp2x_cls_flow_rss_hash(struct mv_pp2x_hw *hw,
 		mv_pp2x_cls_sw_flow_eng_set(fe, MVPP2_CLS_ENGINE_C3HB, 1);
 	}
 	mv_pp2x_cls_sw_flow_extra_set(fe,
-		MVPP2_CLS_LKP_HASH, MVPP2_CLS_FL_RSS_PRI);
+				      MVPP2_CLS_LKP_HASH, MVPP2_CLS_FL_RSS_PRI);
 	fe->index = entry_idx;
 
 	/* Update last for UDP NF flow */
@@ -3067,10 +3065,10 @@ static void mv_pp2x_cls_flow_rss_hash(struct mv_pp2x_hw *hw,
 			MVPP2_PRS_FL_START].flow_entry_rss1) {
 			if (rss_mode == MVPP2_RSS_HASH_2T)
 				mv_pp2x_cls_sw_flow_eng_set(fe,
-						MVPP2_CLS_ENGINE_C3HA, 0);
+							    MVPP2_CLS_ENGINE_C3HA, 0);
 			else
 				mv_pp2x_cls_sw_flow_eng_set(fe,
-						MVPP2_CLS_ENGINE_C3HB, 0);
+							    MVPP2_CLS_ENGINE_C3HB, 0);
 		}
 	}
 
@@ -3208,34 +3206,34 @@ int mv_pp2x_cls_lkp_port_way_set(struct mv_pp2x_hw *hw, int port, int way)
 int mv_pp2x_cls_hw_udf_set(struct mv_pp2x_hw *hw, int udf_no, int offs_id,
 			   int offs_bits, int size_bits)
 {
-	unsigned int regVal;
+	unsigned int reg_val;
 
 	if (mv_pp2x_range_validate(offs_id, 0,
-	    MVPP2_CLS_UDF_OFFSET_ID_MAX) == MV_ERROR)
+				   MVPP2_CLS_UDF_OFFSET_ID_MAX) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(offs_bits, 0,
-	    MVPP2_CLS_UDF_REL_OFFSET_MAX) == MV_ERROR)
+				   MVPP2_CLS_UDF_REL_OFFSET_MAX) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(size_bits, 0,
-	    MVPP2_CLS_UDF_SIZE_MASK) == MV_ERROR)
+				   MVPP2_CLS_UDF_SIZE_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(udf_no, 0,
-	    MVPP2_CLS_UDF_REGS_NUM - 1) == MV_ERROR)
+				   MVPP2_CLS_UDF_REGS_NUM - 1) == MV_ERROR)
 		return MV_ERROR;
 
-	regVal = mv_pp2x_read(hw, MVPP2_CLS_UDF_REG(udf_no));
-	regVal &= ~MVPP2_CLS_UDF_OFFSET_ID_MASK;
-	regVal &= ~MVPP2_CLS_UDF_REL_OFFSET_MASK;
-	regVal &= ~MVPP2_CLS_UDF_SIZE_MASK;
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS_UDF_REG(udf_no));
+	reg_val &= ~MVPP2_CLS_UDF_OFFSET_ID_MASK;
+	reg_val &= ~MVPP2_CLS_UDF_REL_OFFSET_MASK;
+	reg_val &= ~MVPP2_CLS_UDF_SIZE_MASK;
 
-	regVal |= (offs_id << MVPP2_CLS_UDF_OFFSET_ID_OFFS);
-	regVal |= (offs_bits << MVPP2_CLS_UDF_REL_OFFSET_OFFS);
-	regVal |= (size_bits << MVPP2_CLS_UDF_SIZE_OFFS);
+	reg_val |= (offs_id << MVPP2_CLS_UDF_OFFSET_ID_OFFS);
+	reg_val |= (offs_bits << MVPP2_CLS_UDF_REL_OFFSET_OFFS);
+	reg_val |= (size_bits << MVPP2_CLS_UDF_SIZE_OFFS);
 
-	mv_pp2x_write(hw, MVPP2_CLS_UDF_REG(udf_no), regVal);
+	mv_pp2x_write(hw, MVPP2_CLS_UDF_REG(udf_no), reg_val);
 
 	return MV_OK;
 }
@@ -3257,7 +3255,7 @@ void mv_pp2x_cls_lookup_tbl_config(struct mv_pp2x_hw *hw)
 		index++) {
 		int i, j;
 
-		flow_info = &(hw->cls_shadow->flow_info[index]);
+		flow_info = &hw->cls_shadow->flow_info[index];
 		/* Init data[] as invalid value */
 		for (i = 0; i < MVPP2_LKP_PTR_NUM; i++)
 			data[i] = MVPP2_FLOW_TBL_SIZE;
@@ -3390,7 +3388,6 @@ void mv_pp2x_cls_oversize_rxq_set(struct mv_pp2x_port *port)
 
 	mv_pp2x_write(hw, MVPP2_CLS_OVERSIZE_RXQ_LOW_REG(port->id),
 		      port->first_rxq & MVPP2_CLS_OVERSIZE_RXQ_LOW_MASK);
-
 }
 
 void mv_pp21_get_mac_address(struct mv_pp2x_port *port, unsigned char *addr)
@@ -3831,7 +3828,7 @@ void mv_pp2x_pool_refill(struct mv_pp2x *priv, u32 pool,
 }
 
 void mv_pp2x_pool_refill_virtual(struct mv_pp2x *priv, u32 pool,
-			 dma_addr_t phys_addr, u8 *cookie)
+				 dma_addr_t phys_addr, u8 *cookie)
 {
 	int cpu = smp_processor_id();
 
@@ -3852,7 +3849,7 @@ void mv_pp2x_bm_pool_bufsize_set(struct mv_pp2x_hw *hw,
 
 /* Attach long pool to rxq */
 void mv_pp21_rxq_long_pool_set(struct mv_pp2x_hw *hw,
-		int prxq, int long_pool)
+			       int prxq, int long_pool)
 {
 	u32 val;
 
@@ -3947,7 +3944,7 @@ void mv_pp2x_egress_enable(struct mv_pp2x_port *port)
 	for (queue = 0; queue < port->num_tx_queues; queue++) {
 		struct mv_pp2x_tx_queue *txq = port->txqs[queue];
 
-		if (txq->first_desc != NULL)
+		if (txq->first_desc)
 			qmap |= (1 << queue);
 	}
 
@@ -3996,7 +3993,7 @@ void mv_pp2x_egress_disable(struct mv_pp2x_port *port)
 
 /* Parser default initialization */
 int mv_pp2x_prs_default_init(struct platform_device *pdev,
-		struct mv_pp2x_hw *hw)
+			     struct mv_pp2x_hw *hw)
 {
 	int err, index, i;
 
@@ -4067,11 +4064,11 @@ int mv_pp2x_prs_sw_sram_shift_set(struct mv_pp2x_prs_entry *pe,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(shift, 0 - MVPP2_PRS_SRAM_SHIFT_MASK,
-	    MVPP2_PRS_SRAM_SHIFT_MASK) == MV_ERROR)
+				   MVPP2_PRS_SRAM_SHIFT_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(op, 0,
-	    MVPP2_PRS_SRAM_OP_SEL_SHIFT_MASK) == MV_ERROR)
+				   MVPP2_PRS_SRAM_OP_SEL_SHIFT_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	/* Set sign */
@@ -4138,15 +4135,15 @@ int mv_pp2x_prs_sw_sram_offset_set(struct mv_pp2x_prs_entry *pe,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(offset, 0 - MVPP2_PRS_SRAM_UDF_MASK,
-	    MVPP2_PRS_SRAM_UDF_MASK) == MV_ERROR)
+				   MVPP2_PRS_SRAM_UDF_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(type, 0,
-	    MVPP2_PRS_SRAM_UDF_TYPE_MASK) == MV_ERROR)
+				   MVPP2_PRS_SRAM_UDF_TYPE_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(op, 0,
-		MVPP2_PRS_SRAM_OP_SEL_UDF_MASK) == MV_ERROR)
+				   MVPP2_PRS_SRAM_OP_SEL_UDF_MASK) == MV_ERROR)
 		return MV_ERROR;
 
 	/* Set offset sign */
@@ -4282,15 +4279,15 @@ int mv_pp2x_prs_sw_sram_next_lu_get(struct mv_pp2x_prs_entry *pe,
 }
 EXPORT_SYMBOL(mv_pp2x_prs_sw_sram_next_lu_get);
 
-int mv_pp2x_prs_sram_bit_get(struct mv_pp2x_prs_entry *pe, int bitNum,
+int mv_pp2x_prs_sram_bit_get(struct mv_pp2x_prs_entry *pe, int bit_num,
 			     unsigned int *bit)
 {
 	if (mv_pp2x_ptr_validate(pe) == MV_ERROR)
 		return MV_ERROR;
 
-	*bit = pe->sram.byte[SRAM_BIT_TO_BYTE(bitNum)]  &
-		(1 << (bitNum % 8));
-	*bit = (*bit) >> (bitNum % 8);
+	*bit = pe->sram.byte[SRAM_BIT_TO_BYTE(bit_num)]  &
+		(1 << (bit_num % 8));
+	*bit = (*bit) >> (bit_num % 8);
 	return MV_OK;
 }
 
@@ -4345,8 +4342,8 @@ int mv_pp2x_prs_sw_sram_ri_get(struct mv_pp2x_prs_entry *pe,
 	if (mv_pp2x_ptr_validate(enable) == MV_ERROR)
 		return MV_ERROR;
 
-	*bits = pe->sram.word[MVPP2_PRS_SRAM_RI_OFFS/32];
-	*enable = pe->sram.word[MVPP2_PRS_SRAM_RI_CTRL_OFFS/32];
+	*bits = pe->sram.word[MVPP2_PRS_SRAM_RI_OFFS / 32];
+	*enable = pe->sram.word[MVPP2_PRS_SRAM_RI_CTRL_OFFS / 32];
 	return MV_OK;
 }
 EXPORT_SYMBOL(mv_pp2x_prs_sw_sram_ri_get);
@@ -4396,7 +4393,7 @@ int mv_pp2x_prs_sw_sram_ai_get(struct mv_pp2x_prs_entry *pe,
 int mv_pp2x_cls_hw_lkp_read(struct mv_pp2x_hw *hw, int lkpid, int way,
 			    struct mv_pp2x_cls_lookup_entry *fe)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (mv_pp2x_ptr_validate(fe) == MV_ERROR)
 		return MV_ERROR;
@@ -4405,13 +4402,13 @@ int mv_pp2x_cls_hw_lkp_read(struct mv_pp2x_hw *hw, int lkpid, int way,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(lkpid, 0,
-	    MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	/* write index reg */
-	regVal = (way << MVPP2_CLS_LKP_INDEX_WAY_OFFS) |
+	reg_val = (way << MVPP2_CLS_LKP_INDEX_WAY_OFFS) |
 		(lkpid << MVPP2_CLS_LKP_INDEX_LKP_OFFS);
-	mv_pp2x_write(hw, MVPP2_CLS_LKP_INDEX_REG, regVal);
+	mv_pp2x_write(hw, MVPP2_CLS_LKP_INDEX_REG, reg_val);
 
 	fe->way = way;
 	fe->lkpid = lkpid;
@@ -4425,7 +4422,7 @@ int mv_pp2x_cls_hw_lkp_read(struct mv_pp2x_hw *hw, int lkpid, int way,
 int mv_pp2x_cls_hw_lkp_write(struct mv_pp2x_hw *hw, int lkpid,
 			     int way, struct mv_pp2x_cls_lookup_entry *fe)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (mv_pp2x_ptr_validate(fe) == MV_ERROR)
 		return MV_ERROR;
@@ -4434,13 +4431,13 @@ int mv_pp2x_cls_hw_lkp_write(struct mv_pp2x_hw *hw, int lkpid,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(lkpid, 0,
-	    MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	/* write index reg */
-	regVal = (way << MVPP2_CLS_LKP_INDEX_WAY_OFFS) |
+	reg_val = (way << MVPP2_CLS_LKP_INDEX_WAY_OFFS) |
 		(lkpid << MVPP2_CLS_LKP_INDEX_LKP_OFFS);
-	mv_pp2x_write(hw, MVPP2_CLS_LKP_INDEX_REG, regVal);
+	mv_pp2x_write(hw, MVPP2_CLS_LKP_INDEX_REG, reg_val);
 
 	/* write flowId reg */
 	mv_pp2x_write(hw, MVPP2_CLS_LKP_TBL_REG, fe->data);
@@ -4470,7 +4467,7 @@ int mv_pp2x_cls_sw_lkp_rxq_set(struct mv_pp2x_cls_lookup_entry *lkp, int rxq)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(rxq, 0,
-	    (1 << MVPP2_FLOWID_RXQ_BITS) - 1) == MV_ERROR)
+				   (1 << MVPP2_FLOWID_RXQ_BITS) - 1) == MV_ERROR)
 		return MV_ERROR;
 
 	lkp->data &= ~MVPP2_FLOWID_RXQ_MASK;
@@ -4527,13 +4524,13 @@ int mv_pp2x_cls_sw_lkp_flow_get(struct mv_pp2x_cls_lookup_entry *lkp,
 EXPORT_SYMBOL(mv_pp2x_cls_sw_lkp_flow_get);
 
 int mv_pp2x_cls_sw_lkp_flow_set(struct mv_pp2x_cls_lookup_entry *lkp,
-		int flow_idx)
+				int flow_idx)
 {
 	if (mv_pp2x_ptr_validate(lkp) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(flow_idx, 0,
-	    MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	lkp->data &= ~MVPP2_FLOWID_FLOW_MASK;
@@ -4567,7 +4564,7 @@ int mv_pp2x_cls_sw_lkp_mod_set(struct mv_pp2x_cls_lookup_entry *lkp,
 
 	/* TODO: what is the max value of mode base */
 	if (mv_pp2x_range_validate(mod_base, 0,
-	    (1 << MVPP2_FLOWID_MODE_BITS) - 1) == MV_ERROR)
+				   (1 << MVPP2_FLOWID_MODE_BITS) - 1) == MV_ERROR)
 		return MV_ERROR;
 
 	lkp->data &= ~MVPP2_FLOWID_MODE_MASK;
@@ -4588,7 +4585,7 @@ int mv_pp2x_cls_hw_flow_read(struct mv_pp2x_hw *hw, int index,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(index, 0,
-	    MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	fe->index = index;
@@ -4664,11 +4661,11 @@ int mv_pp2x_cls_sw_flow_port_set(struct mv_pp2x_cls_flow_entry *fe,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(type, 0,
-	    ((1 << MVPP2_FLOW_PORT_TYPE_BITS) - 1)) == MV_ERROR)
+				   ((1 << MVPP2_FLOW_PORT_TYPE_BITS) - 1)) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(portid, 0,
-	    ((1 << MVPP2_FLOW_PORT_ID_BITS) - 1)) == MV_ERROR)
+				   ((1 << MVPP2_FLOW_PORT_ID_BITS) - 1)) == MV_ERROR)
 		return MV_ERROR;
 
 	fe->data[0] &= ~MVPP2_FLOW_PORT_ID_MASK;
@@ -4813,7 +4810,6 @@ int mv_pp2x_cls_sw_flow_engine_set(struct mv_pp2x_cls_flow_entry *fe,
 	fe->data[0] |= (engine << MVPP2_FLOW_ENGINE);
 
 	return MV_OK;
-
 }
 EXPORT_SYMBOL(mv_pp2x_cls_sw_flow_engine_set);
 
@@ -4847,11 +4843,11 @@ int mv_pp2x_cls_sw_flow_extra_set(struct mv_pp2x_cls_flow_entry *fe,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(type, 0,
-	    MVPP2_FLOW_PORT_ID_MAX) == MV_ERROR)
+				   MVPP2_FLOW_PORT_ID_MAX) == MV_ERROR)
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(prio, 0,
-	    ((1 << MVPP2_FLOW_FIELD_ID_BITS) - 1)) == MV_ERROR)
+				   ((1 << MVPP2_FLOW_FIELD_ID_BITS) - 1)) == MV_ERROR)
 		return MV_ERROR;
 
 	fe->data[1] &= ~MVPP2_FLOW_LKP_TYPE_MASK;
@@ -4864,7 +4860,6 @@ int mv_pp2x_cls_sw_flow_extra_set(struct mv_pp2x_cls_flow_entry *fe,
 }
 EXPORT_SYMBOL(mv_pp2x_cls_sw_flow_extra_set);
 
-
 /*----------------------------------------------------------------------*/
 /*	Classifier Top Public length change table APIs			*/
 /*----------------------------------------------------------------------*/
@@ -4874,7 +4869,7 @@ int mv_pp2x_cls_hw_flow_hit_get(struct mv_pp2x_hw *hw,
 				int index,  unsigned int *cnt)
 {
 	if (mv_pp2x_range_validate(index, 0,
-	    MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_FLOWS_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	/*set index */
@@ -4896,7 +4891,7 @@ int mv_pp2x_cls_hw_lkp_hit_get(struct mv_pp2x_hw *hw, int lkpid, int way,
 		return MV_ERROR;
 
 	if (mv_pp2x_range_validate(lkpid, 0,
-	    MVPP2_CLS_LKP_TBL_SIZE) == MV_ERROR)
+				   MVPP2_CLS_LKP_TBL_SIZE) == MV_ERROR)
 		return MV_ERROR;
 
 	/*set index */
@@ -4917,7 +4912,7 @@ int mv_pp2x_cls_c2_qos_hw_read(struct mv_pp2x_hw *hw, int tbl_id,
 			       int tbl_sel, int tbl_line,
 			       struct mv_pp2x_cls_c2_qos_entry *qos)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -4929,19 +4924,19 @@ int mv_pp2x_cls_c2_qos_hw_read(struct mv_pp2x_hw *hw, int tbl_id,
 		/*dscp*/
 		/* TODO define 8=DSCP_TBL_NUM  64=DSCP_TBL_LINES */
 		if (mv_pp2x_range_validate(tbl_id, 0,
-		    MVPP2_QOS_TBL_NUM_DSCP) == MV_ERROR)
+					   MVPP2_QOS_TBL_NUM_DSCP) == MV_ERROR)
 			return MV_ERROR;
 		if (mv_pp2x_range_validate(tbl_line, 0,
-		    MVPP2_QOS_TBL_LINE_NUM_DSCP) == MV_ERROR)
+					   MVPP2_QOS_TBL_LINE_NUM_DSCP) == MV_ERROR)
 			return MV_ERROR;
 	} else {
 		/*pri*/
 		/* TODO define 64=PRI_TBL_NUM  8=PRI_TBL_LINES */
 		if (mv_pp2x_range_validate(tbl_id, 0,
-		    MVPP2_QOS_TBL_NUM_PRI) == MV_ERROR)
+					   MVPP2_QOS_TBL_NUM_PRI) == MV_ERROR)
 			return MV_ERROR;
 		if (mv_pp2x_range_validate(tbl_line, 0,
-		    MVPP2_QOS_TBL_LINE_NUM_PRI) == MV_ERROR)
+					   MVPP2_QOS_TBL_LINE_NUM_PRI) == MV_ERROR)
 			return MV_ERROR;
 	}
 
@@ -4950,11 +4945,11 @@ int mv_pp2x_cls_c2_qos_hw_read(struct mv_pp2x_hw *hw, int tbl_id,
 	qos->tbl_line = tbl_line;
 
 	/* write index reg */
-	regVal |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
-	regVal |= (tbl_sel << MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
-	regVal |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
+	reg_val |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
+	reg_val |= (tbl_sel << MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
+	reg_val |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
 
-	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, regVal);
+	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, reg_val);
 
 	/* read data reg*/
 	qos->data = mv_pp2x_read(hw, MVPP2_CLS2_QOS_TBL_REG);
@@ -4965,7 +4960,7 @@ int mv_pp2x_cls_c2_qos_hw_read(struct mv_pp2x_hw *hw, int tbl_id,
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2QosPrioGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *prio)
+int mv_pp2_cls_c2_qos_prio_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *prio)
 {
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -4977,11 +4972,11 @@ int mvPp2ClsC2QosPrioGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *prio)
 		MVPP2_CLS2_QOS_TBL_PRI_OFF;
 	return MV_OK;
 }
-EXPORT_SYMBOL(mvPp2ClsC2QosPrioGet);
+EXPORT_SYMBOL(mv_pp2_cls_c2_qos_prio_get);
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2QosDscpGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *dscp)
+int mv_pp2_cls_c2_qos_dscp_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *dscp)
 {
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -4993,11 +4988,11 @@ int mvPp2ClsC2QosDscpGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *dscp)
 		MVPP2_CLS2_QOS_TBL_DSCP_OFF;
 	return MV_OK;
 }
-EXPORT_SYMBOL(mvPp2ClsC2QosDscpGet);
+EXPORT_SYMBOL(mv_pp2_cls_c2_qos_dscp_get);
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2QosColorGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *color)
+int mv_pp2_cls_c2_qos_color_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *color)
 {
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -5009,11 +5004,11 @@ int mvPp2ClsC2QosColorGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *color)
 		MVPP2_CLS2_QOS_TBL_COLOR_OFF;
 	return MV_OK;
 }
-EXPORT_SYMBOL(mvPp2ClsC2QosColorGet);
+EXPORT_SYMBOL(mv_pp2_cls_c2_qos_color_get);
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2QosGpidGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *gpid)
+int mv_pp2_cls_c2_qos_gpid_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *gpid)
 {
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -5025,11 +5020,11 @@ int mvPp2ClsC2QosGpidGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *gpid)
 		MVPP2_CLS2_QOS_TBL_GEMPORT_OFF;
 	return MV_OK;
 }
-EXPORT_SYMBOL(mvPp2ClsC2QosGpidGet);
+EXPORT_SYMBOL(mv_pp2_cls_c2_qos_gpid_get);
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2QosQueueGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue)
+int mv_pp2_cls_c2_qos_queue_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue)
 {
 	if (mv_pp2x_ptr_validate(qos) == MV_ERROR)
 		return MV_ERROR;
@@ -5041,7 +5036,7 @@ int mvPp2ClsC2QosQueueGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue)
 		MVPP2_CLS2_QOS_TBL_QUEUENUM_OFF;
 	return MV_OK;
 }
-EXPORT_SYMBOL(mvPp2ClsC2QosQueueGet);
+EXPORT_SYMBOL(mv_pp2_cls_c2_qos_queue_get);
 
 /*----------------------------------------------------------------------*/
 /*	Classifier C2 engine TCAM table Public APIs			*/
@@ -5053,8 +5048,8 @@ int mvPp2ClsC2QosQueueGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue)
 int mv_pp2x_cls_c2_hw_read(struct mv_pp2x_hw *hw, int index,
 			   struct mv_pp2x_cls_c2_entry *c2)
 {
-	unsigned int regVal;
-	int	TcmIdx;
+	unsigned int reg_val;
+	int	tcm_idx;
 
 	if (mv_pp2x_ptr_validate(c2) == MV_ERROR)
 		return MV_ERROR;
@@ -5065,16 +5060,16 @@ int mv_pp2x_cls_c2_hw_read(struct mv_pp2x_hw *hw, int index,
 	mv_pp2x_write(hw, MVPP2_CLS2_TCAM_IDX_REG, index);
 
 	/* read inValid bit*/
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_TCAM_INV_REG);
-	c2->inv = (regVal & MVPP2_CLS2_TCAM_INV_INVALID_MASK) >>
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_TCAM_INV_REG);
+	c2->inv = (reg_val & MVPP2_CLS2_TCAM_INV_INVALID_MASK) >>
 		MVPP2_CLS2_TCAM_INV_INVALID_OFF;
 
 	if (c2->inv)
 		return MV_OK;
 
-	for (TcmIdx = 0; TcmIdx < MVPP2_CLS_C2_TCAM_WORDS; TcmIdx++)
-		c2->tcam.words[TcmIdx] = mv_pp2x_read(hw,
-					MVPP2_CLS2_TCAM_DATA_REG(TcmIdx));
+	for (tcm_idx = 0; tcm_idx < MVPP2_CLS_C2_TCAM_WORDS; tcm_idx++)
+		c2->tcam.words[tcm_idx] = mv_pp2x_read(hw,
+					MVPP2_CLS2_TCAM_DATA_REG(tcm_idx));
 
 	/* read action_tbl 0x1B30 */
 	c2->sram.regs.action_tbl = mv_pp2x_read(hw, MVPP2_CLS2_ACT_DATA_REG);
@@ -5100,8 +5095,8 @@ int mv_pp2x_cls_c2_hw_read(struct mv_pp2x_hw *hw, int index,
 
 /*----------------------------------------------------------------------*/
 
-int mvPp2ClsC2TcamByteGet(struct mv_pp2x_cls_c2_entry *c2,
-			  unsigned int offs, unsigned char *byte,
+int mv_pp2_cls_c2_tcam_byte_get(struct mv_pp2x_cls_c2_entry *c2,
+				unsigned int offs, unsigned char *byte,
 			  unsigned char *enable)
 {
 	if (mv_pp2x_ptr_validate(c2) == MV_ERROR)
@@ -5129,13 +5124,13 @@ int mvPp2ClsC2TcamByteGet(struct mv_pp2x_cls_c2_entry *c2,
 
 int mv_pp2x_cls_c2_hit_cntr_is_busy(struct mv_pp2x_hw *hw)
 {
-	unsigned int regVal;
+	unsigned int reg_val;
 
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_HIT_CTR_REG);
-	regVal &= MVPP2_CLS2_HIT_CTR_CLR_DONE_MASK;
-	regVal >>= MVPP2_CLS2_HIT_CTR_CLR_DONE_OFF;
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_HIT_CTR_REG);
+	reg_val &= MVPP2_CLS2_HIT_CTR_CLR_DONE_MASK;
+	reg_val >>= MVPP2_CLS2_HIT_CTR_CLR_DONE_OFF;
 
-	return (1 - (int)regVal);
+	return (1 - (int)reg_val);
 }
 
 /*----------------------------------------------------------------------*/
@@ -5146,7 +5141,7 @@ int mv_pp2x_cls_c2_hit_cntr_clear_all(struct mv_pp2x_hw *hw)
 
 	/* wrirte clear bit*/
 	mv_pp2x_write(hw, MVPP2_CLS2_HIT_CTR_CLR_REG,
-		(1 << MVPP2_CLS2_HIT_CTR_CLR_CLR_OFF));
+		      (1 << MVPP2_CLS2_HIT_CTR_CLR_CLR_OFF));
 
 	while (mv_pp2x_cls_c2_hit_cntr_is_busy(hw))
 		if (iter++ >= RETRIES_EXCEEDED) {
@@ -5215,7 +5210,7 @@ void mv_pp2x_cls_flow_tbl_temp_copy(struct mv_pp2x_hw *hw, int lkpid,
 	int flow_start = hw->cls_shadow->flow_free_start;
 	struct mv_pp2x_cls_flow_info *flow_info;
 
-	flow_info = &(hw->cls_shadow->flow_info[index]);
+	flow_info = &hw->cls_shadow->flow_info[index];
 
 	if (flow_info->flow_entry_dflt) {
 		mv_pp2x_cls_flow_read(hw, flow_info->flow_entry_dflt, &fe);
@@ -5250,7 +5245,7 @@ void mv_pp2x_cls_flow_tbl_temp_copy(struct mv_pp2x_hw *hw, int lkpid,
 int mv_pp2x_cls_c2_hw_write(struct mv_pp2x_hw *hw, int index,
 			    struct mv_pp2x_cls_c2_entry *c2)
 {
-	int TcmIdx;
+	int tcm_idx;
 
 	if (!c2 || index >= MVPP2_CLS_C2_TCAM_SIZE)
 		return -EINVAL;
@@ -5263,11 +5258,11 @@ int mv_pp2x_cls_c2_hw_write(struct mv_pp2x_hw *hw, int index,
 	/* write valid bit*/
 	c2->inv = 0;
 	mv_pp2x_write(hw, MVPP2_CLS2_TCAM_INV_REG,
-		((c2->inv) << MVPP2_CLS2_TCAM_INV_INVALID_OFF));
+		      ((c2->inv) << MVPP2_CLS2_TCAM_INV_INVALID_OFF));
 
-	for (TcmIdx = 0; TcmIdx < MVPP2_CLS_C2_TCAM_WORDS; TcmIdx++)
-		mv_pp2x_write(hw, MVPP2_CLS2_TCAM_DATA_REG(TcmIdx),
-			c2->tcam.words[TcmIdx]);
+	for (tcm_idx = 0; tcm_idx < MVPP2_CLS_C2_TCAM_WORDS; tcm_idx++)
+		mv_pp2x_write(hw, MVPP2_CLS2_TCAM_DATA_REG(tcm_idx),
+			      c2->tcam.words[tcm_idx]);
 
 	/* write action_tbl CLSC2_ACT_DATA */
 	mv_pp2x_write(hw, MVPP2_CLS2_ACT_DATA_REG, c2->sram.regs.action_tbl);
@@ -5291,7 +5286,7 @@ int mv_pp2x_cls_c2_hw_write(struct mv_pp2x_hw *hw, int index,
 int mv_pp2x_cls_c2_qos_hw_write(struct mv_pp2x_hw *hw,
 				struct mv_pp2x_cls_c2_qos_entry *qos)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (!qos || qos->tbl_sel > MVPP2_QOS_TBL_SEL_DSCP)
 		return -EINVAL;
@@ -5299,19 +5294,19 @@ int mv_pp2x_cls_c2_qos_hw_write(struct mv_pp2x_hw *hw,
 	if (qos->tbl_sel == MVPP2_QOS_TBL_SEL_DSCP) {
 		/*dscp*/
 		if (qos->tbl_id >=  MVPP2_QOS_TBL_NUM_DSCP ||
-			qos->tbl_line >= MVPP2_QOS_TBL_LINE_NUM_DSCP)
+		    qos->tbl_line >= MVPP2_QOS_TBL_LINE_NUM_DSCP)
 			return -EINVAL;
 	} else {
 		/*pri*/
 		if (qos->tbl_id >=  MVPP2_QOS_TBL_NUM_PRI ||
-			qos->tbl_line >= MVPP2_QOS_TBL_LINE_NUM_PRI)
+		    qos->tbl_line >= MVPP2_QOS_TBL_LINE_NUM_PRI)
 			return -EINVAL;
 	}
 	/* write index reg */
-	regVal |= (qos->tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
-	regVal |= (qos->tbl_sel << MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
-	regVal |= (qos->tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
-	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, regVal);
+	reg_val |= (qos->tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
+	reg_val |= (qos->tbl_sel << MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
+	reg_val |= (qos->tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
+	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, reg_val);
 
 	/* write data reg*/
 	mv_pp2x_write(hw, MVPP2_CLS2_QOS_TBL_REG, qos->data);
@@ -5421,7 +5416,7 @@ int mv_pp2x_cls_c2_prio_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
 			    int prio, int from)
 {
 	if (!c2 || cmd > MVPP2_ACTION_TYPE_UPDT_LOCK ||
-			prio >= MVPP2_QOS_TBL_LINE_NUM_PRI)
+	    prio >= MVPP2_QOS_TBL_LINE_NUM_PRI)
 		return -EINVAL;
 
 	/*set command*/
@@ -5448,7 +5443,7 @@ int mv_pp2x_cls_c2_dscp_set(struct mv_pp2x_cls_c2_entry *c2,
 			    int cmd, int dscp, int from)
 {
 	if (!c2 || cmd > MVPP2_ACTION_TYPE_UPDT_LOCK ||
-			dscp >= MVPP2_QOS_TBL_LINE_NUM_DSCP)
+	    dscp >= MVPP2_QOS_TBL_LINE_NUM_DSCP)
 		return -EINVAL;
 
 	/*set command*/
@@ -5476,7 +5471,7 @@ int mv_pp2x_cls_c2_queue_low_set(struct mv_pp2x_cls_c2_entry *c2,
 				 int cmd, int queue, int from)
 {
 	if (!c2 || cmd > MVPP2_ACTION_TYPE_UPDT_LOCK ||
-			queue >= (1 << MVPP2_CLS2_ACT_QOS_ATTR_QL_BITS))
+	    queue >= (1 << MVPP2_CLS2_ACT_QOS_ATTR_QL_BITS))
 		return -EINVAL;
 
 	/*set command*/
@@ -5504,7 +5499,7 @@ int mv_pp2x_cls_c2_queue_high_set(struct mv_pp2x_cls_c2_entry *c2,
 				  int cmd, int queue, int from)
 {
 	if (!c2 || cmd > MVPP2_ACTION_TYPE_UPDT_LOCK ||
-			queue >= (1 << MVPP2_CLS2_ACT_QOS_ATTR_QH_BITS))
+	    queue >= (1 << MVPP2_CLS2_ACT_QOS_ATTR_QH_BITS))
 		return -EINVAL;
 
 	/*set command*/
@@ -5616,7 +5611,7 @@ static int mv_pp2x_c2_tcam_set(struct mv_pp2x_hw *hw,
 
 	/* Set QOS table, selection and ID */
 	ret_code = mv_pp2x_cls_c2_qos_tbl_set(&c2_entry,
-					c2_add_entry->qos_info.qos_tbl_index,
+					      c2_add_entry->qos_info.qos_tbl_index,
 					c2_add_entry->qos_info.qos_tbl_type);
 	if (ret_code)
 		return ret_code;
@@ -5654,7 +5649,7 @@ static int mv_pp2x_c2_tcam_set(struct mv_pp2x_hw *hw,
 
 	/* Set queue high, cmd, value and source */
 	ret_code = mv_pp2x_cls_c2_queue_high_set(&c2_entry,
-					c2_add_entry->action.q_high_act,
+						 c2_add_entry->action.q_high_act,
 					c2_add_entry->qos_value.q_high,
 					c2_add_entry->qos_info.q_high_src);
 	if (ret_code)
@@ -5760,7 +5755,7 @@ static int mv_pp2x_c2_rule_add(struct mv_pp2x_port *port,
 	bool first_free_update = false;
 	struct mv_pp2x_c2_rule_idx *rule_idx;
 
-	rule_idx = &(port->priv->hw.c2_shadow->rule_idx_info[port->id]);
+	rule_idx = &port->priv->hw.c2_shadow->rule_idx_info[port->id];
 
 	if (!port || !c2_add_entry)
 		return -EINVAL;
@@ -5830,7 +5825,6 @@ static void mv_pp2x_cls_c2_qos_tbl_fill(struct mv_pp2x_port *port,
 	u32 pri, line_num;
 	u8 cos_value, cos_queue, queue;
 
-
 	if (tbl_sel == MVPP2_QOS_TBL_SEL_PRI)
 		line_num = MVPP2_QOS_TBL_LINE_NUM_PRI;
 	else
@@ -5957,15 +5951,15 @@ int mv_pp2x_cls_c2_rule_set(struct mv_pp2x_port *port, u8 start_queue)
 /* The function get the queue in the C2 rule with input index */
 u8 mv_pp2x_cls_c2_rule_queue_get(struct mv_pp2x_hw *hw, u32 rule_idx)
 {
-	u32 regVal;
+	u32 reg_val;
 	u8 queue;
 
 	/* Write index reg */
 	mv_pp2x_write(hw, MVPP2_CLS2_TCAM_IDX_REG, rule_idx);
 
 	/* Read Reg CLSC2_ATTR0 */
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG);
-	queue = (regVal & (MVPP2_CLS2_ACT_QOS_ATTR_QL_MASK |
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG);
+	queue = (reg_val & (MVPP2_CLS2_ACT_QOS_ATTR_QL_MASK |
 			MVPP2_CLS2_ACT_QOS_ATTR_QH_MASK)) >>
 			MVPP2_CLS2_ACT_QOS_ATTR_QL_OFF;
 	return queue;
@@ -5975,20 +5969,20 @@ u8 mv_pp2x_cls_c2_rule_queue_get(struct mv_pp2x_hw *hw, u32 rule_idx)
 void mv_pp2x_cls_c2_rule_queue_set(struct mv_pp2x_hw *hw, u32 rule_idx,
 				   u8 queue)
 {
-	u32 regVal;
+	u32 reg_val;
 
 	/* Write index reg */
 	mv_pp2x_write(hw, MVPP2_CLS2_TCAM_IDX_REG, rule_idx);
 
 	/* Read Reg CLSC2_ATTR0 */
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG);
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG);
 	/* Update Value */
-	regVal &= (~(MVPP2_CLS2_ACT_QOS_ATTR_QL_MASK |
+	reg_val &= (~(MVPP2_CLS2_ACT_QOS_ATTR_QL_MASK |
 			MVPP2_CLS2_ACT_QOS_ATTR_QH_MASK));
-	regVal |= (((u32)queue) << MVPP2_CLS2_ACT_QOS_ATTR_QL_OFF);
+	reg_val |= (((u32)queue) << MVPP2_CLS2_ACT_QOS_ATTR_QL_OFF);
 
 	/* Write Reg CLSC2_ATTR0 */
-	mv_pp2x_write(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG, regVal);
+	mv_pp2x_write(hw, MVPP2_CLS2_ACT_QOS_ATTR_REG, reg_val);
 }
 
 /* The function get the queue in the pbit table entry */
@@ -5996,17 +5990,17 @@ u8 mv_pp2x_cls_c2_pbit_tbl_queue_get(struct mv_pp2x_hw *hw, u8 tbl_id,
 				     u8 tbl_line)
 {
 	u8 queue;
-	u32 regVal = 0;
+	u32 reg_val = 0;
 
 	/* write index reg */
-	regVal |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
-	regVal |= (MVPP2_QOS_TBL_SEL_PRI <<
+	reg_val |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
+	reg_val |= (MVPP2_QOS_TBL_SEL_PRI <<
 			MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
-	regVal |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
-	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, regVal);
+	reg_val |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
+	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, reg_val);
 	/* Read Reg CLSC2_DSCP_PRI */
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_QOS_TBL_REG);
-	queue = (regVal &  MVPP2_CLS2_QOS_TBL_QUEUENUM_MASK) >>
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_QOS_TBL_REG);
+	queue = (reg_val &  MVPP2_CLS2_QOS_TBL_QUEUENUM_MASK) >>
 			MVPP2_CLS2_QOS_TBL_QUEUENUM_OFF;
 
 	return queue;
@@ -6016,22 +6010,22 @@ u8 mv_pp2x_cls_c2_pbit_tbl_queue_get(struct mv_pp2x_hw *hw, u8 tbl_id,
 void mv_pp2x_cls_c2_pbit_tbl_queue_set(struct mv_pp2x_hw *hw,
 				       u8 tbl_id, u8 tbl_line, u8 queue)
 {
-	u32 regVal = 0;
+	u32 reg_val = 0;
 
 	/* write index reg */
-	regVal |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
-	regVal |=
+	reg_val |= (tbl_line << MVPP2_CLS2_DSCP_PRI_INDEX_LINE_OFF);
+	reg_val |=
 		(MVPP2_QOS_TBL_SEL_PRI << MVPP2_CLS2_DSCP_PRI_INDEX_SEL_OFF);
-	regVal |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
-	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, regVal);
+	reg_val |= (tbl_id << MVPP2_CLS2_DSCP_PRI_INDEX_TBL_ID_OFF);
+	mv_pp2x_write(hw, MVPP2_CLS2_DSCP_PRI_INDEX_REG, reg_val);
 
 	/* Read Reg CLSC2_DSCP_PRI */
-	regVal = mv_pp2x_read(hw, MVPP2_CLS2_QOS_TBL_REG);
-	regVal &= (~MVPP2_CLS2_QOS_TBL_QUEUENUM_MASK);
-	regVal |= (((u32)queue) << MVPP2_CLS2_QOS_TBL_QUEUENUM_OFF);
+	reg_val = mv_pp2x_read(hw, MVPP2_CLS2_QOS_TBL_REG);
+	reg_val &= (~MVPP2_CLS2_QOS_TBL_QUEUENUM_MASK);
+	reg_val |= (((u32)queue) << MVPP2_CLS2_QOS_TBL_QUEUENUM_OFF);
 
 	/* Write Reg CLSC2_DSCP_PRI */
-	mv_pp2x_write(hw, MVPP2_CLS2_QOS_TBL_REG, regVal);
+	mv_pp2x_write(hw, MVPP2_CLS2_QOS_TBL_REG, reg_val);
 }
 
 /* RSS */
@@ -6039,7 +6033,7 @@ void mv_pp2x_cls_c2_pbit_tbl_queue_set(struct mv_pp2x_hw *hw,
 int mv_pp22_rss_tbl_entry_set(struct mv_pp2x_hw *hw,
 			      struct mv_pp22_rss_entry *rss)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (!rss || rss->sel > MVPP22_RSS_ACCESS_TBL)
 		return -EINVAL;
@@ -6048,31 +6042,31 @@ int mv_pp22_rss_tbl_entry_set(struct mv_pp2x_hw *hw,
 		if (rss->u.pointer.rss_tbl_ptr >= MVPP22_RSS_TBL_NUM)
 			return -EINVAL;
 		/* Write index */
-		regVal |= rss->u.pointer.rxq_idx <<
+		reg_val |= rss->u.pointer.rxq_idx <<
 				MVPP22_RSS_IDX_RXQ_NUM_OFF;
-		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, regVal);
+		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, reg_val);
 		/* Write entry */
-		regVal &= (~MVPP22_RSS_RXQ2RSS_TBL_POINT_MASK);
-		regVal |= rss->u.pointer.rss_tbl_ptr <<
+		reg_val &= (~MVPP22_RSS_RXQ2RSS_TBL_POINT_MASK);
+		reg_val |= rss->u.pointer.rss_tbl_ptr <<
 				MVPP22_RSS_RXQ2RSS_TBL_POINT_OFF;
-		mv_pp2x_write(hw, MVPP22_RSS_RXQ2RSS_TBL_REG, regVal);
+		mv_pp2x_write(hw, MVPP22_RSS_RXQ2RSS_TBL_REG, reg_val);
 	} else if (rss->sel == MVPP22_RSS_ACCESS_TBL) {
 		if (rss->u.entry.tbl_id >= MVPP22_RSS_TBL_NUM ||
 		    rss->u.entry.tbl_line >= MVPP22_RSS_TBL_LINE_NUM ||
 		    rss->u.entry.width >= MVPP22_RSS_WIDTH_MAX)
 			return -EINVAL;
 		/* Write index */
-		regVal |= (rss->u.entry.tbl_line <<
+		reg_val |= (rss->u.entry.tbl_line <<
 				MVPP22_RSS_IDX_ENTRY_NUM_OFF |
 			   rss->u.entry.tbl_id << MVPP22_RSS_IDX_TBL_NUM_OFF);
-		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, regVal);
+		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, reg_val);
 		/* Write entry */
-		regVal &= (~MVPP22_RSS_TBL_ENTRY_MASK);
-		regVal |= (rss->u.entry.rxq << MVPP22_RSS_TBL_ENTRY_OFF);
-		mv_pp2x_write(hw, MVPP22_RSS_TBL_ENTRY_REG, regVal);
-		regVal &= (~MVPP22_RSS_WIDTH_MASK);
-		regVal |= (rss->u.entry.width << MVPP22_RSS_WIDTH_OFF);
-		mv_pp2x_write(hw, MVPP22_RSS_WIDTH_REG, regVal);
+		reg_val &= (~MVPP22_RSS_TBL_ENTRY_MASK);
+		reg_val |= (rss->u.entry.rxq << MVPP22_RSS_TBL_ENTRY_OFF);
+		mv_pp2x_write(hw, MVPP22_RSS_TBL_ENTRY_REG, reg_val);
+		reg_val &= (~MVPP22_RSS_WIDTH_MASK);
+		reg_val |= (rss->u.entry.width << MVPP22_RSS_WIDTH_OFF);
+		mv_pp2x_write(hw, MVPP22_RSS_WIDTH_REG, reg_val);
 	}
 	return 0;
 }
@@ -6081,7 +6075,7 @@ int mv_pp22_rss_tbl_entry_set(struct mv_pp2x_hw *hw,
 int mv_pp22_rss_tbl_entry_get(struct mv_pp2x_hw *hw,
 			      struct mv_pp22_rss_entry *rss)
 {
-	unsigned int regVal = 0;
+	unsigned int reg_val = 0;
 
 	if (!rss || rss->sel > MVPP22_RSS_ACCESS_TBL)
 		return -EINVAL;
@@ -6096,11 +6090,11 @@ int mv_pp22_rss_tbl_entry_get(struct mv_pp2x_hw *hw,
 		    rss->u.entry.tbl_line >= MVPP22_RSS_TBL_LINE_NUM)
 			return -EINVAL;
 		/* Read index */
-		regVal |= (rss->u.entry.tbl_line <<
+		reg_val |= (rss->u.entry.tbl_line <<
 				MVPP22_RSS_IDX_ENTRY_NUM_OFF |
 			   rss->u.entry.tbl_id <<
 				MVPP22_RSS_IDX_TBL_NUM_OFF);
-		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, regVal);
+		mv_pp2x_write(hw, MVPP22_RSS_IDX_REG, reg_val);
 		/* Read entry */
 		rss->u.entry.rxq = mv_pp2x_read(hw,
 						MVPP22_RSS_TBL_ENTRY_REG) &
@@ -6162,7 +6156,7 @@ void mv_pp22_rss_c2_enable(struct mv_pp2x_port *port, bool en)
 	int c2_index[MVPP2_CLS_LKP_MAX];
 	struct mv_pp2x_c2_rule_idx *rule_idx;
 
-	rule_idx = &(port->priv->hw.c2_shadow->rule_idx_info[port->id]);
+	rule_idx = &port->priv->hw.c2_shadow->rule_idx_info[port->id];
 
 	/* Get the C2 index from shadow */
 	c2_index[MVPP2_CLS_LKP_VLAN_PRI] = rule_idx->vlan_pri_idx;
@@ -6197,7 +6191,6 @@ void mv_pp2x_tx_fifo_threshold_set(struct mv_pp2x_hw *hw, u32 port_id, u32 val)
 /* Check number of buffers in BM pool */
 int mv_pp2x_check_hw_buf_num(struct mv_pp2x *priv, struct mv_pp2x_bm_pool *bm_pool)
 {
-
 	int buf_num = 0;
 
 	buf_num += mv_pp2x_read(&priv->hw, MVPP2_BM_POOL_PTRS_NUM_REG(bm_pool->id))
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.h b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.h
index a780e8b..790ee39 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw.h
@@ -35,7 +35,7 @@ static inline void mv_pp2x_write(struct mv_pp2x_hw *hw, u32 offset, u32 data)
 }
 
 static inline void mv_pp2x_relaxed_write(struct mv_pp2x_hw *hw, u32 offset, u32 data,
-					int cpu)
+					 int cpu)
 {
 	void *reg_ptr = hw->cpu_base[cpu] + offset;
 
@@ -64,39 +64,39 @@ static inline u32 mv_pp2x_relaxed_read(struct mv_pp2x_hw *hw, u32 offset, int cp
 }
 
 static inline void mv_pp22_thread_write(struct mv_pp2x_hw *hw, u32 sw_thread,
-					     u32 offset, u32 data)
+					u32 offset, u32 data)
 {
-	writel(data, hw->base + sw_thread*MVPP2_ADDR_SPACE_SIZE + offset);
+	writel(data, hw->base + sw_thread * MVPP2_ADDR_SPACE_SIZE + offset);
 }
 
 static inline u32 mv_pp22_thread_read(struct mv_pp2x_hw *hw, u32 sw_thread,
-					    u32 offset)
+				      u32 offset)
 {
-	return readl(hw->base + sw_thread*MVPP2_ADDR_SPACE_SIZE + offset);
+	return readl(hw->base + sw_thread * MVPP2_ADDR_SPACE_SIZE + offset);
 }
 
 static inline void mv_pp22_thread_relaxed_write(struct mv_pp2x_hw *hw,
 						u32 sw_thread,
 						u32 offset, u32 data)
 {
-	writel_relaxed(data, hw->base + sw_thread*MVPP2_ADDR_SPACE_SIZE + offset);
+	writel_relaxed(data, hw->base + sw_thread * MVPP2_ADDR_SPACE_SIZE + offset);
 }
 
 static inline u32 mv_pp22_thread_relaxed_read(struct mv_pp2x_hw *hw,
 					      u32 sw_thread,
 					      u32 offset)
 {
-	return readl_relaxed(hw->base + sw_thread*MVPP2_ADDR_SPACE_SIZE + offset);
+	return readl_relaxed(hw->base + sw_thread * MVPP2_ADDR_SPACE_SIZE + offset);
 }
 
 static inline void mv_pp21_isr_rx_group_write(struct mv_pp2x_hw *hw, int port,
-						    int num_rx_queues)
+					      int num_rx_queues)
 {
 	mv_pp2x_write(hw, MVPP21_ISR_RXQ_GROUP_REG(port), num_rx_queues);
 }
 
 static inline void mv_pp22_isr_rx_group_write(struct mv_pp2x_hw *hw, int port,
-						    int sub_group,
+					      int sub_group,
 						    int start_queue,
 						    int num_rx_queues)
 {
@@ -107,7 +107,6 @@ static inline void mv_pp22_isr_rx_group_write(struct mv_pp2x_hw *hw, int port,
 	val = (num_rx_queues << MVPP22_ISR_RXQ_SUB_GROUP_SIZE_OFFSET) |
 		start_queue;
 	mv_pp2x_write(hw, MVPP22_ISR_RXQ_SUB_GROUP_CONFIG_REG, val);
-
 }
 
 /* Get number of physical egress port */
@@ -145,7 +144,7 @@ static inline int mv_pp2x_rxq_free(struct mv_pp2x_port *port, int rxq_id)
  * Rx descriptor slots.
  */
 static inline void mv_pp2x_rxq_status_update(struct mv_pp2x_port *port,
-						    int rxq_id,
+					     int rxq_id,
 						    int used_count,
 						    int free_count)
 {
@@ -176,7 +175,7 @@ static inline void mv_pp2x_interrupts_mask(void *arg)
 {
 	struct mv_pp2x_port *port = arg;
 
-	mv_pp2x_write(&(port->priv->hw), MVPP2_ISR_RX_TX_MASK_REG(port->id), 0);
+	mv_pp2x_write(&port->priv->hw, MVPP2_ISR_RX_TX_MASK_REG(port->id), 0);
 }
 
 /* Unmask the current CPU's Rx/Tx interrupts */
@@ -186,10 +185,10 @@ static inline void mv_pp2x_interrupts_unmask(void *arg)
 	u32 val;
 
 	val = MVPP2_CAUSE_MISC_SUM_MASK | MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK;
-	if (port->priv->pp2xdata->interrupt_tx_done == true)
+	if (port->priv->pp2xdata->interrupt_tx_done)
 		val |= MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
 
-	mv_pp2x_write(&(port->priv->hw),
+	mv_pp2x_write(&port->priv->hw,
 		      MVPP2_ISR_RX_TX_MASK_REG(port->id), val);
 }
 
@@ -199,7 +198,7 @@ static inline void mv_pp2x_shared_thread_interrupts_mask(
 	struct queue_vector *q_vec = &port->q_vector[0];
 	int i;
 
-	if (port->priv->pp2xdata->multi_addr_space == false)
+	if (!port->priv->pp2xdata->multi_addr_space)
 		return;
 
 	for (i = 0; i < port->num_qvector; i++) {
@@ -218,7 +217,7 @@ static inline void mv_pp2x_shared_thread_interrupts_unmask(
 	struct queue_vector *q_vec = &port->q_vector[0];
 	int i;
 
-	if (port->priv->pp2xdata->multi_addr_space == false)
+	if (!port->priv->pp2xdata->multi_addr_space)
 		return;
 
 	for (i = 0; i < port->num_qvector; i++) {
@@ -266,7 +265,7 @@ static inline dma_addr_t mv_pp2x_bm_phys_addr_get(struct mv_pp2x_hw *hw, u32 poo
 }
 
 static inline void mv_pp2x_bm_hw_pool_create(struct mv_pp2x_hw *hw,
-						      u32 pool,
+					     u32 pool,
 						      dma_addr_t pool_addr,
 						      int size)
 {
@@ -286,44 +285,43 @@ static inline void mv_pp2x_bm_hw_pool_create(struct mv_pp2x_hw *hw,
 }
 
 static inline void mv_pp2x_bm_pool_put_virtual(struct mv_pp2x_hw *hw, u32 pool,
-					      dma_addr_t buf_phys_addr,
+					       dma_addr_t buf_phys_addr,
 					      u8 *buf_virt_addr, int cpu)
 {
 	mv_pp2x_relaxed_write(hw, MVPP2_BM_VIRT_RLS_REG,
 			      lower_32_bits((uintptr_t)buf_virt_addr), cpu);
 
 	mv_pp2x_relaxed_write(hw, MVPP2_BM_PHY_RLS_REG(pool),
-				lower_32_bits(buf_phys_addr), cpu);
+			      lower_32_bits(buf_phys_addr), cpu);
 }
 
 /* Release buffer to BM */
 static inline void mv_pp2x_bm_pool_put(struct mv_pp2x_hw *hw, u32 pool,
-					      dma_addr_t buf_phys_addr, int cpu)
+				       dma_addr_t buf_phys_addr, int cpu)
 {
-
 #if defined(CONFIG_ARCH_DMA_ADDR_T_64BIT) && defined(CONFIG_PHYS_ADDR_T_64BIT)
 	mv_pp2x_relaxed_write(hw, MVPP22_BM_PHY_VIRT_HIGH_RLS_REG,
-			upper_32_bits(buf_phys_addr), cpu);
+			      upper_32_bits(buf_phys_addr), cpu);
 #endif
 
 	mv_pp2x_relaxed_write(hw, MVPP2_BM_PHY_RLS_REG(pool),
-				lower_32_bits(buf_phys_addr), cpu);
+			      lower_32_bits(buf_phys_addr), cpu);
 }
 
 /* Release multicast buffer */
 static inline void mv_pp2x_bm_pool_mc_put(struct mv_pp2x_port *port, int pool,
-						   u32 buf_phys_addr,
+					  u32 buf_phys_addr,
 						   u32 buf_virt_addr,
 						   int mc_id, int cpu)
 {
 	u32 val = 0;
 
 	val |= (mc_id & MVPP21_BM_MC_ID_MASK);
-	mv_pp2x_write(&(port->priv->hw), MVPP21_BM_MC_RLS_REG, val);
+	mv_pp2x_write(&port->priv->hw, MVPP21_BM_MC_RLS_REG, val);
 	/*TODO : YuvalC, this is just workaround to compile.
 	 * Need to handle mv_pp2x_buff_hdr_rx().
 	 */
-	mv_pp2x_bm_pool_put(&(port->priv->hw), pool,
+	mv_pp2x_bm_pool_put(&port->priv->hw, pool,
 			    (dma_addr_t)(buf_phys_addr |
 			    MVPP2_BM_PHY_RLS_MC_BUFF_MASK), cpu);
 }
@@ -351,7 +349,6 @@ static inline void mv_pp2x_port_interrupts_disable(struct mv_pp2x_port *port)
 		      MVPP2_ISR_DISABLE_INTERRUPT(sw_thread_mask));
 }
 
-
 static inline void mv_pp2x_qvector_interrupt_enable(struct queue_vector *q_vec)
 {
 	struct mv_pp2x_port *port = q_vec->parent;
@@ -366,7 +363,6 @@ static inline void mv_pp2x_qvector_interrupt_disable(struct queue_vector *q_vec)
 
 	mv_pp2x_write(&port->priv->hw, MVPP2_ISR_ENABLE_REG(port->id),
 		      MVPP2_ISR_DISABLE_INTERRUPT(q_vec->sw_thread_mask));
-
 }
 
 static inline u32 mv_pp2x_qvector_interrupt_state_get(struct queue_vector
@@ -390,7 +386,7 @@ static inline int mv_pp2x_txq_sent_desc_proc(struct mv_pp2x_port *port,
 	if (port->priv->pp2_version == PPV21) {
 		sw_thread = 0;
 		val = mv_pp22_thread_relaxed_read(&port->priv->hw,
-							sw_thread,
+						  sw_thread,
 							MVPP21_TXQ_SENT_REG(txq_id));
 		return (val & MVPP21_TRANSMITTED_COUNT_MASK) >>
 			MVPP21_TRANSMITTED_COUNT_OFFSET;
@@ -402,7 +398,6 @@ static inline int mv_pp2x_txq_sent_desc_proc(struct mv_pp2x_port *port,
 		return (val & MVPP22_TRANSMITTED_COUNT_MASK) >>
 			MVPP22_TRANSMITTED_COUNT_OFFSET;
 		}
-
 }
 
 static inline void mv_pp2x_txq_desc_put(struct mv_pp2x_tx_queue *txq)
@@ -413,7 +408,6 @@ static inline void mv_pp2x_txq_desc_put(struct mv_pp2x_tx_queue *txq)
 		txq->next_desc_to_proc--;
 }
 
-
 static inline void mv_pp2x_txq_sent_counter_clear(void *arg)
 {
 	struct mv_pp2x_port *port = arg;
@@ -423,10 +417,10 @@ static inline void mv_pp2x_txq_sent_counter_clear(void *arg)
 		int id = port->txqs[queue]->id;
 
 		if (port->priv->pp2_version == PPV21)
-			mv_pp2x_read(&(port->priv->hw),
+			mv_pp2x_read(&port->priv->hw,
 				     MVPP21_TXQ_SENT_REG(id));
 		else
-			mv_pp2x_read(&(port->priv->hw),
+			mv_pp2x_read(&port->priv->hw,
 				     MVPP22_TXQ_SENT_REG(id));
 	}
 }
@@ -496,15 +490,14 @@ static inline dma_addr_t mv_pp2x_txdesc_phys_addr_get(
 	return mv_pp22_txdesc_phys_addr_get(tx_desc);
 }
 
-
 static inline void mv_pp21_txdesc_phys_addr_set(dma_addr_t phys_addr,
-	struct mv_pp2x_tx_desc *tx_desc)
+						struct mv_pp2x_tx_desc *tx_desc)
 {
 	tx_desc->u.pp21.buf_phys_addr = phys_addr;
 }
 
 static inline void mv_pp22_txdesc_phys_addr_set(dma_addr_t phys_addr,
-	struct mv_pp2x_tx_desc *tx_desc)
+						struct mv_pp2x_tx_desc *tx_desc)
 {
 	u64 *buf_phys_addr_p = &tx_desc->u.pp22.buf_phys_addr_hw_cmd2;
 
@@ -518,7 +511,7 @@ static inline void mv_pp22_txdesc_phys_addr_set(dma_addr_t phys_addr,
 }
 
 static inline void mv_pp2x_txdesc_phys_addr_set(enum mvppv2_version pp2_ver,
-	dma_addr_t phys_addr, struct mv_pp2x_tx_desc *tx_desc)
+						dma_addr_t phys_addr, struct mv_pp2x_tx_desc *tx_desc)
 {
 	if (pp2_ver == PPV21)
 		mv_pp21_txdesc_phys_addr_set(phys_addr, tx_desc);
@@ -590,7 +583,7 @@ void mv_pp2x_pool_refill(struct mv_pp2x *priv, u32 pool,
 			 dma_addr_t phys_addr, int cpu);
 
 void mv_pp2x_pool_refill_virtual(struct mv_pp2x *priv, u32 pool,
-				dma_addr_t phys_addr, u8 *cookie);
+				 dma_addr_t phys_addr, u8 *cookie);
 void mv_pp21_rxq_long_pool_set(struct mv_pp2x_hw *hw,
 			       int prxq, int long_pool);
 void mv_pp21_rxq_short_pool_set(struct mv_pp2x_hw *hw,
@@ -634,7 +627,7 @@ int mv_pp2x_prs_sw_sram_shift_set(struct mv_pp2x_prs_entry *pe, int shift,
 int mv_pp2x_prs_sw_sram_shift_get(struct mv_pp2x_prs_entry *pe, int *shift);
 int mv_pp2x_prs_sw_sram_next_lu_get(struct mv_pp2x_prs_entry *pe,
 				    unsigned int *lu);
-int mv_pp2x_prs_sram_bit_get(struct mv_pp2x_prs_entry *pe, int bitNum,
+int mv_pp2x_prs_sram_bit_get(struct mv_pp2x_prs_entry *pe, int bit_num,
 			     unsigned int *bit);
 int mv_pp2x_prs_sw_sram_lu_done_get(struct mv_pp2x_prs_entry *pe,
 				    unsigned int *bit);
@@ -662,7 +655,7 @@ void mv_pp2x_prs_tcam_port_set(struct mv_pp2x_prs_entry *pe,
 void mv_pp2x_prs_tcam_port_map_set(struct mv_pp2x_prs_entry *pe,
 				   unsigned int ports);
 void mv_pp2x_prs_tcam_data_byte_set(struct mv_pp2x_prs_entry *pe,
-				   unsigned int offs,
+				    unsigned int offs,
 				   unsigned char byte,
 				   unsigned char enable);
 void mv_pp2x_prs_tcam_ai_update(struct mv_pp2x_prs_entry *pe,
@@ -738,55 +731,55 @@ int mv_pp2x_cls_c2_qos_hw_read(struct mv_pp2x_hw *hw, int tbl_id, int tbl_sel,
 			       struct mv_pp2x_cls_c2_qos_entry *qos);
 int mv_pp2x_cls_c2_qos_hw_write(struct mv_pp2x_hw *hw,
 				struct mv_pp2x_cls_c2_qos_entry *qos);
-int mvPp2ClsC2QosPrioGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *prio);
-int mvPp2ClsC2QosDscpGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *dscp);
-int mvPp2ClsC2QosColorGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *color);
-int mvPp2ClsC2QosGpidGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *gpid);
-int mvPp2ClsC2QosQueueGet(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue);
+int mv_pp2_cls_c2_qos_prio_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *prio);
+int mv_pp2_cls_c2_qos_dscp_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *dscp);
+int mv_pp2_cls_c2_qos_color_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *color);
+int mv_pp2_cls_c2_qos_gpid_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *gpid);
+int mv_pp2_cls_c2_qos_queue_get(struct mv_pp2x_cls_c2_qos_entry *qos, int *queue);
 int mv_pp2x_cls_c2_qos_tbl_set(struct mv_pp2x_cls_c2_entry *c2, int tbl_id,
-				     int tbl_sel);
+			       int tbl_sel);
 int mv_pp2x_cls_c2_hw_write(struct mv_pp2x_hw *hw, int index,
-				  struct mv_pp2x_cls_c2_entry *c2);
+			    struct mv_pp2x_cls_c2_entry *c2);
 int mv_pp2x_cls_c2_hw_read(struct mv_pp2x_hw *hw, int index,
-				  struct mv_pp2x_cls_c2_entry *c2);
+			   struct mv_pp2x_cls_c2_entry *c2);
 int mv_pp2x_cls_c2_hit_cntr_clear_all(struct mv_pp2x_hw *hw);
 int mv_pp2x_cls_c2_hit_cntr_read(struct mv_pp2x_hw *hw, int index, u32 *cntr);
 int mv_pp2x_cls_c2_rule_set(struct mv_pp2x_port *port, u8 start_queue);
 u8 mv_pp2x_cls_c2_rule_queue_get(struct mv_pp2x_hw *hw, u32 rule_idx);
 void mv_pp2x_cls_c2_rule_queue_set(struct mv_pp2x_hw *hw, u32 rule_idx,
-					   u8 queue);
+				   u8 queue);
 u8 mv_pp2x_cls_c2_pbit_tbl_queue_get(struct mv_pp2x_hw *hw, u8 tbl_id,
-					     u8 tbl_line);
+				     u8 tbl_line);
 void mv_pp2x_cls_c2_pbit_tbl_queue_set(struct mv_pp2x_hw *hw, u8 tbl_id,
-					      u8 tbl_line, u8 queue);
+				       u8 tbl_line, u8 queue);
 int mv_pp2x_cls_c2_hw_inv(struct mv_pp2x_hw *hw, int index);
 void mv_pp2x_cls_c2_hw_inv_all(struct mv_pp2x_hw *hw);
 int mv_pp2x_cls_c2_tcam_byte_set(struct mv_pp2x_cls_c2_entry *c2,
-					unsigned int offs,
+				 unsigned int offs,
 					unsigned char byte,
 					unsigned char enable);
 int mv_pp2x_cls_c2_qos_queue_set(struct mv_pp2x_cls_c2_qos_entry *qos,
-					 u8 queue);
+				 u8 queue);
 int mv_pp2x_cls_c2_color_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-				   int from);
+			     int from);
 int mv_pp2x_cls_c2_prio_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-				 int prio, int from);
+			    int prio, int from);
 int mv_pp2x_cls_c2_dscp_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-				  int dscp, int from);
+			    int dscp, int from);
 int mv_pp2x_cls_c2_queue_low_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-					 int queue, int from);
+				 int queue, int from);
 int mv_pp2x_cls_c2_queue_high_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-					  int queue, int from);
+				  int queue, int from);
 int mv_pp2x_cls_c2_forward_set(struct mv_pp2x_cls_c2_entry *c2, int cmd);
 int mv_pp2x_cls_c2_rss_set(struct mv_pp2x_cls_c2_entry *c2, int cmd,
-				 int rss_en);
+			   int rss_en);
 int mv_pp2x_cls_c2_flow_id_en(struct mv_pp2x_cls_c2_entry *c2,
-				    int flowid_en);
+			      int flowid_en);
 
 int mv_pp22_rss_tbl_entry_set(struct mv_pp2x_hw *hw,
-				struct mv_pp22_rss_entry *rss);
+			      struct mv_pp22_rss_entry *rss);
 int mv_pp22_rss_tbl_entry_get(struct mv_pp2x_hw *hw,
-				struct mv_pp22_rss_entry *rss);
+			      struct mv_pp22_rss_entry *rss);
 
 int mv_pp22_rss_rxq_set(struct mv_pp2x_port *port, u32 cos_width);
 
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw_type.h b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw_type.h
index 83d2d87..2e56db8 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw_type.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_hw_type.h
@@ -23,17 +23,17 @@
 #include <linux/skbuff.h>
 #include <linux/bitops.h>
 
-#define CREATE_MASK(pos, len)		GENMASK((pos)+(len)-1, (pos))
-#define CREATE_MASK_ULL(pos, len)	GENMASK_ULL((pos)+(len)-1, (pos))
+#define CREATE_MASK(pos, len)		GENMASK((pos) + (len) - 1, (pos))
+#define CREATE_MASK_ULL(pos, len)	GENMASK_ULL((pos) + (len) - 1, (pos))
 
 #define AUTO_MASK(reg_name)	CREATE_MASK(reg_name##_OFFS, reg_name##_SIZE)
 
 /*All PPV22 Addresses are 40-bit */
 #define MVPP22_ADDR_HIGH_SIZE			8
-#define MVPP22_ADDR_HIGH_MASK		((1<<MVPP22_ADDR_HIGH_SIZE) - 1)
+#define MVPP22_ADDR_HIGH_MASK		((1 << MVPP22_ADDR_HIGH_SIZE) - 1)
 
 /*PPV22 ADDRESS SPACE */
-#define MVPP2_ADDR_SPACE_SIZE			(64*1024)
+#define MVPP2_ADDR_SPACE_SIZE			(64 * 1024)
 
 /*TODO*/
 /*AXI_BRIDGE*/
@@ -41,7 +41,7 @@
 /*Top Regfile*/
 
 #define MVPP21_DESC_ADDR_SHIFT		0 /*Applies to RXQ, AGGR_TXQ*/
-#define MVPP22_DESC_ADDR_SHIFT		(9-1) /*Applies to RXQ, AGGR_TXQ*/
+#define MVPP22_DESC_ADDR_SHIFT		(9 - 1) /*Applies to RXQ, AGGR_TXQ*/
 
 /* RX Fifo Registers */
 #define MVPP2_RX_DATA_FIFO_SIZE_REG(port)	(0x00 + 4 * (port))
@@ -118,35 +118,29 @@
 #define MVPP22_AXI_ATTR_DOMAIN_SIZE		2
 #define MVPP22_AXI_ATTR_DOMAIN_MASK	AUTO_MASK(MVPP22_AXI_ATTR_DOMAIN)
 
-#define MVPP22_AXI_ATTR_NON_CACHE	((0x3<<MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
-					 (0x3<<MVPP22_AXI_ATTR_CACHE_OFFS))
+#define MVPP22_AXI_ATTR_NON_CACHE	((0x3 << MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
+					 (0x3 << MVPP22_AXI_ATTR_CACHE_OFFS))
 
-#define MVPP22_AXI_ATTR_SW_COH_WRITE	((0x0<<MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
-					 (0x7<<MVPP22_AXI_ATTR_CACHE_OFFS))
-
-#define MVPP22_AXI_ATTR_SW_COH_READ	((0x0<<MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
-					 (0xB<<MVPP22_AXI_ATTR_CACHE_OFFS))
-
-
-#define MVPP22_AXI_ATTR_HW_COH_WRITE	((0x2<<MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
-					 (0x7<<MVPP22_AXI_ATTR_CACHE_OFFS))
-
-#define MVPP22_AXI_ATTR_HW_COH_READ	((0x2<<MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
-					 (0xB<<MVPP22_AXI_ATTR_CACHE_OFFS))
+#define MVPP22_AXI_ATTR_SW_COH_WRITE	((0x0 << MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
+					 (0x7 << MVPP22_AXI_ATTR_CACHE_OFFS))
 
+#define MVPP22_AXI_ATTR_SW_COH_READ	((0x0 << MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
+					 (0xB << MVPP22_AXI_ATTR_CACHE_OFFS))
 
+#define MVPP22_AXI_ATTR_HW_COH_WRITE	((0x2 << MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
+					 (0x7 << MVPP22_AXI_ATTR_CACHE_OFFS))
 
+#define MVPP22_AXI_ATTR_HW_COH_READ	((0x2 << MVPP22_AXI_ATTR_DOMAIN_OFFS) + \
+					 (0xB << MVPP22_AXI_ATTR_CACHE_OFFS))
 
 #define MVPP22_AXI_ATTR_SNOOP_CNTRL_BIT		BIT(16)
 
-
 #define MVPP22_AXI_RD_NORMAL_CODE_REG		0x4150
 #define MVPP22_AXI_RD_SNOOP_CODE_REG		0x4154
 #define MVPP22_AXI_WR_NORMAL_CODE_REG		0x4160
 #define MVPP22_AXI_WR_SNOOP_CODE_REG		0x4164
 #define MVPP22_AXI_WR_DEP_CODE_REG		0x4168
 
-
 #define MVPP22_AXI_CODE_CACHE_OFFS		0
 #define MVPP22_AXI_CODE_CACHE_SIZE		4
 #define MVPP22_AXI_CODE_CACHE_MASK	AUTO_MASK(MVPP22_AXI_CODE_CACHE)
@@ -155,7 +149,6 @@
 #define MVPP22_AXI_CODE_CACHE_RD_CACHE		0xB
 #define MVPP22_AXI_CODE_CACHE_WR_CACHE		0x7
 
-
 #define MVPP22_AXI_CODE_DOMAIN_OFFS		4
 #define MVPP22_AXI_CODE_DOMAIN_SIZE		2
 #define MVPP22_AXI_CODE_DOMAIN_MASK	AUTO_MASK(MVPP22_AXI_CODE_DOMAIN)
@@ -164,8 +157,6 @@
 #define MVPP22_AXI_CODE_DOMAIN_SYSTEM		3
 #define MVPP22_AXI_CODE_DOMAIN_NON_SHARE	0
 
-
-
 /* Parser Registers */
 #define MVPP2_PRS_INIT_LOOKUP_REG		0x1000
 #define MVPP2_PRS_PORT_LU_MAX			0xf
@@ -226,7 +217,6 @@
 #define MVPP2_CLS_FLOW_TBL1_REG			0x1828
 #define MVPP2_CLS_FLOW_TBL2_REG			0x182c
 
-
 #define MVPP2_CLS_PORT_SPID_REG			0x1830
 
 #define MVPP2_CLS_PORT_SPID_BITS		2
@@ -375,7 +365,7 @@
 /* Flow counters index */
 #define MVPP2_CNT_IDX_FLOW(index)		(index)
 /* TX counters index */
-#define MVPP2_CNT_IDX_TX(port, txq)		(((16+port) << 3) | (txq))
+#define MVPP2_CNT_IDX_TX(port, txq)		(((16 + port) << 3) | (txq))
 
 #define MVPP2_TX_DESC_ENQ_REG			0x7100
 #define MVPP2_TX_DESC_ENQ_TO_DRAM_REG		0x7104
@@ -626,7 +616,7 @@
 #define MVPP2_CLS3_HASH_OP_TBL_ADDR_MASK	\
 	((MVPP2_CLS3_HASH_OP_TBL_ADDR_MAX) << MVPP2_CLS3_HASH_OP_TBL_ADDR)
 #define MVPP2_CLS3_MISS_PTR			12
-#define MVPP2_CLS3_MISS_PTR_MASK		(1 << MVPP2_CLS3_MISS_PTR)
+#define MVPP2_CLS3_MISS_PTR_MASK		BIT(MVPP2_CLS3_MISS_PTR)
 #define MVPP2_CLS3_HASH_OP_DEL			14
 #define MVPP2_CLS3_HASH_OP_ADD			15
 #define MVPP2_CLS3_HASH_OP_EXT_TBL_ADDR		16
@@ -645,7 +635,7 @@
 #define MVPP2_CLS3_STATE_CLEAR_CTR_DONE_MASK	(1 << \
 					MVPP2_CLS3_STATE_CLEAR_CTR_DONE)
 #define MVPP2_CLS3_STATE_SC_DONE		2
-#define MVPP2_CLS3_STATE_SC_DONE_MASK		(1 << MVPP2_CLS3_STATE_SC_DONE)
+#define MVPP2_CLS3_STATE_SC_DONE_MASK		BIT(MVPP2_CLS3_STATE_SC_DONE)
 #define MVPP2_CLS3_STATE_OCCIPIED		8
 #define MVPP2_CLS3_STATE_OCCIPIED_BITS		8
 #define MVPP2_CLS3_STATE_OCCIPIED_MASK		(((1 << \
@@ -671,7 +661,7 @@
 
 #define MVPP2_CLS3_DB_INDEX_REG			0x1C90
 #define MVPP2_CLS3_DB_MISS_OFFS			12
-#define MVPP2_CLS3_DB_MISS_MASK			(1 << MVPP2_CLS3_DB_MISS_OFFS)
+#define MVPP2_CLS3_DB_MISS_MASK			BIT(MVPP2_CLS3_DB_MISS_OFFS)
 
 						/* 0-3 valid val*/
 #define MVPP2_CLS3_HASH_DATA_REG(num)		(0x1CA0 + 4 * (num))
@@ -816,7 +806,7 @@
 #define MVPP21_TXQ_SENT_REG(txq)		(0x3c00 + 4 * (txq))
 #define MVPP21_TRANSMITTED_COUNT_OFFSET		16
 #define MVPP21_TRANSMITTED_COUNT_MASK		0x3fff0000
-#define MVPP22_TXQ_SENT_REG(txq)		(0x3e00 + 4 * (txq-128))
+#define MVPP22_TXQ_SENT_REG(txq)		(0x3e00 + 4 * (txq - 128))
 #define MVPP22_TRANSMITTED_COUNT_OFFSET		16
 #define MVPP22_TRANSMITTED_COUNT_MASK		0x3fff0000
 
@@ -832,7 +822,6 @@
 #define MVPP22_AGGR_TXQ_DESC_ADDR_SHIFT		MVPP22_DESC_ADDR_SHIFT
 #define MVPP22_AGGR_TXQ_DESC_ADDR_MASK		0xfffffffe
 
-
 #define MVPP2_AGGR_TXQ_DESC_SIZE_REG(cpu)	(0x2140 + 4 * (cpu))
 #define MVPP2_AGGR_TXQ_DESC_SIZE_MASK		0x3ff0
 #define MVPP2_AGGR_TXQ_STATUS_REG(cpu)		(0x2180 + 4 * (cpu))
@@ -1037,7 +1026,6 @@
 #define MVPP2_BM_QSET_MAX_GRNTD_MASK		(0xffff << \
 					MVPP2_BM_QSET_MAX_GRNTD_OFFS)
 
-
 #define MVPP2_BM_QSET_SET_CNTRS_REG		0x6824
 
 /* TX Scheduler registers */
@@ -1109,7 +1097,6 @@
 						/* Same for PPv21/PPv22 */
 #define MVPP2_TX_DROP_CNTR_REG(eth_tx_port)	(0x8980 + ((eth_tx_port) << 2))
 
-
 #define MVPP2_TX_ETH_DSEC_THRESH_REG(eth_tx_port)(0x8a40 + \
 					((eth_tx_port) << 2))
 #define MVPP2_TX_ETH_DSEC_THRESH_MASK		0x7f0
@@ -1215,7 +1202,7 @@
 #define MVPP2_RXQ_TOTAL_NUM		(MVPP2_MAX_PORTS * MVPP2_MAX_RXQ)
 
 #define MVPP2_TXQ_TOTAL_NUM		(128/*pon*/ + \
-					MVPP2_MAX_PORTS*MVPP2_MAX_TXQ/*eth*/)
+					MVPP2_MAX_PORTS * MVPP2_MAX_TXQ/*eth*/)
 
 /* Max number of Rx descriptors */
 #define MVPP2_MAX_RXD			1024
@@ -1482,7 +1469,7 @@ enum mv_pp2x_tag_type {
 			MVPP2_FLOWID_FLOW_BITS) - 1) << MVPP2_FLOWID_FLOW)
 
 #define MVPP2_FLOWID_EN			25 /*one bit */
-#define MVPP2_FLOWID_EN_MASK		(1 << MVPP2_FLOWID_EN)
+#define MVPP2_FLOWID_EN_MASK		BIT(MVPP2_FLOWID_EN)
 
 /* flow table structure */
 #define MVPP2_FLOW_TBL_SIZE		512
@@ -1533,7 +1520,7 @@ enum mv_pp2x_tag_type {
 #define MVPP2_FLOW_UDF7_MAX		((1 << MVPP2_FLOW_UDF7_BITS) - 1)
 
 #define MVPP2_FLOW_PORT_ID_SEL		23
-#define MVPP2_FLOW_PORT_ID_SEL_MASK	(1 << MVPP2_FLOW_PORT_ID_SEL)
+#define MVPP2_FLOW_PORT_ID_SEL_MASK	BIT(MVPP2_FLOW_PORT_ID_SEL)
 
 /*-----------------------  DWORD 1  ------------------------------------ */
 
@@ -1804,7 +1791,7 @@ enum mv_pp2x_bm_pool_log_num {
 #define MVPP2_RXD_CPU_CODE_MASK		(((1 << \
 		MVPP2_RXD_CPU_CODE_BITS) - 1) << MVPP2_RXD_CPU_CODE_OFFS)
 #define MVPP2_RXD_PPPOE_BIT		9
-#define MVPP2_RXD_PPPOE_MASK		(1 << MVPP2_RXD_PPPOE_BIT)
+#define MVPP2_RXD_PPPOE_MASK		BIT(MVPP2_RXD_PPPOE_BIT)
 #define MVPP2_RXD_L3_CAST_OFFS		10
 #define MVPP2_RXD_L3_CAST_BITS		2
 #define MVPP2_RXD_L3_CAST_MASK		(((1 << \
@@ -1828,15 +1815,15 @@ enum mv_pp2x_bm_pool_log_num {
 #define MVPP2_RXD_IP_HLEN_OFFS		8
 #define MVPP2_RXD_IP_HLEN_MASK		(0x1F << MVPP2_RXD_IP_HLEN_OFFS)
 #define MVPP2_RXD_ES_BIT		15
-#define MVPP2_RXD_ES_MASK		(1 << MVPP2_RXD_ES_BIT)
+#define MVPP2_RXD_ES_MASK		BIT(MVPP2_RXD_ES_BIT)
 #define MVPP2_RXD_HWF_SYNC_BIT		21
-#define MVPP2_RXD_HWF_SYNC_MASK		(1 << MVPP2_RXD_HWF_SYNC_BIT)
+#define MVPP2_RXD_HWF_SYNC_MASK		BIT(MVPP2_RXD_HWF_SYNC_BIT)
 #define MVPP2_RXD_L4_CHK_OK_BIT		22
-#define MVPP2_RXD_L4_CHK_OK_MASK	(1 << MVPP2_RXD_L4_CHK_OK_BIT)
+#define MVPP2_RXD_L4_CHK_OK_MASK	BIT(MVPP2_RXD_L4_CHK_OK_BIT)
 #define MVPP2_RXD_IP_FRAG_BIT		23
-#define MVPP2_RXD_IP_FRAG_MASK		(1 << MVPP2_RXD_IP_FRAG_BIT)
+#define MVPP2_RXD_IP_FRAG_MASK		BIT(MVPP2_RXD_IP_FRAG_BIT)
 #define MVPP2_RXD_IP4_HEADER_ERR_BIT	24
-#define MVPP2_RXD_IP4_HEADER_ERR_MASK	(1 << MVPP2_RXD_IP4_HEADER_ERR_BIT)
+#define MVPP2_RXD_IP4_HEADER_ERR_MASK	BIT(MVPP2_RXD_IP4_HEADER_ERR_BIT)
 #define MVPP2_RXD_L4_OFFS		25
 #define MVPP2_RXD_L4_MASK		(7 << MVPP2_RXD_L4_OFFS)
 /* Value 0 - N/A, 3-7 - User Defined */
@@ -1847,7 +1834,7 @@ enum mv_pp2x_bm_pool_log_num {
 #define MVPP2_RXD_L3_IP4_OTHER		(3 << MVPP2_RXD_L3_OFFS)
 #define MVPP2_RXD_L3_IP6_EXT		(5 << MVPP2_RXD_L3_OFFS)
 #define MVPP2_RXD_BUF_HDR_BIT		31
-#define MVPP2_RXD_BUF_HDR_MASK		(1 << MVPP2_RXD_BUF_HDR_BIT)
+#define MVPP2_RXD_BUF_HDR_MASK		BIT(MVPP2_RXD_BUF_HDR_BIT)
 /* status field MACROs */
 #define MVPP2_RXD_L3_IS_IP4(status)		(((status) & \
 				MVPP2_RXD_L3_MASK) == MVPP2_RXD_L3_IP4)
@@ -1911,6 +1898,7 @@ struct pp21_specific_rx_desc {
 	u32 rsrvd_flow_id;	/* flow_id (for future use, PnC) */
 	u32 rsrvd_abs;
 };
+
 struct pp22_specific_rx_desc {
 	u16 rsrvd_gem;		/* gem_port_id (for future use, PON)	*/
 	u16 rsrvd_l4csum;	/* csum_l4 (for future use, PnC)	*/
@@ -2275,7 +2263,6 @@ struct mv_pp2x_buff_hdr {
 #define MVPP2_B_HDR_INFO_IS_LAST(info) \
 	   ((info & MVPP2_B_HDR_INFO_LAST_MASK) >> MVPP2_B_HDR_INFO_LAST_OFFS)
 
-
 /* Macroes */
 #define MVPP2_RX_DESC_POOL(rx_desc)	((rx_desc->status & \
 		MVPP2_RXD_BM_POOL_ID_MASK) >> MVPP2_RXD_BM_POOL_ID_OFFS)
@@ -2402,7 +2389,7 @@ struct mv_pp2x_cls_c3_shadow_hash_entry {
 };
 
 /* Classifier C4 Top Registers */
-#define MVPP2_CLS4_PHY_TO_RL_REG(port)			(0x1E00 + ((port)*4))
+#define MVPP2_CLS4_PHY_TO_RL_REG(port)			(0x1E00 + ((port) * 4))
 #define MVPP2_CLS4_PHY_TO_RL_GRP			0
 #define MVPP2_CLS4_PHY_TO_RL_GRP_BITS			3
 #define MVPP2_CLS4_PHY_TO_RL_GRP_MASK			(((1 << MVPP2_CLS4_PHY_TO_RL_GRP_BITS) - 1) << \
@@ -2412,7 +2399,7 @@ struct mv_pp2x_cls_c3_shadow_hash_entry {
 #define MVPP2_CLS4_PHY_TO_RL_RULE_NUM_MASK		(((1 << MVPP2_CLS4_PHY_TO_RL_RULE_NUM_BITS) - 1) << \
 							 MVPP2_CLS4_PHY_TO_RL_RULE_NUM)
 
-#define MVPP2_CLS4_UNI_TO_RL_REG(uni)			(0x1E20 + ((uni)*4))
+#define MVPP2_CLS4_UNI_TO_RL_REG(uni)			(0x1E20 + ((uni) * 4))
 #define MVPP2_CLS4_UNI_TO_RL_GRP			0
 #define MVPP2_CLS4_UNI_TO_RL_RULE_NUM			4
 
@@ -2446,7 +2433,7 @@ struct mv_pp2x_cls_c3_shadow_hash_entry {
 #define MVPP2_CLS4_FDATA6_REG				(0x1E6C)
 #define MVPP2_CLS4_FDATA7_REG				(0x1E70)
 #define MVPP2_CLS4_FDATA8_REG				(0x1E74)
-#define MVPP2_CLS4_FDATA_REG(reg_num)			(0x1E58 + (4*(reg_num)))
+#define MVPP2_CLS4_FDATA_REG(reg_num)			(0x1E58 + (4 * (reg_num)))
 #define MVPP2_CLS4_FDATA_REGS_NUM			8
 
 #define MVPP2_CLS4_FDATA7_L3INFO			16
@@ -2497,13 +2484,13 @@ struct mv_pp2x_cls_c3_shadow_hash_entry {
 
 /* C4 entry structure */
 struct mv_pp2x_cls_c4_entry {
-	u32 ruleIndex;
-	u32 setIndex;
+	u32 rule_index;
+	u32 set_index;
 	union {
 		u32	words[MVPP2_CLS_C4_TBL_WORDS];
 		struct {
 			u32 attr[MVPP2_CLS4_FATTR_REG_NUM];
-			u32 fdataArr[MVPP2_CLS_C4_TBL_DATA_WORDS];
+			u32 fdata_arr[MVPP2_CLS_C4_TBL_DATA_WORDS];
 		} regs;
 	} rules;
 	union {
@@ -2546,7 +2533,7 @@ struct mv_pp2x_cls_c4_entry {
 /*--------------------------------------------------------------------------*/
 #define MVPP2_PME_TTL_ZERO_FRWD_REG		(0x8640)
 #define MVPP2_PME_TTL_ZERO_FRWD_BIT		0
-#define MVPP2_PME_TTL_ZERO_FRWD_MASK		(1 << MVPP2_PME_TTL_ZERO_FRWD_BIT)
+#define MVPP2_PME_TTL_ZERO_FRWD_MASK		BIT(MVPP2_PME_TTL_ZERO_FRWD_BIT)
 /*--------------------------------------------------------------------------*/
 #define MVPP2_PME_PPPOE_ETYPE_REG		(0x8650)
 #define MVPP2_PME_PPPOE_DATA_REG		(0x8654)
@@ -2593,7 +2580,7 @@ struct mv_pp2x_cls_c4_entry {
 						 MVPP2_PME_MAX_INSTR_NUM_ALL_MASK)
 
 #define MVPP2_PME_DROP_ON_ERR_BIT		24
-#define MVPP2_PME_DROP_ON_ERR_MASK		(1 << MVPP2_PME_DROP_ON_ERR_BIT)
+#define MVPP2_PME_DROP_ON_ERR_MASK		BIT(MVPP2_PME_DROP_ON_ERR_BIT)
 /*--------------------------------------------------------------------------*/
 
 #define MVPP2_PME_STATUS_1_REG			(0x8664)
@@ -2615,13 +2602,13 @@ struct mv_pp2x_cls_c4_entry {
 #define MVPP2_PME_CMD_MASK(cmd)			((cmd) << MVPP2_PME_CMD_OFFS)
 
 #define MVPP2_PME_IP4_CSUM_BIT			21
-#define MVPP2_PME_IP4_CSUM_MASK			(1 << MVPP2_PME_IP4_CSUM_BIT)
+#define MVPP2_PME_IP4_CSUM_MASK			BIT(MVPP2_PME_IP4_CSUM_BIT)
 
 #define MVPP2_PME_L4_CSUM_BIT			22
-#define MVPP2_PME_L4_CSUM_MASK			(1 << MVPP2_PME_L4_CSUM_BIT)
+#define MVPP2_PME_L4_CSUM_MASK			BIT(MVPP2_PME_L4_CSUM_BIT)
 
 #define MVPP2_PME_LAST_BIT			23
-#define MVPP2_PME_LAST_MASK			(1 << MVPP2_PME_LAST_BIT)
+#define MVPP2_PME_LAST_MASK			BIT(MVPP2_PME_LAST_BIT)
 
 #define MVPP2_PME_CMD_TYPE_OFFS			24
 #define MVPP2_PME_CMD_TYPE_BITS			3
@@ -2675,6 +2662,7 @@ enum mv_pp2x_pme_instr {
 	MVPP2_PME_CMD_DROP_PKT = 0x1f,
 	MVPP2_TMP_CMD_LAST
 };
+
 /* PME entry structure */
 struct mv_pp2x_pme_entry {
 	int     index;
@@ -2694,13 +2682,13 @@ struct mv_pp2x_pme_entry {
 #define MVPP2_MC_DATA2_GEM_ID			0
 #define MVPP2_MC_DATA2_PRI			12
 #define MVPP2_MC_DATA2_DSCP			15
-#define MVPP2_MC_DATA2_GEM_ID_EN		(1 << 21)
-#define MVPP2_MC_DATA2_PRI_EN			(1 << 22)
-#define MVPP2_MC_DATA2_DSCP_EN			(1 << 23)
+#define MVPP2_MC_DATA2_GEM_ID_EN		BIT(21)
+#define MVPP2_MC_DATA2_PRI_EN			BIT(22)
+#define MVPP2_MC_DATA2_DSCP_EN			BIT(23)
 /*------------------------------------------------------------------------------*/
 #define MVPP2_MC_DATA3_REG			(0x16C)
 #define MVPP2_MC_DATA3_QUEUE			0
-#define MVPP2_MC_DATA3_HWF_EN			(1 << 8)
+#define MVPP2_MC_DATA3_HWF_EN			BIT(8)
 #define MVPP2_MC_DATA3_NEXT			16
 #define MVPP2_MC_DATA3_NEXT_MASK		(MVPP2_MC_INDEX_MAX << MVPP2_MC_DATA3_NEXT)
 
@@ -2744,7 +2732,7 @@ struct mv_pp2x_mc_entry {
 		(((p) << MVPP2_PLCR_BASE_PERIOD_OFFS) & MVPP2_PLCR_BASE_PERIOD_ALL_MASK)
 
 #define MVPP2_PLCR_ADD_TOKENS_EN_BIT		16
-#define MVPP2_PLCR_ADD_TOKENS_EN_MASK		(1 << MVPP2_PLCR_ADD_TOKENS_EN_BIT)
+#define MVPP2_PLCR_ADD_TOKENS_EN_MASK		BIT(MVPP2_PLCR_ADD_TOKENS_EN_BIT)
 /*--------------------------------------------------------------------------------------------*/
 #define MVPP2_PLCR_MODE_REG			(0x1308)
 #define MVPP2_PLCR_MODE_BITS			(3)
@@ -2791,17 +2779,17 @@ struct mv_pp2x_mc_entry {
 		(((type) << MVPP2_PLCR_TOKEN_TYPE_OFFS) & MVPP2_PLCR_TOKEN_TYPE_ALL_MASK)
 
 #define MVPP2_PLCR_TOKEN_UNIT_BIT		31
-#define MVPP2_PLCR_TOKEN_UNIT_MASK		(1 << MVPP2_PLCR_TOKEN_UNIT_BIT)
+#define MVPP2_PLCR_TOKEN_UNIT_MASK		BIT(MVPP2_PLCR_TOKEN_UNIT_BIT)
 #define MVPP2_PLCR_TOKEN_UNIT_BYTES		(0 << MVPP2_PLCR_TOKEN_UNIT_BIT)
-#define MVPP2_PLCR_TOKEN_UNIT_PKTS		(1 << MVPP2_PLCR_TOKEN_UNIT_BIT)
+#define MVPP2_PLCR_TOKEN_UNIT_PKTS		BIT(MVPP2_PLCR_TOKEN_UNIT_BIT)
 
 #define MVPP2_PLCR_COLOR_MODE_BIT		30
-#define MVPP2_PLCR_COLOR_MODE_MASK		(1 << MVPP2_PLCR_COLOR_MODE_BIT)
+#define MVPP2_PLCR_COLOR_MODE_MASK		BIT(MVPP2_PLCR_COLOR_MODE_BIT)
 #define MVPP2_PLCR_COLOR_MODE_BLIND		(0 << MVPP2_PLCR_COLOR_MODE_BIT)
-#define MVPP2_PLCR_COLOR_MODE_AWARE		(1 << MVPP2_PLCR_COLOR_MODE_BIT)
+#define MVPP2_PLCR_COLOR_MODE_AWARE		BIT(MVPP2_PLCR_COLOR_MODE_BIT)
 
 #define MVPP2_PLCR_ENABLE_BIT			29
-#define MVPP2_PLCR_ENABLE_MASK			(1 << MVPP2_PLCR_ENABLE_BIT)
+#define MVPP2_PLCR_ENABLE_MASK			BIT(MVPP2_PLCR_ENABLE_BIT)
 /*---------------------------------------------------------------------------------------------*/
 
 #define MVPP2_PLCR_MIN_PKT_LEN_REG		(0x1320)
@@ -2817,7 +2805,7 @@ struct mv_pp2x_mc_entry {
 #define MVPP2_PLCR_EDROP_EN_REG		(0x1330)
 
 #define MVPP2_PLCR_EDROP_EN_BIT		0
-#define MVPP2_PLCR_EDROP_EN_MASK		(1 << MVPP2_PLCR_EDROP_EN_BIT)
+#define MVPP2_PLCR_EDROP_EN_MASK		BIT(MVPP2_PLCR_EDROP_EN_BIT)
 /*---------------------------------------------------------------------------------------------*/
 /*ppv2.1 policer early drop threshold mechanism changed*/
 #define MVPP2_V0_PLCR_EDROP_THRESH_NUM		4
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
index 91e15b8..828d57e 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
@@ -69,7 +69,7 @@
 
 #define MVPP2_SKB_TEST_SIZE 64
 #define MVPP2_ADDRESS 0xf2000000
-#define CPN110_ADDRESS_SPACE_SIZE (16*1024*1024)
+#define CPN110_ADDRESS_SPACE_SIZE (16 * 1024 * 1024)
 
 /* Declaractions */
 #if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
@@ -127,7 +127,7 @@ struct mv_pp2x_pool_attributes mv_pp2x_pools[] = {
 
 module_param(cos_classifer, byte, S_IRUGO);
 MODULE_PARM_DESC(cos_classifer,
-	"Cos Classifier (vlan_pri=0, dscp=1, vlan_dscp=2, dscp_vlan=3)");
+		 "Cos Classifier (vlan_pri=0, dscp=1, vlan_dscp=2, dscp_vlan=3)");
 
 module_param(pri_map, uint, S_IRUGO);
 MODULE_PARM_DESC(pri_map, "Set priority_map, nibble for each cos.");
@@ -151,7 +151,7 @@ struct mv_pp2x_pool_attributes mv_pp2x_pools[] = {
 
 module_param(debug_param, uint, S_IRUGO);
 MODULE_PARM_DESC(debug_param,
-	"Ad-hoc parameter, which can be used for various debug operations.");
+		 "Ad-hoc parameter, which can be used for various debug operations.");
 
 module_param(stats_delay_msec, ushort, S_IRUGO);
 MODULE_PARM_DESC(stats_delay_msec, "Set statistic delay in msec, def=250");
@@ -169,7 +169,7 @@ struct mv_pp2x_pool_attributes mv_pp2x_pools[] = {
 
 module_param(port_cpu_bind_map, uint, S_IRUGO);
 MODULE_PARM_DESC(port_cpu_bind_map,
-	"Set default port-to-cpu binding, nibble for each port. Relevant when queue_mode=multi-mode & rss is disabled");
+		 "Set default port-to-cpu binding, nibble for each port. Relevant when queue_mode=multi-mode & rss is disabled");
 
 module_param(first_bm_pool, byte, S_IRUGO);
 MODULE_PARM_DESC(first_bm_pool, "First used buffer pool (0-11)");
@@ -195,7 +195,6 @@ void set_device_base_address(struct net_device *dev)
 
 static inline int mv_pp2x_txq_count(struct mv_pp2x_txq_pcpu *txq_pcpu)
 {
-
 	int index_modulo = (txq_pcpu->txq_put_index - txq_pcpu->txq_get_index +
 				txq_pcpu->size) % txq_pcpu->size;
 
@@ -204,7 +203,6 @@ static inline int mv_pp2x_txq_count(struct mv_pp2x_txq_pcpu *txq_pcpu)
 
 static inline int mv_pp2x_txq_free_count(struct mv_pp2x_txq_pcpu *txq_pcpu)
 {
-
 	int index_modulo = (txq_pcpu->txq_get_index - txq_pcpu->txq_put_index +
 				txq_pcpu->size) % txq_pcpu->size;
 
@@ -233,7 +231,6 @@ void mv_pp2x_txq_inc_error(struct mv_pp2x_txq_pcpu *txq_pcpu, int num)
 	}
 }
 
-
 void mv_pp2x_txq_inc_put(enum mvppv2_version pp2_ver,
 			 struct mv_pp2x_txq_pcpu *txq_pcpu,
 			 struct sk_buff *skb,
@@ -283,7 +280,6 @@ char *mv_pp2x_pool_description_get(enum mv_pp2x_bm_pool_log_num  log_id)
 }
 EXPORT_SYMBOL(mv_pp2x_pool_description_get);
 
-
 /* Buffer Manager configuration routines */
 static void *mv_pp2x_frag_alloc(const struct mv_pp2x_bm_pool *pool)
 {
@@ -302,7 +298,7 @@ static void mv_pp2x_frag_free(const struct mv_pp2x_bm_pool *pool, void *data)
 }
 
 static int mv_pp2x_rx_refill_new(struct mv_pp2x_port *port,
-			   struct mv_pp2x_bm_pool *bm_pool,
+				 struct mv_pp2x_bm_pool *bm_pool,
 			   u32 pool, int is_recycle, int cpu)
 {
 	dma_addr_t phys_addr;
@@ -327,7 +323,7 @@ static int mv_pp2x_rx_refill_new(struct mv_pp2x_port *port,
 
 /* Create pool */
 static int mv_pp2x_bm_pool_create(struct device *dev,
-					 struct mv_pp2x_hw *hw,
+				  struct mv_pp2x_hw *hw,
 					 struct mv_pp2x_bm_pool *bm_pool,
 					 int size, int pkt_size)
 {
@@ -336,7 +332,7 @@ static int mv_pp2x_bm_pool_create(struct device *dev,
 	/* Driver enforces size= x16 both for PPv21 and for PPv22, even though
 	 *    PPv22 HW allows size= x8
 	 */
-	if (!IS_ALIGNED(size, (1<<MVPP21_BM_POOL_SIZE_OFFSET)))
+	if (!IS_ALIGNED(size, (1 << MVPP21_BM_POOL_SIZE_OFFSET)))
 		return -EINVAL;
 
 	/*YuvalC: Two pointers per buffer, existing bug fixed. */
@@ -370,7 +366,7 @@ static int mv_pp2x_bm_pool_create(struct device *dev,
 }
 
 void mv_pp2x_bm_bufs_free(struct device *dev, struct mv_pp2x *priv,
-			struct mv_pp2x_bm_pool *bm_pool, int buf_num)
+			  struct mv_pp2x_bm_pool *bm_pool, int buf_num)
 {
 	int i;
 
@@ -378,7 +374,6 @@ void mv_pp2x_bm_bufs_free(struct device *dev, struct mv_pp2x *priv,
 		WARN(1, "Pool does not have so many bufs pool(%d) bufs(%d)\n",
 		     bm_pool->id, buf_num);
 		buf_num = bm_pool->buf_num;
-
 	}
 	for (i = 0; i < buf_num; i++) {
 		u8 *virt_addr;
@@ -390,7 +385,7 @@ void mv_pp2x_bm_bufs_free(struct device *dev, struct mv_pp2x *priv,
 			break;
 		if (!bm_pool->external_pool) {
 			dma_unmap_single(dev, phys_addr,
-				 MVPP2_RX_BUF_SIZE(bm_pool->pkt_size), DMA_TO_DEVICE);
+					 MVPP2_RX_BUF_SIZE(bm_pool->pkt_size), DMA_TO_DEVICE);
 			virt_addr = phys_to_virt(dma_to_phys(dev, phys_addr));
 			mv_pp2x_frag_free(bm_pool, virt_addr);
 		}
@@ -481,7 +476,7 @@ int mv_pp2x_bm_pool_ext_add(struct device *dev, struct mv_pp2x *priv,
 }
 
 static int mv_pp2x_bm_pools_init(struct platform_device *pdev,
-				       struct mv_pp2x *priv,
+				 struct mv_pp2x *priv,
 				       u8 first_pool, u8 num_pools)
 {
 	int i, err, size;
@@ -538,7 +533,7 @@ static int mv_pp2x_bm_init(struct platform_device *pdev, struct mv_pp2x *priv)
 
 /* Allocate buffers for the pool */
 int mv_pp2x_bm_bufs_add(struct mv_pp2x_port *port,
-			       struct mv_pp2x_bm_pool *bm_pool, int buf_num)
+			struct mv_pp2x_bm_pool *bm_pool, int buf_num)
 {
 	int i, buf_size, total_size, cpu;
 
@@ -575,7 +570,7 @@ int mv_pp2x_bm_bufs_add(struct mv_pp2x_port *port,
 }
 
 static int mv_pp2x_bm_buf_calc(enum mv_pp2x_bm_pool_log_num log_pool,
-				     u32 port_map)
+			       u32 port_map)
 {
 	/*TODO: Code algo based  on
 	 * port_map/num_rx_queues/num_tx_queues/queue_sizes
@@ -644,11 +639,10 @@ static struct mv_pp2x_bm_pool *mv_pp2x_bm_pool_stop_use(
 	return mv_pp2x_bm_pool_use_internal(port, log_pool, false);
 }
 
-
 int mv_pp2x_swf_bm_pool_assign(struct mv_pp2x_port *port, u32 rxq,
 			       u32 long_id, u32 short_id)
 {
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 
 	if (rxq >= port->num_rx_queues)
 		return -ENOMEM;
@@ -665,7 +659,7 @@ static int mv_pp2x_swf_bm_pool_init(struct mv_pp2x_port *port)
 {
 	int rxq;
 	enum mv_pp2x_bm_pool_log_num long_log_pool;
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 
 	if (port->pkt_size > MVPP2_BM_LONG_PKT_SIZE)
 		long_log_pool = MVPP2_BM_SWF_JUMBO_POOL;
@@ -818,16 +812,16 @@ static inline void *mv_pp2_extra_pool_get(struct mv_pp2x_port *port)
 	struct mv_pp2x_ext_buf_struct *ext_buf_struct;
 
 	if (!list_empty(&port_pcpu->ext_buf_port_list)) {
-
 		ext_buf_struct = list_first_entry(&port_pcpu->ext_buf_port_list,
-				struct mv_pp2x_ext_buf_struct, ext_buf_list);
+						  struct mv_pp2x_ext_buf_struct, ext_buf_list);
 		list_del(&ext_buf_struct->ext_buf_list);
 		port_pcpu->ext_buf_pool->buf_pool_in_use--;
 
 		ext_buf = ext_buf_struct->ext_buf_data;
 
-	} else
+	} else {
 		ext_buf = kmalloc(MVPP2_EXTRA_BUF_SIZE, GFP_ATOMIC);
+	}
 
 	return ext_buf;
 }
@@ -848,7 +842,7 @@ static inline int mv_pp2_extra_pool_put(struct mv_pp2x_port *port, void *ext_buf
 	ext_buf_struct->ext_buf_data = ext_buf;
 
 	list_add(&ext_buf_struct->ext_buf_list,
-				&port_pcpu->ext_buf_port_list);
+		 &port_pcpu->ext_buf_port_list);
 	port_pcpu->ext_buf_pool->buf_pool_in_use++;
 
 	return 0;
@@ -922,7 +916,6 @@ int mv_pp2x_tso_txq_reserved_desc_num_proc(
 			txq_pcpu_aux = per_cpu_ptr(txq->pcpu, cpu_desc);
 			txq_count = mv_pp2x_txq_count(txq_pcpu_aux);
 			desc_count += txq_count;
-
 		}
 		desc_count += req;
 
@@ -999,13 +992,12 @@ static void mv_pp2x_txq_buf_free(struct mv_pp2x_port *port, uintptr_t skb,
 
 /* Handle end of transmission */
 static void mv_pp2x_txq_done(struct mv_pp2x_port *port,
-				   struct mv_pp2x_tx_queue *txq,
+			     struct mv_pp2x_tx_queue *txq,
 				   struct mv_pp2x_txq_pcpu *txq_pcpu)
 {
 	struct netdev_queue *nq = netdev_get_tx_queue(port->dev, txq->log_id);
 	int tx_done;
 
-
 #ifdef DEV_NETMAP
 	if (port->flags & MVPP2_F_IFCAP_NETMAP) {
 		if (netmap_tx_irq(port->dev, 0))
@@ -1027,7 +1019,7 @@ static void mv_pp2x_txq_done(struct mv_pp2x_port *port,
 }
 
 static unsigned int mv_pp2x_tx_done(struct mv_pp2x_port *port, u32 cause,
-					    int cpu)
+				    int cpu)
 {
 	struct mv_pp2x_tx_queue *txq;
 	struct mv_pp2x_txq_pcpu *txq_pcpu;
@@ -1060,7 +1052,7 @@ static unsigned int mv_pp2x_tx_done(struct mv_pp2x_port *port, u32 cause,
 
 /* Allocate and initialize descriptors for aggr TXQ */
 static int mv_pp2x_aggr_txq_init(struct platform_device *pdev,
-				      struct mv_pp2x_aggr_tx_queue *aggr_txq,
+				 struct mv_pp2x_aggr_tx_queue *aggr_txq,
 				      int desc_num, int cpu,
 				      struct mv_pp2x *priv)
 {
@@ -1079,7 +1071,7 @@ static int mv_pp2x_aggr_txq_init(struct platform_device *pdev,
 	first_desc_phy = MVPP2_DESCQ_MEM_ALIGN(aggr_txq->descs_phys);
 
 	pr_debug("first_desc=%p, desc_mem=%p\n",
-		aggr_txq->desc_mem, aggr_txq->first_desc);
+		 aggr_txq->desc_mem, aggr_txq->first_desc);
 
 	aggr_txq->last_desc = aggr_txq->size - 1;
 
@@ -1100,7 +1092,7 @@ static int mv_pp2x_aggr_txq_init(struct platform_device *pdev,
 
 /* Create a specified Rx queue */
 static int mv_pp2x_rxq_init(struct mv_pp2x_port *port,
-			       struct mv_pp2x_rx_queue *rxq)
+			    struct mv_pp2x_rx_queue *rxq)
 {
 	struct mv_pp2x_hw *hw = &port->priv->hw;
 	dma_addr_t first_desc_phy;
@@ -1146,7 +1138,7 @@ static int mv_pp2x_rxq_init(struct mv_pp2x_port *port,
 
 /* Push packets received by the RXQ to BM pool */
 static void mv_pp2x_rxq_drop_pkts(struct mv_pp2x_port *port,
-					struct mv_pp2x_rx_queue *rxq)
+				  struct mv_pp2x_rx_queue *rxq)
 {
 	int rx_received, i, cpu;
 	u8 *buf_cookie;
@@ -1171,7 +1163,7 @@ static void mv_pp2x_rxq_drop_pkts(struct mv_pp2x_port *port,
 		buf_cookie = phys_to_virt(dma_to_phys(port->dev->dev.parent, buf_phys_addr));
 
 		mv_pp2x_pool_refill(port->priv, MVPP2_RX_DESC_POOL(rx_desc),
-			buf_phys_addr, cpu);
+				    buf_phys_addr, cpu);
 	}
 	put_cpu();
 	mv_pp2x_rxq_status_update(port, rxq->id, rx_received, rx_received);
@@ -1179,9 +1171,9 @@ static void mv_pp2x_rxq_drop_pkts(struct mv_pp2x_port *port,
 
 /* Cleanup Rx queue */
 static void mv_pp2x_rxq_deinit(struct mv_pp2x_port *port,
-				   struct mv_pp2x_rx_queue *rxq)
+			       struct mv_pp2x_rx_queue *rxq)
 {
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 
 	mv_pp2x_rxq_drop_pkts(port, rxq);
 
@@ -1208,11 +1200,11 @@ static void mv_pp2x_rxq_deinit(struct mv_pp2x_port *port,
 
 /* Create and initialize a Tx queue */
 static int mv_pp2x_txq_init(struct mv_pp2x_port *port,
-			       struct mv_pp2x_tx_queue *txq)
+			    struct mv_pp2x_tx_queue *txq)
 {
 	u32 val;
 	int cpu, desc, desc_per_txq, tx_port_num;
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 	struct mv_pp2x_txq_pcpu *txq_pcpu;
 	dma_addr_t first_desc_phy;
 
@@ -1229,7 +1221,6 @@ static int mv_pp2x_txq_init(struct mv_pp2x_port *port,
 		MVPP2_DESCQ_MEM_ALIGN((uintptr_t)txq->desc_mem);
 	first_desc_phy  = MVPP2_DESCQ_MEM_ALIGN(txq->descs_phys);
 
-
 	txq->last_desc = txq->size - 1;
 
 	/* Set Tx descriptors queue starting address - indirect access */
@@ -1256,7 +1247,7 @@ static int mv_pp2x_txq_init(struct mv_pp2x_port *port,
 
 	mv_pp2x_write(hw, MVPP2_TXQ_PREF_BUF_REG,
 		      MVPP2_PREF_BUF_PTR(desc) | MVPP2_PREF_BUF_SIZE_16 |
-		      MVPP2_PREF_BUF_THRESH(desc_per_txq/2));
+		      MVPP2_PREF_BUF_THRESH(desc_per_txq / 2));
 
 	/* WRR / EJP configuration - indirect access */
 	tx_port_num = mv_pp2x_egress_port(port);
@@ -1315,7 +1306,7 @@ static int mv_pp2x_txq_init(struct mv_pp2x_port *port,
 
 /* Free allocated TXQ resources */
 static void mv_pp2x_txq_deinit(struct mv_pp2x_port *port,
-				   struct mv_pp2x_tx_queue *txq)
+			       struct mv_pp2x_tx_queue *txq)
 {
 	struct mv_pp2x_txq_pcpu *txq_pcpu;
 	struct mv_pp2x_hw *hw = &port->priv->hw;
@@ -1350,7 +1341,7 @@ static void mv_pp2x_txq_deinit(struct mv_pp2x_port *port,
 
 /* Cleanup Tx ports */
 static void mv_pp2x_txq_clean(struct mv_pp2x_port *port,
-				   struct mv_pp2x_tx_queue *txq)
+			      struct mv_pp2x_tx_queue *txq)
 {
 	struct mv_pp2x_txq_pcpu *txq_pcpu;
 	int delay, pending, cpu;
@@ -1484,7 +1475,7 @@ int mv_pp2x_setup_txqs(struct mv_pp2x_port *port)
 		if (err)
 			goto err_cleanup;
 	}
-	if (port->priv->pp2xdata->interrupt_tx_done == true) {
+	if (port->priv->pp2xdata->interrupt_tx_done) {
 		mv_pp2x_tx_done_time_coal_set(port, port->tx_time_coal);
 		on_each_cpu(mv_pp2x_tx_done_pkts_coal_set, port, 1);
 	}
@@ -1518,8 +1509,8 @@ static irqreturn_t mv_pp2x_isr(int irq, void *dev_id)
 
 	mv_pp2x_qvector_interrupt_disable(q_vec);
 	pr_debug("%s cpu_id(%d) port_id(%d) q_vec(%d), qv_type(%d)\n",
-		__func__, smp_processor_id(), q_vec->parent->id,
-		(int)(q_vec-q_vec->parent->q_vector), q_vec->qv_type);
+		 __func__, smp_processor_id(), q_vec->parent->id,
+		(int)(q_vec - q_vec->parent->q_vector), q_vec->qv_type);
 	napi_schedule(&q_vec->napi);
 
 	return IRQ_HANDLED;
@@ -1530,7 +1521,7 @@ static irqreturn_t mv_pp2_link_change_isr(int irq, void *data)
 	struct mv_pp2x_port *port = (struct mv_pp2x_port *)data;
 
 	pr_debug("%s cpu_id(%d) irq(%d) pp_port(%d)\n", __func__,
-		smp_processor_id(), irq, port->id);
+		 smp_processor_id(), irq, port->id);
 	if (port->priv->pp2_version == PPV22) {
 		/* mask all events from this mac */
 		mv_gop110_port_events_mask(&port->priv->hw.gop, &port->mac_data);
@@ -1542,7 +1533,6 @@ static irqreturn_t mv_pp2_link_change_isr(int irq, void *data)
 		tasklet_schedule(&port->link_change_tasklet);
 
 	return IRQ_HANDLED;
-
 }
 
 int mv_pp2x_setup_irqs(struct net_device *dev, struct mv_pp2x_port *port)
@@ -1608,7 +1598,6 @@ static void mv_pp22_dev_link_event(struct net_device *dev)
 	/* Check Link status on ethernet port */
 	link_is_up = mv_gop110_port_is_link_up(gop, &port->mac_data);
 
-
 	if (link_is_up) {
 		if (netif_carrier_ok(dev))
 			return;
@@ -1841,18 +1830,18 @@ static void mv_pp2x_width_calc(struct mv_pp2x_port *port, u32 *cpu_width,
 *     3: cos based on dscp for IP packets, and based on vlan for non-IP packets;
 */
 int mv_pp2x_cos_classifier_set(struct mv_pp2x_port *port,
-					enum mv_pp2x_cos_classifier cos_mode)
+			       enum mv_pp2x_cos_classifier cos_mode)
 {
 	int index, flow_idx, lkpid;
 	int data[MVPP2_LKP_PTR_NUM];
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 	struct mv_pp2x_cls_flow_info *flow_info;
 
 	for (index = 0; index < (MVPP2_PRS_FL_LAST - MVPP2_PRS_FL_START);
 		index++) {
 		int i, j;
 
-		flow_info = &(hw->cls_shadow->flow_info[index]);
+		flow_info = &hw->cls_shadow->flow_info[index];
 		/* Init data[] as invalid value */
 		for (i = 0; i < MVPP2_LKP_PTR_NUM; i++)
 			data[i] = MVPP2_FLOW_TBL_SIZE;
@@ -1889,26 +1878,26 @@ int mv_pp2x_cos_classifier_set(struct mv_pp2x_port *port,
 			    (cos_mode == MVPP2_COS_CLS_DSCP_VLAN &&
 				lkpid == MVPP2_PRS_FL_NON_IP_TAG))
 				mv_pp2x_cls_flow_port_add(hw,
-				flow_info->flow_entry_vlan, port->id);
+							  flow_info->flow_entry_vlan, port->id);
 			/* Hanlde NON-IP tagged packet */
 			else if (cos_mode == MVPP2_COS_CLS_DSCP &&
-					lkpid == MVPP2_PRS_FL_NON_IP_TAG)
+				 lkpid == MVPP2_PRS_FL_NON_IP_TAG)
 				mv_pp2x_cls_flow_port_add(hw,
-				flow_info->flow_entry_dflt, port->id);
+							  flow_info->flow_entry_dflt, port->id);
 			else if (cos_mode == MVPP2_COS_CLS_DSCP ||
-					cos_mode == MVPP2_COS_CLS_DSCP_VLAN)
+				 cos_mode == MVPP2_COS_CLS_DSCP_VLAN)
 				mv_pp2x_cls_flow_port_add(hw,
-				flow_info->flow_entry_dscp, port->id);
+							  flow_info->flow_entry_dscp, port->id);
 		} else {
 			if (lkpid == MVPP2_PRS_FL_NON_IP_UNTAG ||
-					cos_mode == MVPP2_COS_CLS_VLAN)
+			    cos_mode == MVPP2_COS_CLS_VLAN)
 				mv_pp2x_cls_flow_port_add(hw,
-				flow_info->flow_entry_dflt, port->id);
+							  flow_info->flow_entry_dflt, port->id);
 			else if (cos_mode == MVPP2_COS_CLS_DSCP ||
 				 cos_mode == MVPP2_COS_CLS_VLAN_DSCP ||
 				 cos_mode == MVPP2_COS_CLS_DSCP_VLAN)
 				mv_pp2x_cls_flow_port_add(hw,
-				flow_info->flow_entry_dscp, port->id);
+							  flow_info->flow_entry_dscp, port->id);
 		}
 		/* Restore lookup table */
 		flow_idx = data[0];
@@ -1927,7 +1916,6 @@ int mv_pp2x_cos_classifier_set(struct mv_pp2x_port *port,
 }
 EXPORT_SYMBOL(mv_pp2x_cos_classifier_set);
 
-
 /* mv_pp2x_cos_pri_map_set
 *  -- Set priority_map per port, nibble for each cos value(0~7).
 */
@@ -1936,14 +1924,12 @@ int mv_pp2x_cos_pri_map_set(struct mv_pp2x_port *port, int cos_pri_map)
 	int ret, prev_pri_map;
 	u8 bound_cpu_first_rxq;
 
-
 	if (port->cos_cfg.pri_map == cos_pri_map)
 		return 0;
 
 	prev_pri_map = port->cos_cfg.pri_map;
 	port->cos_cfg.pri_map = cos_pri_map;
 
-
 	/* Update C2 rules with nre pri_map */
 	bound_cpu_first_rxq  = mv_pp2x_bound_cpu_first_rxq_calc(port);
 	ret = mv_pp2x_cls_c2_rule_set(port, bound_cpu_first_rxq);
@@ -1956,8 +1942,6 @@ int mv_pp2x_cos_pri_map_set(struct mv_pp2x_port *port, int cos_pri_map)
 }
 EXPORT_SYMBOL(mv_pp2x_cos_pri_map_set);
 
-
-
 /* mv_pp2x_cos_default_value_set
 *  -- Set default cos value for untagged or non-IP packets per port.
 */
@@ -1984,7 +1968,6 @@ int mv_pp2x_cos_default_value_set(struct mv_pp2x_port *port, int cos_value)
 }
 EXPORT_SYMBOL(mv_pp2x_cos_default_value_set);
 
-
 /* RSS API */
 
 /* Translate CPU sequence number to real CPU ID */
@@ -2041,7 +2024,7 @@ int mv_pp22_rss_rxfh_indir_set(struct mv_pp2x_port *port)
 			rss_entry.u.entry.tbl_id = rss_tbl;
 			rss_entry.u.entry.tbl_line = entry_idx;
 			if (mv_pp22_cpu_id_from_indir_tbl_get(port->priv,
-			     port->priv->rx_indir_table[entry_idx],
+							      port->priv->rx_indir_table[entry_idx],
 			     &cpu_id))
 				return -1;
 			/* Value of rss_tbl equals to cos queue */
@@ -2073,9 +2056,9 @@ void mv_pp22_rss_enable(struct mv_pp2x_port *port, bool en)
 		port->rss_cfg.rss_en = en;
 		if (en) {
 			if (mv_pp22_rss_default_cpu_set(port,
-				port->rss_cfg.dflt_cpu)) {
+							port->rss_cfg.dflt_cpu)) {
 				netdev_err(port->dev,
-				"cannot set rss default cpu on port(%d)\n",
+					   "cannot set rss default cpu on port(%d)\n",
 				port->id);
 				port->rss_cfg.rss_en = 0;
 			}
@@ -2083,7 +2066,7 @@ void mv_pp22_rss_enable(struct mv_pp2x_port *port, bool en)
 			if (mv_pp2x_cls_c2_rule_set(port,
 						    bound_cpu_first_rxq)) {
 				netdev_err(port->dev,
-				"cannot set c2 and qos table on port(%d)\n",
+					   "cannot set c2 and qos table on port(%d)\n",
 				port->id);
 				port->rss_cfg.rss_en = 1;
 			}
@@ -2098,7 +2081,7 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 {
 	int index, flow_idx, flow_idx_rss, lkpid, lkpid_attr;
 	int data[3];
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 	struct mv_pp2x_cls_flow_info *flow_info;
 
 	if (port->priv->pp2_cfg.queue_mode == MVPP2_QDIST_SINGLE_MODE)
@@ -2112,7 +2095,7 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 
 	for (index = 0; index < (MVPP2_PRS_FL_LAST - MVPP2_PRS_FL_START);
 		index++) {
-		flow_info = &(hw->cls_shadow->flow_info[index]);
+		flow_info = &hw->cls_shadow->flow_info[index];
 		data[0] = MVPP2_FLOW_TBL_SIZE;
 		data[1] = MVPP2_FLOW_TBL_SIZE;
 		data[2] = MVPP2_FLOW_TBL_SIZE;
@@ -2130,9 +2113,9 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 			/* Update original flow table */
 			/* First, remove the port from original table */
 			mv_pp2x_cls_flow_port_del(hw,
-				flow_info->flow_entry_rss1, port->id);
+						  flow_info->flow_entry_rss1, port->id);
 			mv_pp2x_cls_flow_port_del(hw,
-				flow_info->flow_entry_rss2, port->id);
+						  flow_info->flow_entry_rss2, port->id);
 			if (flow_info->flow_entry_dflt)
 				data[0] = flow_info->flow_entry_dflt;
 			if (flow_info->flow_entry_vlan)
@@ -2148,9 +2131,9 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 
 			/*Find the ptr of flow table, the min flow index */
 			flow_idx_rss = min(flow_info->flow_entry_rss1,
-				flow_info->flow_entry_rss2);
+					   flow_info->flow_entry_rss2);
 			flow_idx = min(min(data[0], data[1]), min(data[2],
-				flow_idx_rss));
+								  flow_idx_rss));
 			/*Third, restore lookup table */
 			mv_pp2x_cls_lkp_flow_set(hw, lkpid, 0, flow_idx);
 			mv_pp2x_cls_lkp_flow_set(hw, lkpid, 1, flow_idx);
@@ -2158,7 +2141,7 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 			if (flow_info->flow_entry_rss1) {
 				flow_idx_rss = flow_info->flow_entry_rss1;
 				mv_pp2x_cls_flow_port_add(hw, flow_idx_rss,
-					port->id);
+							  port->id);
 		}
 	}
 	/* Record it in priv */
@@ -2168,7 +2151,6 @@ int mv_pp22_rss_mode_set(struct mv_pp2x_port *port, int rss_mode)
 }
 EXPORT_SYMBOL(mv_pp22_rss_mode_set);
 
-
 /* mv_pp22_rss_default_cpu_set
 *  -- The API to update the default CPU to handle the non-IP packets.
 */
@@ -2176,7 +2158,7 @@ int mv_pp22_rss_default_cpu_set(struct mv_pp2x_port *port, int default_cpu)
 {
 	u8 index, queue, q_cpu_mask;
 	u32 cpu_width = 0, cos_width = 0;
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 
 	if (port->priv->pp2_cfg.queue_mode == MVPP2_QDIST_SINGLE_MODE)
 		return -1;
@@ -2217,25 +2199,6 @@ int mv_pp22_rss_default_cpu_set(struct mv_pp2x_port *port, int default_cpu)
 EXPORT_SYMBOL(mv_pp22_rss_default_cpu_set);
 
 /* Main RX/TX processing routines */
-#if 0
-
-/* Reuse skb if possible, or allocate a new skb and add it to BM pool */
-static int mv_pp2x_rx_refill(struct mv_pp2x_port *port,
-			   struct mv_pp2x_bm_pool *bm_pool,
-			   u32 pool, int is_recycle, int cpu)
-{
-	struct sk_buff *skb;
-	dma_addr_t phys_addr;
-
-	/* No recycle or too many buffers are in use, so allocate a new skb */
-	skb = mv_pp2x_skb_alloc(port, bm_pool, &phys_addr, GFP_ATOMIC);
-	if (!skb)
-		return -ENOMEM;
-
-	mv_pp2x_pool_refill(port->priv, pool, phys_addr, skb, cpu);
-	return 0;
-}
-#endif
 
 /* Handle tx checksum */
 static u32 mv_pp2x_skb_tx_csum(struct mv_pp2x_port *port, struct sk_buff *skb)
@@ -2269,7 +2232,7 @@ static u32 mv_pp2x_skb_tx_csum(struct mv_pp2x_port *port, struct sk_buff *skb)
 }
 
 static void mv_pp2x_buff_hdr_rx(struct mv_pp2x_port *port,
-			      struct mv_pp2x_rx_desc *rx_desc, int cpu)
+				struct mv_pp2x_rx_desc *rx_desc, int cpu)
 {
 	struct mv_pp2x_buff_hdr *buff_hdr;
 	struct sk_buff *skb;
@@ -2300,7 +2263,7 @@ static void mv_pp2x_buff_hdr_rx(struct mv_pp2x_port *port,
 
 		/* Release buffer */
 		mv_pp2x_bm_pool_mc_put(port, pool_id, buff_phys_addr,
-				     buff_virt_addr, mc_id, cpu);
+				       buff_virt_addr, mc_id, cpu);
 
 		buff_phys_addr = buff_phys_addr_next;
 		buff_virt_addr = buff_virt_addr_next;
@@ -2309,11 +2272,11 @@ static void mv_pp2x_buff_hdr_rx(struct mv_pp2x_port *port,
 }
 
 static void mv_pp2x_set_skb_hash(struct mv_pp2x_rx_desc *rx_desc, u32 rx_status,
-				struct sk_buff *skb)
+				 struct sk_buff *skb)
 {
 	u32 hash;
 
-	hash = (u32) (rx_desc->u.pp22.buf_phys_addr_key_hash >> 40);
+	hash = (u32)(rx_desc->u.pp22.buf_phys_addr_key_hash >> 40);
 	if ((rx_status & MVPP2_RXD_L4_UDP) || (rx_status & MVPP2_RXD_L4_TCP))
 		skb_set_hash(skb, hash, PKT_HASH_TYPE_L4);
 	else
@@ -2322,7 +2285,7 @@ static void mv_pp2x_set_skb_hash(struct mv_pp2x_rx_desc *rx_desc, u32 rx_status,
 
 /* Main rx processing */
 static int mv_pp2x_rx(struct mv_pp2x_port *port, struct napi_struct *napi,
-			int rx_todo, struct mv_pp2x_rx_queue *rxq)
+		      int rx_todo, struct mv_pp2x_rx_queue *rxq)
 {
 	struct net_device *dev = port->dev;
 	int rx_received, rx_filled, i;
@@ -2414,7 +2377,7 @@ static int mv_pp2x_rx(struct mv_pp2x_port *port, struct napi_struct *napi,
 		}
 
 		err = mv_pp2x_rx_refill_new(port, bm_pool,
-			bm_pool->log_id, 0, cpu);
+					    bm_pool->log_id, 0, cpu);
 
 		if (err)
 			netdev_err(port->dev, "failed to refill BM pools\n");
@@ -2426,14 +2389,10 @@ static int mv_pp2x_rx(struct mv_pp2x_port *port, struct napi_struct *napi,
 #ifdef MVPP2_VERBOSE
 		mv_pp2x_skb_dump(skb, rx_desc->data_size, 4);
 #endif
-#if 0
-		dma_sync_single_for_cpu(dev->dev.parent, buf_phys_addr,
-					MVPP2_RX_BUF_SIZE(rx_desc->data_size),
-					DMA_FROM_DEVICE);
-#endif
+
 		rcvd_pkts++;
 		rcvd_bytes += rx_bytes;
-		skb_reserve(skb, MVPP2_MH_SIZE+NET_SKB_PAD);
+		skb_reserve(skb, MVPP2_MH_SIZE + NET_SKB_PAD);
 #ifdef CONFIG_MV_PTP_SERVICE
 		/* If packet is PTP fetch timestamp info and built into packet data */
 		mv_pp2_is_pkt_ptp_rx_proc(port, rx_desc, rx_bytes, skb->data, rcvd_pkts);
@@ -2465,7 +2424,7 @@ static int mv_pp2x_rx(struct mv_pp2x_port *port, struct napi_struct *napi,
 }
 
 static inline void tx_desc_unmap_put(struct device *dev,
-	struct mv_pp2x_tx_queue *txq, struct mv_pp2x_tx_desc *desc)
+				     struct mv_pp2x_tx_queue *txq, struct mv_pp2x_tx_desc *desc)
 {
 	dma_addr_t buf_phys_addr;
 
@@ -2478,7 +2437,7 @@ static inline void tx_desc_unmap_put(struct device *dev,
 
 /* Handle tx fragmentation processing */
 static int mv_pp2x_tx_frag_process(struct mv_pp2x_port *port,
-	struct sk_buff *skb, struct mv_pp2x_aggr_tx_queue *aggr_txq,
+				   struct sk_buff *skb, struct mv_pp2x_aggr_tx_queue *aggr_txq,
 	 struct mv_pp2x_tx_queue *txq)
 {
 	struct mv_pp2x_txq_pcpu *txq_pcpu = this_cpu_ptr(txq->pcpu);
@@ -2503,20 +2462,20 @@ static int mv_pp2x_tx_frag_process(struct mv_pp2x_port *port,
 		}
 		tx_desc->packet_offset = buf_phys_addr & MVPP2_TX_DESC_ALIGN;
 		mv_pp2x_txdesc_phys_addr_set(port->priv->pp2_version,
-			buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
+					     buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
 
 		if (i == (skb_shinfo(skb)->nr_frags - 1)) {
 			/* Last descriptor */
 			tx_desc->command = MVPP2_TXD_L_DESC;
 			mv_pp2x_txq_inc_put(port->priv->pp2_version, txq_pcpu,
-				(struct sk_buff *)((uintptr_t) skb | MVPP2_ETH_SHADOW_SKB),
+					    (struct sk_buff *)((uintptr_t)skb | MVPP2_ETH_SHADOW_SKB),
 				tx_desc);
 
 		} else {
 			/* Descriptor in the middle: Not First, Not Last */
 			tx_desc->command = 0;
 			mv_pp2x_txq_inc_put(port->priv->pp2_version,
-				txq_pcpu, NULL, tx_desc);
+					    txq_pcpu, NULL, tx_desc);
 		}
 	}
 
@@ -2537,7 +2496,7 @@ static int mv_pp2x_tx_frag_process(struct mv_pp2x_port *port,
 }
 
 static inline void mv_pp2x_tx_done_post_proc(struct mv_pp2x_tx_queue *txq,
-	struct mv_pp2x_txq_pcpu *txq_pcpu, struct mv_pp2x_port *port, int frags)
+					     struct mv_pp2x_txq_pcpu *txq_pcpu, struct mv_pp2x_port *port, int frags)
 {
 	int txq_count = mv_pp2x_txq_count(txq_pcpu);
 
@@ -2563,7 +2522,7 @@ static inline int mv_pp2_tso_validate(struct sk_buff *skb, struct net_device *de
 		pr_err("skb_is_gso(skb) returns true but features is not NETIF_F_TSO\n");
 		return 1;
 	}
-	if (skb_shinfo(skb)->frag_list != NULL) {
+	if (skb_shinfo(skb)->frag_list) {
 		pr_err("frag_list is not null\n");
 		return 1;
 	}
@@ -2573,11 +2532,11 @@ static inline int mv_pp2_tso_validate(struct sk_buff *skb, struct net_device *de
 	}
 	if (skb->len <= skb_shinfo(skb)->gso_size) {
 		pr_err("total_len (%d) less than gso_size (%d)\n",
-			skb->len, skb_shinfo(skb)->gso_size);
+		       skb->len, skb_shinfo(skb)->gso_size);
 		return 1;
 	}
-	if ((htons(ETH_P_IP) != skb->protocol) || (ip_hdr(skb)->protocol != IPPROTO_TCP)
-		|| (tcp_hdr(skb) == NULL)) {
+	if ((htons(ETH_P_IP) != skb->protocol) || (ip_hdr(skb)->protocol != IPPROTO_TCP) ||
+	    (!tcp_hdr(skb))) {
 		pr_err("Protocol is not TCP over IP\n");
 		return 1;
 	}
@@ -2647,11 +2606,11 @@ static inline int mv_pp2_tso_build_hdr_desc(struct mv_pp2x_tx_desc *tx_desc,
 	tx_desc->packet_offset = buf_phys_addr & MVPP2_TX_DESC_ALIGN;
 
 	mv_pp2x_txdesc_phys_addr_set(port->priv->pp2_version,
-		buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
+				     buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
 
 	mv_pp2x_txq_inc_put(port->priv->pp2_version,
-				txq_pcpu,
-				(struct sk_buff *)((uintptr_t) data_orig |
+			    txq_pcpu,
+				(struct sk_buff *)((uintptr_t)data_orig |
 				MVPP2_ETH_SHADOW_EXT), tx_desc);
 
 	return hdr_len;
@@ -2682,7 +2641,7 @@ static inline int mv_pp2_tso_build_data_desc(struct mv_pp2x_port *port,
 	tx_desc->packet_offset = buf_phys_addr & MVPP2_TX_DESC_ALIGN;
 
 	mv_pp2x_txdesc_phys_addr_set(port->priv->pp2_version,
-		buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
+				     buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
 
 	tx_desc->command = 0;
 
@@ -2692,18 +2651,18 @@ static inline int mv_pp2_tso_build_data_desc(struct mv_pp2x_port *port,
 
 		if (total_left == 0) {
 			/* last descriptor in SKB */
-			val = ((uintptr_t) skb | MVPP2_ETH_SHADOW_SKB);
+			val = ((uintptr_t)skb | MVPP2_ETH_SHADOW_SKB);
 		}
 	}
 	mv_pp2x_txq_inc_put(port->priv->pp2_version, txq_pcpu,
-				(struct sk_buff *)(val), tx_desc);
+			    (struct sk_buff *)(val), tx_desc);
 
 	return size;
 }
 
 /* send tso packet */
 static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
-			 struct mv_pp2x_tx_queue *txq,
+				struct mv_pp2x_tx_queue *txq,
 			 struct mv_pp2x_aggr_tx_queue *aggr_txq, int cpu)
 {
 	int frag = 0, i;
@@ -2779,14 +2738,14 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 		/* Sanity check */
 		if (total_desc_num >= max_desc_num) {
 			pr_err("%s: Used TX descriptors number %d is larger than allocated %d\n",
-				__func__, total_desc_num, max_desc_num);
-			goto outNoTxDesc;
+			       __func__, total_desc_num, max_desc_num);
+			goto out_no_tx_desc;
 		}
 
 		data = mv_pp2_extra_pool_get(port);
 		if (!data) {
 			pr_err("Can't allocate extra buffer for TSO\n");
-			goto outNoTxDesc;
+			goto out_no_tx_desc;
 		}
 		tx_desc = mv_pp2x_txq_next_desc_get(aggr_txq);
 		tx_desc->phys_txq = txq->id;
@@ -2800,7 +2759,7 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 						 data_left, tcp_seq, ip_id,
 						 total_len);
 		if (size < 0)
-			goto outNoTxDesc;
+			goto out_no_tx_desc;
 
 		total_bytes += size;
 
@@ -2808,12 +2767,11 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 		ip_id++;
 
 		while (data_left > 0) {
-
 			/* Sanity check */
 			if (total_desc_num >= max_desc_num) {
 				pr_err("%s: Used TX descriptors number %d is larger than allocated %d\n",
-					__func__, total_desc_num, max_desc_num);
-				goto outNoTxDesc;
+				       __func__, total_desc_num, max_desc_num);
+				goto out_no_tx_desc;
 			}
 			tx_desc = mv_pp2x_txq_next_desc_get(aggr_txq);
 			tx_desc->phys_txq = txq->id;
@@ -2822,7 +2780,7 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 							  frag_ptr, frag_size, data_left, total_len);
 
 			if (size < 0)
-				goto outNoTxDesc;
+				goto out_no_tx_desc;
 
 			total_desc_num++;
 			total_bytes += size;
@@ -2859,10 +2817,10 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 
 	return total_desc_num;
 
-outNoTxDesc:
+out_no_tx_desc:
 	/* No enough memory for packet header - rollback */
 	pr_err("%s: No TX descriptors - rollback %d, txq_count=%d, nr_frags=%d, skb=%p, len=%d, gso_segs=%d\n",
-			__func__, total_desc_num, aggr_txq->count, skb_shinfo(skb)->nr_frags,
+	       __func__, total_desc_num, aggr_txq->count, skb_shinfo(skb)->nr_frags,
 			skb, skb->len, skb_shinfo(skb)->gso_segs);
 
 	for (i = 0; i < total_desc_num; i++) {
@@ -2876,9 +2834,8 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 		shadow_buf = txq_pcpu->tx_buffs[txq_pcpu->txq_put_index];
 		data_size = txq_pcpu->data_size[txq_pcpu->txq_get_index];
 
-
 		mv_pp2x_txq_buf_free(port, (uintptr_t)shadow_skb, shadow_buf,
-					data_size);
+				     data_size);
 
 		mv_pp2x_txq_prev_desc_get(aggr_txq);
 	}
@@ -2919,7 +2876,7 @@ static int mv_pp2x_tx(struct sk_buff *skb, struct net_device *dev)
 	/* Check number of available descriptors */
 	if (mv_pp2x_aggr_desc_num_check(port->priv, aggr_txq, frags, cpu) ||
 	    mv_pp2x_txq_reserved_desc_num_proc(port->priv, txq,
-					     txq_pcpu, frags, cpu)) {
+					       txq_pcpu, frags, cpu)) {
 		netif_tx_stop_queue(nq);
 		frags = 0;
 		goto out;
@@ -2956,7 +2913,7 @@ static int mv_pp2x_tx(struct sk_buff *skb, struct net_device *dev)
 
 	tx_desc->packet_offset = buf_phys_addr & MVPP2_TX_DESC_ALIGN;
 	mv_pp2x_txdesc_phys_addr_set(port->priv->pp2_version,
-		buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
+				     buf_phys_addr & ~MVPP2_TX_DESC_ALIGN, tx_desc);
 
 	tx_cmd = mv_pp2x_skb_tx_csum(port, skb);
 	if (frags == 1) {
@@ -2965,14 +2922,14 @@ static int mv_pp2x_tx(struct sk_buff *skb, struct net_device *dev)
 		tx_cmd |= MVPP2_TXD_F_DESC | MVPP2_TXD_L_DESC;
 		tx_desc->command = tx_cmd;
 		mv_pp2x_txq_inc_put(port->priv->pp2_version,
-			txq_pcpu, (struct sk_buff *)((uintptr_t) skb |
+				    txq_pcpu, (struct sk_buff *)((uintptr_t)skb |
 			MVPP2_ETH_SHADOW_SKB), tx_desc);
 	} else {
 		/* First but not Last */
 		tx_cmd |= MVPP2_TXD_F_DESC | MVPP2_TXD_PADDING_DISABLE;
 		tx_desc->command = tx_cmd;
 		mv_pp2x_txq_inc_put(port->priv->pp2_version,
-			txq_pcpu, NULL, tx_desc);
+				    txq_pcpu, NULL, tx_desc);
 
 		/* Continue with other skb fragments */
 		if (mv_pp2x_tx_frag_process(port, skb, aggr_txq, txq)) {
@@ -3014,13 +2971,14 @@ static int mv_pp2x_tx(struct sk_buff *skb, struct net_device *dev)
 	}
 	/* PPV22 TX Post-Processing */
 
-	if (port->priv->pp2xdata->interrupt_tx_done == false)
+	if (!port->priv->pp2xdata->interrupt_tx_done)
 		mv_pp2x_tx_done_post_proc(txq, txq_pcpu, port, frags);
 
 	return NETDEV_TX_OK;
 }
+
 static inline void mv_pp2x_cause_misc_handle(struct mv_pp2x_port *port,
-	struct mv_pp2x_hw *hw, u32 cause_rx_tx)
+					     struct mv_pp2x_hw *hw, u32 cause_rx_tx)
 {
 	u32 cause_misc = cause_rx_tx & MVPP2_CAUSE_MISC_SUM_MASK;
 
@@ -3030,12 +2988,12 @@ static inline void mv_pp2x_cause_misc_handle(struct mv_pp2x_port *port,
 		/* Clear the cause register */
 		mv_pp2x_write(hw, MVPP2_ISR_MISC_CAUSE_REG, 0);
 		mv_pp2x_write(hw, MVPP2_ISR_RX_TX_CAUSE_REG(port->id),
-			    cause_rx_tx & ~MVPP2_CAUSE_MISC_SUM_MASK);
+			      cause_rx_tx & ~MVPP2_CAUSE_MISC_SUM_MASK);
 	}
 }
 
 static inline int mv_pp2x_cause_rx_handle(struct mv_pp2x_port *port,
-		struct queue_vector *q_vec, struct napi_struct *napi,
+					  struct queue_vector *q_vec, struct napi_struct *napi,
 		int budget, u32 cause_rx)
 {
 	int rx_done = 0, count = 0;
@@ -3134,9 +3092,9 @@ static int mv_pp22_poll(struct napi_struct *napi, int budget)
 
 	/*The read is in the q_vector's sw_thread_id  address_space */
 	cause_rx_tx = mv_pp22_thread_relaxed_read(hw, q_vec->sw_thread_id,
-			MVPP2_ISR_RX_TX_CAUSE_REG(port->id));
+						  MVPP2_ISR_RX_TX_CAUSE_REG(port->id));
 	pr_debug("%s port_id(%d), q_vec(%d), cpuId(%d), sw_thread_id(%d), isr_tx_rx(0x%x)\n",
-		__func__, port->id, (int)(q_vec - port->q_vector),
+		 __func__, port->id, (int)(q_vec - port->q_vector),
 		QV_THR_2_CPU(q_vec->sw_thread_id), q_vec->sw_thread_id, cause_rx_tx);
 
 	/*Process misc errors */
@@ -3219,10 +3177,8 @@ static void mv_serdes_port_init(struct mv_pp2x_port *port)
 	}
 }
 
-
 int mvcpn110_mac_hw_init(struct mv_pp2x_port *port)
 {
-
 	struct gop_hw *gop = &port->priv->hw.gop;
 	struct mv_mac_data *mac = &port->mac_data;
 	int gop_port = mac->gop_index;
@@ -3256,21 +3212,21 @@ void mv_pp2x_start_dev(struct mv_pp2x_port *port)
 	if (port->flags & MVPP2_F_IFCAP_NETMAP) {
 		if (mv_pp2x_netmap_rxq_init_buffers(port))
 			pr_debug("%s: Netmap rxq_init_buffers done\n",
-				__func__);
+				 __func__);
 		if (mv_pp2x_netmap_txq_init_buffers(port))
 			pr_debug("%s: Netmap txq_init_buffers done\n",
-				__func__);
+				 __func__);
 	}
 #endif /* DEV_NETMAP */
-	if (port->priv->pp2_version == PPV21)
+	if (port->priv->pp2_version == PPV21) {
 		mv_pp21_gmac_max_rx_size_set(port);
-	else {
+	} else {
 		switch (mac->phy_mode) {
 		case PHY_INTERFACE_MODE_RGMII:
 		case PHY_INTERFACE_MODE_SGMII:
 		case PHY_INTERFACE_MODE_QSGMII:
 			mv_gop110_gmac_max_rx_size_set(gop, mac_num,
-					port->pkt_size);
+						       port->pkt_size);
 		break;
 		case PHY_INTERFACE_MODE_XAUI:
 		case PHY_INTERFACE_MODE_RXAUI:
@@ -3278,7 +3234,7 @@ void mv_pp2x_start_dev(struct mv_pp2x_port *port)
 		case PHY_INTERFACE_MODE_SFI:
 		case PHY_INTERFACE_MODE_XFI:
 			mv_gop110_xlg_mac_max_rx_size_set(gop,
-					mac_num, port->pkt_size);
+							  mac_num, port->pkt_size);
 		break;
 		default:
 		break;
@@ -3303,12 +3259,12 @@ void mv_pp2x_start_dev(struct mv_pp2x_port *port)
 		mv_gop110_port_enable(gop, mac);
 	}
 
-	if (port->mac_data.phy_dev)
+	if (port->mac_data.phy_dev) {
 		phy_start(port->mac_data.phy_dev);
-	else {
+	} else {
 		mv_pp22_dev_link_event(port->dev);
 		tasklet_init(&port->link_change_tasklet, mv_pp2_link_change_tasklet,
-				(unsigned long)(port->dev));
+			     (unsigned long)(port->dev));
 	}
 
 	if (port->mac_data.phy_dev)
@@ -3379,7 +3335,7 @@ static int mv_pp2x_check_mtu_valid(struct net_device *dev, int mtu)
 }
 
 int mv_pp2x_check_ringparam_valid(struct net_device *dev,
-				       struct ethtool_ringparam *ring)
+				  struct ethtool_ringparam *ring)
 {
 	u16 new_rx_pending = ring->rx_pending;
 	u16 new_tx_pending = ring->tx_pending;
@@ -3435,12 +3391,11 @@ void mv_pp2x_check_queue_size_valid(struct mv_pp2x_port *port)
 
 	if (tx_queue_size != port->tx_ring_size)
 		pr_err("illegal Tx queue size value %d, round to %d\n",
-			    tx_queue_size, port->tx_ring_size);
+		       tx_queue_size, port->tx_ring_size);
 
 	if (rx_queue_size != port->rx_ring_size)
 		pr_err("illegal Rx queue size value %d, round to %d\n",
-			    rx_queue_size, port->rx_ring_size);
-
+		       rx_queue_size, port->rx_ring_size);
 }
 
 static int mv_pp2x_phy_connect(struct mv_pp2x_port *port)
@@ -3454,7 +3409,7 @@ static int mv_pp2x_phy_connect(struct mv_pp2x_port *port)
 		fp = mv_pp22_link_event;
 
 	phy_dev = of_phy_connect(port->dev, port->mac_data.phy_node,
-		fp, 0, port->mac_data.phy_mode);
+				 fp, 0, port->mac_data.phy_mode);
 	if (!phy_dev) {
 		dev_err(port->dev->dev.parent, "port ID: %d cannot connect to phy\n", port->id);
 		return -ENODEV;
@@ -3483,7 +3438,7 @@ int mv_pp2x_open_cls(struct net_device *dev)
 	struct mv_pp2x_port *port = netdev_priv(dev);
 	unsigned char mac_bcast[ETH_ALEN] = {
 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff };
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 	int err;
 	u32 cpu_width = 0, cos_width = 0, port_rxq_width = 0;
 	u8 bound_cpu_first_rxq;
@@ -3570,13 +3525,12 @@ int mv_pp2x_open_cls(struct net_device *dev)
 		/* Set rss default CPU only when rss enabled */
 		if (port->rss_cfg.rss_en) {
 			err = mv_pp22_rss_default_cpu_set(port,
-				port->rss_cfg.dflt_cpu);
+							  port->rss_cfg.dflt_cpu);
 			if (err) {
 				netdev_err(port->dev, "cannot set rss default cpu\n");
 				return err;
 			}
 		}
-
 	}
 
 	return 0;
@@ -3716,7 +3670,7 @@ static void mv_pp2x_set_rx_mode(struct net_device *dev)
 {
 	struct mv_pp2x_port *port = netdev_priv(dev);
 	struct netdev_hw_addr *ha;
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 	int id = port->id;
 	int err;
 
@@ -3768,7 +3722,7 @@ static void mv_pp2x_set_rx_mode(struct net_device *dev)
 								  true);
 					if (err)
 						netdev_err(dev,
-						"MAC[%2x:%2x:%2x:%2x:%2x:%2x] add failed\n",
+							   "MAC[%2x:%2x:%2x:%2x:%2x:%2x] add failed\n",
 						ha->addr[0], ha->addr[1],
 						ha->addr[2], ha->addr[3],
 						ha->addr[4], ha->addr[5]);
@@ -3958,7 +3912,7 @@ int mv_pp2x_of_irq_count(struct device_node *dev)
 
 /* Currently only support LK-3.18 and above, no back support */
 static int mv_pp2x_netdev_set_features(struct net_device *dev,
-	netdev_features_t features)
+				       netdev_features_t features)
 {
 	netdev_features_t changed = dev->features ^ features;
 	struct mv_pp2x_port *port = netdev_priv(dev);
@@ -3990,7 +3944,7 @@ static int mv_pp2x_netdev_set_features(struct net_device *dev,
 }
 
 u16 mv_pp2x_select_queue(struct net_device *dev, struct sk_buff *skb,
-		       void *accel_priv, select_queue_fallback_t fallback)
+			 void *accel_priv, select_queue_fallback_t fallback)
 
 {
 	if (skb->queue_mapping)
@@ -4018,7 +3972,6 @@ u16 mv_pp2x_select_queue(struct net_device *dev, struct sk_buff *skb,
 
 static void mv_pp21_port_power_up(struct mv_pp2x_port *port)
 {
-
 	mv_pp21_port_mii_set(port);
 	mv_pp21_port_periodic_xon_disable(port);
 	mv_pp21_port_fc_adv_enable(port);
@@ -4026,7 +3979,7 @@ static void mv_pp21_port_power_up(struct mv_pp2x_port *port)
 }
 
 static int  mv_pp2x_port_txqs_init(struct device *dev,
-		struct mv_pp2x_port *port)
+				   struct mv_pp2x_port *port)
 {
 	int queue, cpu;
 	struct mv_pp2x_txq_pcpu *txq_pcpu;
@@ -4061,7 +4014,7 @@ static int  mv_pp2x_port_txqs_init(struct device *dev,
 }
 
 static int  mv_pp2x_port_rxqs_init(struct device *dev,
-		struct mv_pp2x_port *port)
+				   struct mv_pp2x_port *port)
 {
 	int queue;
 
@@ -4097,7 +4050,7 @@ static void mv_pp21_port_queue_vectors_init(struct mv_pp2x_port *port)
 	q_vec[0].sw_thread_mask = port->priv->cpu_map;
 	q_vec[0].irq = port->of_irqs[0];
 	netif_napi_add(port->dev, &q_vec[0].napi, mv_pp21_poll,
-		NAPI_POLL_WEIGHT);
+		       NAPI_POLL_WEIGHT);
 
 	port->num_qvector = 1;
 }
@@ -4127,16 +4080,16 @@ static void mv_pp22_queue_vectors_init(struct mv_pp2x_port *port)
 		q_vec[cpu].parent = port;
 		q_vec[cpu].qv_type = MVPP2_PRIVATE;
 		q_vec[cpu].sw_thread_id = sw_thread_index++;
-		q_vec[cpu].sw_thread_mask = (1<<q_vec[cpu].sw_thread_id);
+		q_vec[cpu].sw_thread_mask = (1 << q_vec[cpu].sw_thread_id);
 		q_vec[cpu].pending_cause_rx = 0;
-		if (port->priv->pp2xdata->interrupt_tx_done == true ||
+		if (port->priv->pp2xdata->interrupt_tx_done ||
 		    mv_pp2x_queue_mode == MVPP2_QDIST_MULTI_MODE)
 			q_vec[cpu].irq = port->of_irqs[irq_index++];
 		netif_napi_add(net_dev, &q_vec[cpu].napi, mv_pp22_poll,
 			       NAPI_POLL_WEIGHT);
 		if (mv_pp2x_queue_mode == MVPP2_QDIST_MULTI_MODE) {
 			q_vec[cpu].num_rx_queues = mv_pp2x_num_cos_queues;
-			q_vec[cpu].first_rx_queue = cpu*mv_pp2x_num_cos_queues;
+			q_vec[cpu].first_rx_queue = cpu * mv_pp2x_num_cos_queues;
 		} else {
 			q_vec[cpu].first_rx_queue = 0;
 			q_vec[cpu].num_rx_queues = 0;
@@ -4148,7 +4101,7 @@ static void mv_pp22_queue_vectors_init(struct mv_pp2x_port *port)
 		q_vec[cpu].parent = port;
 		q_vec[cpu].qv_type = MVPP2_SHARED;
 		q_vec[cpu].sw_thread_id = irq_index;
-		q_vec[cpu].sw_thread_mask = (1<<q_vec[cpu].sw_thread_id);
+		q_vec[cpu].sw_thread_mask = (1 << q_vec[cpu].sw_thread_id);
 		q_vec[cpu].pending_cause_rx = 0;
 		q_vec[cpu].irq = port->of_irqs[irq_index];
 		netif_napi_add(net_dev, &q_vec[cpu].napi, mv_pp22_poll,
@@ -4171,7 +4124,7 @@ static void mv_pp2x_port_irq_names_update(struct mv_pp2x_port *port)
 	parent_dev = net_dev->dev.parent;
 
 	snprintf(str_common, sizeof(str_common), "%s.%s",
-		dev_name(parent_dev), net_dev->name);
+		 dev_name(parent_dev), net_dev->name);
 
 	if (port->priv->pp2_version == PPV21) {
 		snprintf(q_vec[0].irq_name, IRQ_NAME_SIZE, "%s", str_common);
@@ -4184,32 +4137,32 @@ static void mv_pp2x_port_irq_names_update(struct mv_pp2x_port *port)
 		if (q_vec[i].qv_type == MVPP2_PRIVATE) {
 			cpu = QV_THR_2_CPU(q_vec[i].sw_thread_id);
 			snprintf(q_vec[i].irq_name, IRQ_NAME_SIZE, "%s.%s%d",
-				str_common, "cpu", cpu);
+				 str_common, "cpu", cpu);
 		} else {
 			snprintf(q_vec[i].irq_name, IRQ_NAME_SIZE, "%s.%s",
-				str_common, "rx_shared");
+				 str_common, "rx_shared");
 		}
 	}
 	snprintf(port->mac_data.irq_name, IRQ_NAME_SIZE, "%s.%s", str_common,
-		"link");
+		 "link");
 }
 
 static void mv_pp21x_port_isr_rx_group_cfg(struct mv_pp2x_port *port)
 {
 	mv_pp21_isr_rx_group_write(&port->priv->hw, port->id,
-		port->num_rx_queues);
+				   port->num_rx_queues);
 }
 
 static void mv_pp22_port_isr_rx_group_cfg(struct mv_pp2x_port *port)
 {
 	int i;
 /*	u8 cur_rx_queue; */
-	struct mv_pp2x_hw *hw = &(port->priv->hw);
+	struct mv_pp2x_hw *hw = &port->priv->hw;
 
 	for (i = 0; i < port->num_qvector; i++) {
 		if (port->q_vector[i].num_rx_queues != 0) {
 			mv_pp22_isr_rx_group_write(hw, port->id,
-				port->q_vector[i].sw_thread_id,
+						   port->q_vector[i].sw_thread_id,
 				port->q_vector[i].first_rx_queue,
 				port->q_vector[i].num_rx_queues);
 		}
@@ -4217,7 +4170,7 @@ static void mv_pp22_port_isr_rx_group_cfg(struct mv_pp2x_port *port)
 }
 
 static int mv_pp2_init_emac_data(struct mv_pp2x_port *port,
-		struct device_node *emac_node)
+				 struct device_node *emac_node)
 {
 	struct device_node *fixed_link_node, *phy_node;
 	int phy_mode;
@@ -4238,7 +4191,7 @@ static int mv_pp2_init_emac_data(struct mv_pp2x_port *port,
 		port->mac_data.duplex = of_property_read_bool(fixed_link_node,
 				"full-duplex");
 		if (of_property_read_u32(fixed_link_node, "speed",
-				&port->mac_data.speed))
+					 &port->mac_data.speed))
 			return -EINVAL;
 	} else {
 		port->mac_data.force_link = false;
@@ -4278,19 +4231,19 @@ static int mv_pp2_init_emac_data(struct mv_pp2x_port *port,
 	}
 	port->mac_data.phy_mode = phy_mode;
 	pr_debug("gop_mac(%d), phy_mode(%d) (%s)\n", id,  phy_mode,
-		phy_modes(phy_mode));
+		 phy_modes(phy_mode));
 	pr_debug("gop_mac(%d), phy_speed(%d)\n", id,  port->mac_data.speed);
 
 	phy_node = of_parse_phandle(emac_node, "phy", 0);
 	if (phy_node) {
 		port->mac_data.phy_node = phy_node;
 		if (of_property_read_u32(phy_node, "reg",
-		    &port->mac_data.phy_addr))
+					 &port->mac_data.phy_addr))
 			netdev_err(port->dev, "%s: NO PHY address on emac %d\n",
 				   __func__, port->mac_data.gop_index);
 
 		pr_debug("gop_mac(%d), phy_reg(%d)\n", id,
-			     port->mac_data.phy_addr);
+			 port->mac_data.phy_addr);
 	} else {
 		pr_debug("No PHY NODE on emac %d\n", id);
 	}
@@ -4457,7 +4410,7 @@ static void mv_pp2x_port_init_config(struct mv_pp2x_port *port)
 
 /* Ports initialization */
 static int mv_pp2x_port_probe(struct platform_device *pdev,
-			    struct device_node *port_node,
+			      struct device_node *port_node,
 			    struct mv_pp2x *priv)
 {
 	struct device_node *emac_node;
@@ -4479,7 +4432,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 	struct phy *comphy;
 
 	dev = alloc_etherdev_mqs(sizeof(struct mv_pp2x_port),
-		mv_pp2x_txq_number, mv_pp2x_rxq_number);
+				 mv_pp2x_txq_number, mv_pp2x_rxq_number);
 	if (!dev)
 		return -ENOMEM;
 
@@ -4555,7 +4508,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 		}
 	}
 	pr_info("mac_addr %x:%x:%x:%x:%x:%x",
-			dev->dev_addr[0],
+		dev->dev_addr[0],
 			dev->dev_addr[1], dev->dev_addr[2], dev->dev_addr[3],
 			dev->dev_addr[4], dev->dev_addr[5]);
 
@@ -4567,7 +4520,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 		goto err_free_netdev;
 	}
 	port_irqs = devm_kcalloc(&pdev->dev, port_num_irq,
-			sizeof(u32), GFP_KERNEL);
+				 sizeof(u32), GFP_KERNEL);
 	port->of_irqs = port_irqs;
 	port->num_irqs = 0;
 	for (i = 0; i < port_num_irq; i++) {
@@ -4593,10 +4546,10 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 	mv_pp2x_set_ethtool_ops(dev);
 
 	if (priv->pp2_version == PPV21)
-		port->first_rxq = (port->id)*mv_pp2x_rxq_number +
+		port->first_rxq = (port->id) * mv_pp2x_rxq_number +
 			first_log_rxq_queue;
 	else
-		port->first_rxq = (port->id)*(priv->pp2xdata->pp2x_max_port_rxqs) +
+		port->first_rxq = (port->id) * priv->pp2xdata->pp2x_max_port_rxqs +
 			first_log_rxq_queue;
 
 	if (priv->pp2_version == PPV21) {
@@ -4622,7 +4575,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 	mv_pp2x_check_queue_size_valid(port);
 
 	if (mv_pp2_num_cpu_irqs(port) < num_active_cpus() &&
-	    port->priv->pp2xdata->interrupt_tx_done == true) {
+	    port->priv->pp2xdata->interrupt_tx_done) {
 		port->priv->pp2xdata->interrupt_tx_done = false;
 		dev_info(&pdev->dev, "mvpp2x: interrupt_tx_done override to false\n");
 	}
@@ -4640,7 +4593,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 		err = -ENOMEM;
 		goto err_free_txq_pcpu;
 	}
-	if (port->priv->pp2xdata->interrupt_tx_done == false) {
+	if (!port->priv->pp2xdata->interrupt_tx_done) {
 		for_each_online_cpu(cpu) {
 			port_pcpu = per_cpu_ptr(port->pcpu, cpu);
 
@@ -4650,7 +4603,7 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 			port_pcpu->timer_scheduled = false;
 
 			tasklet_init(&port_pcpu->tx_done_tasklet,
-				mv_pp2x_tx_proc_cb, (unsigned long)dev);
+				     mv_pp2x_tx_proc_cb, (unsigned long)dev);
 		}
 	}
 	/* Init pool of external buffers for TSO, fragmentation, etc */
@@ -4664,19 +4617,19 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 		port_pcpu->ext_buf_pool->buf_pool_size = MVPP2_EXTRA_BUF_NUM;
 		port_pcpu->ext_buf_pool->ext_buf_struct =
 			devm_kzalloc(port->dev->dev.parent,
-			sizeof(*ext_buf_struct) * MVPP2_EXTRA_BUF_NUM, GFP_ATOMIC);
+				     sizeof(*ext_buf_struct) * MVPP2_EXTRA_BUF_NUM, GFP_ATOMIC);
 
 		for (i = 0; i < MVPP2_EXTRA_BUF_NUM; i++) {
 			u8 *ext_buf = kmalloc(MVPP2_EXTRA_BUF_SIZE, GFP_ATOMIC);
 
 			port_pcpu->ext_buf_pool->ext_buf_struct[i].ext_buf_data = ext_buf;
-			if (ext_buf == NULL) {
+			if (!ext_buf) {
 				pr_warn("\to %s Warning: %d of %d extra buffers allocated\n",
 					__func__, i, MVPP2_EXTRA_BUF_NUM);
 				break;
 			}
 			list_add(&port_pcpu->ext_buf_pool->ext_buf_struct[i].ext_buf_list,
-				&port_pcpu->ext_buf_port_list);
+				 &port_pcpu->ext_buf_port_list);
 			port_pcpu->ext_buf_pool->buf_pool_in_use++;
 		}
 	}
@@ -4759,7 +4712,7 @@ static void mv_pp2x_port_remove(struct mv_pp2x_port *port)
 
 /* Initialize decoding windows */
 static void mv_pp2x_conf_mbus_windows(const struct mbus_dram_target_info *dram,
-				    struct mv_pp2x_hw *hw)
+				      struct mv_pp2x_hw *hw)
 {
 	u32 win_enable;
 	int i;
@@ -4778,11 +4731,11 @@ static void mv_pp2x_conf_mbus_windows(const struct mbus_dram_target_info *dram,
 		const struct mbus_dram_window *cs = dram->cs + i;
 
 		mv_pp2x_write(hw, MVPP2_WIN_BASE(i),
-			    (cs->base & 0xffff0000) | (cs->mbus_attr << 8) |
+			      (cs->base & 0xffff0000) | (cs->mbus_attr << 8) |
 			    dram->mbus_dram_target_id);
 
 		mv_pp2x_write(hw, MVPP2_WIN_SIZE(i),
-			    (cs->size - 1) & 0xffff0000);
+			      (cs->size - 1) & 0xffff0000);
 
 		win_enable |= (1 << i);
 	}
@@ -4878,7 +4831,7 @@ static int mv_pp2x_init(struct platform_device *pdev, struct mv_pp2x *priv)
 		val |= MVPP2_PHY_AN_STOP_SMI0_MASK;
 		writel(val, hw->lms_base + MVPP2_PHY_AN_CFG0_REG);
 		writel(MVPP2_EXT_GLOBAL_CTRL_DEFAULT,
-			hw->lms_base + MVPP2_MNG_EXTENDED_GLOBAL_CTRL_REG);
+		       hw->lms_base + MVPP2_MNG_EXTENDED_GLOBAL_CTRL_REG);
 	}
 
 	/* Allocate and initialize aggregated TXQs */
@@ -4896,7 +4849,7 @@ static int mv_pp2x_init(struct platform_device *pdev, struct mv_pp2x *priv)
 		priv->aggr_txqs[i].size = MVPP2_AGGR_TXQ_SIZE;
 
 		err = mv_pp2x_aggr_txq_init(pdev, &priv->aggr_txqs[i],
-					  MVPP2_AGGR_TXQ_SIZE, i, priv);
+					    MVPP2_AGGR_TXQ_SIZE, i, priv);
 		if (err < 0)
 			return err;
 		i++;
@@ -5005,11 +4958,11 @@ static void mv_pp22_init_rxfhindir(struct mv_pp2x *pp2)
 		return;
 
 	for (i = 0; i < MVPP22_RSS_TBL_LINE_NUM; i++)
-		pp2->rx_indir_table[i] = i%online_cpus;
+		pp2->rx_indir_table[i] = i % online_cpus;
 }
 
 static int mv_pp2x_platform_data_get(struct platform_device *pdev,
-		struct mv_pp2x *priv,	u32 *cell_index, int *port_count)
+				     struct mv_pp2x *priv,	u32 *cell_index, int *port_count)
 {
 	struct mv_pp2x_hw *hw = &priv->hw;
 	static int auto_cell_index;
@@ -5024,15 +4977,14 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 	if (!match)
 		return -ENODEV;
 
-	priv->pp2xdata = (struct mv_pp2x_platform_data *) match->data;
+	priv->pp2xdata = (struct mv_pp2x_platform_data *)match->data;
 
 	if (of_property_read_u32(dn, "cell-index", cell_index)) {
 		*cell_index = auto_cell_index;
 		auto_cell_index++;
-	}
-
-	else
+	} else {
 		cell_index_dts_flag = true;
+	}
 
 	if (auto_cell_index && cell_index_dts_flag)
 		return -ENXIO;
@@ -5058,7 +5010,7 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 			return PTR_ERR(hw->base);
 		/* xmib */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "xmib");
+						   IORESOURCE_MEM, "xmib");
 		hw->gop.gop_110.xmib.base =
 			devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(hw->gop.gop_110.xmib.base))
@@ -5069,7 +5021,7 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 
 		/* smi */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "smi");
+						   IORESOURCE_MEM, "smi");
 		hw->gop.gop_110.smi_base =
 			devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(hw->gop.gop_110.smi_base))
@@ -5077,7 +5029,7 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 
 		/* rfu1 */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "rfu1");
+						   IORESOURCE_MEM, "rfu1");
 		hw->gop.gop_110.rfu1_base =
 			devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(hw->gop.gop_110.rfu1_base))
@@ -5087,7 +5039,7 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 
 		/* xsmi  */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "xsmi");
+						   IORESOURCE_MEM, "xsmi");
 		hw->gop.gop_110.xsmi_base =
 			devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(hw->gop.gop_110.xsmi_base))
@@ -5095,7 +5047,7 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 
 		/* MSPG - base register */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "mspg");
+						   IORESOURCE_MEM, "mspg");
 		hw->gop.gop_110.mspg_base =
 			devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(hw->gop.gop_110.mspg_base))
@@ -5105,44 +5057,44 @@ static int mv_pp2x_platform_data_get(struct platform_device *pdev,
 
 		/* xpcs */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "xpcs");
+						   IORESOURCE_MEM, "xpcs");
 		if ((res->start <= mspg_base) || (res->end >= mspg_end))
 			return -ENXIO;
 		hw->gop.gop_110.xpcs_base =
 			(void *)(hw->gop.gop_110.mspg_base +
-				(res->start-mspg_base));
+				(res->start - mspg_base));
 
 		hw->gop.gop_110.ptp.base =
 			(void *)(hw->gop.gop_110.mspg_base + 0x0800);
 		hw->gop.gop_110.ptp.obj_size = 0x1000;
 		/* MSPG - gmac */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "gmac");
+						   IORESOURCE_MEM, "gmac");
 		if ((res->start <= mspg_base) || (res->end >= mspg_end))
 			return -ENXIO;
 		hw->gop.gop_110.gmac.base =
 			(void *)(hw->gop.gop_110.mspg_base +
-			(res->start-mspg_base));
+			(res->start - mspg_base));
 		hw->gop.gop_110.gmac.obj_size = 0x1000;
 
 		/* FCA - flow control*/
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "fca");
+						   IORESOURCE_MEM, "fca");
 		if ((res->start <= mspg_base) || (res->end >= mspg_end))
 			return -ENXIO;
 		hw->gop.gop_110.fca.base =
 			(void *)(hw->gop.gop_110.mspg_base +
-			(res->start-mspg_base));
+			(res->start - mspg_base));
 		hw->gop.gop_110.fca.obj_size = 0x1000;
 
 		/* MSPG - xlg */
 		res = platform_get_resource_byname(pdev,
-			IORESOURCE_MEM, "xlg");
+						   IORESOURCE_MEM, "xlg");
 		if ((res->start <= mspg_base) || (res->end >= mspg_end))
 			return -ENXIO;
 		hw->gop.gop_110.xlg_mac.base =
 			(void *)(hw->gop.gop_110.mspg_base +
-			(res->start-mspg_base));
+			(res->start - mspg_base));
 		hw->gop.gop_110.xlg_mac.obj_size = 0x1000;
 
 		/* Jumbo L4_checksum port */
@@ -5244,18 +5196,18 @@ static void mv_pp22_tx_fifo_init(struct mv_pp2x *priv)
 	for (i = 0; i < priv->num_ports; i++) {
 		if (priv->port_list[i]->id != priv->l4_chksum_jumbo_port) {
 			mv_pp2x_tx_fifo_size_set(&priv->hw,
-					    priv->port_list[i]->id,
+						 priv->port_list[i]->id,
 					    MVPP2_TX_FIFO_DATA_SIZE_3KB);
 			mv_pp2x_tx_fifo_threshold_set(&priv->hw,
-					    priv->port_list[i]->id,
+						      priv->port_list[i]->id,
 					    MVPP2_TX_FIFO_THRESHOLD_3KB);
 			}
 	}
 	mv_pp2x_tx_fifo_size_set(&priv->hw,
-			    priv->l4_chksum_jumbo_port,
+				 priv->l4_chksum_jumbo_port,
 			    MVPP2_TX_FIFO_DATA_SIZE_10KB);
 	mv_pp2x_tx_fifo_threshold_set(&priv->hw,
-			    priv->l4_chksum_jumbo_port,
+				      priv->l4_chksum_jumbo_port,
 			    MVPP2_TX_FIFO_THRESHOLD_10KB);
 }
 
@@ -5266,13 +5218,13 @@ static void mvpp21_rx_fifo_init(struct mv_pp2x *priv)
 
 	for (port = 0; port < MVPP2_MAX_PORTS; port++) {
 		mv_pp2x_write(&priv->hw, MVPP2_RX_DATA_FIFO_SIZE_REG(port),
-			    MVPP2_RX_FIFO_PORT_DATA_SIZE);
+			      MVPP2_RX_FIFO_PORT_DATA_SIZE);
 		mv_pp2x_write(&priv->hw, MVPP2_RX_ATTR_FIFO_SIZE_REG(port),
-			    MVPP2_RX_FIFO_PORT_ATTR_SIZE);
+			      MVPP2_RX_FIFO_PORT_ATTR_SIZE);
 	}
 
 	mv_pp2x_write(&priv->hw, MVPP2_RX_MIN_PKT_SIZE_REG,
-		    MVPP2_RX_FIFO_PORT_MIN_PKT);
+		      MVPP2_RX_FIFO_PORT_MIN_PKT);
 	mv_pp2x_write(&priv->hw, MVPP2_RX_FIFO_INIT_REG, 0x1);
 }
 
@@ -5304,7 +5256,6 @@ void mv_pp22_set_net_comp(struct mv_pp2x *priv)
 	mv_gop110_netc_init(&priv->hw.gop, net_comp_config, MV_NETC_SECOND_PHASE);
 }
 
-
 static int mv_pp2x_probe(struct platform_device *pdev)
 {
 	struct mv_pp2x *priv;
@@ -5345,11 +5296,11 @@ static int mv_pp2x_probe(struct platform_device *pdev)
 	cpu_map = 0;
 	i = 0;
 	for_each_online_cpu(cpu) {
-		cpu_map |= (1<<cpu);
+		cpu_map |= (1 << cpu);
 		hw->cpu_base[cpu] = hw->base;
 		if (priv->pp2xdata->multi_addr_space) {
 			hw->cpu_base[cpu] +=
-				(first_addr_space + i)*MVPP2_ADDR_SPACE_SIZE;
+				(first_addr_space + i) * MVPP2_ADDR_SPACE_SIZE;
 			i++;
 		}
 	}
@@ -5400,10 +5351,9 @@ static int mv_pp2x_probe(struct platform_device *pdev)
 		/* Init tx fifo for each port */
 		mv_pp22_tx_fifo_init(priv);
 		mv_pp22_set_net_comp(priv);
-	}
-
-	else
+	} else {
 		mv_pp21_fifo_init(priv);
+	}
 
 	platform_set_drvdata(pdev, priv);
 
-- 
1.7.9.5

