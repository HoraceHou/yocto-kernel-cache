From 6681f99abe286d0bbd4e362c26b1a00300868e1d Mon Sep 17 00:00:00 2001
From: Stefan Chulski <stefanc@marvell.com>
Date: Mon, 5 Dec 2016 14:10:34 +0200
Subject: [PATCH 0634/1345] net: mvpp2x: Separate function for TSO TXQ
 reservations.

commit  0654b3a5c4fbd7fa7adc5db55ec90aa3dd7adf4a from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

- check if there are enough TXQ descriptors only for TSO traffic
- add likely/unlikely cases

Change-Id: I50b0c570ea367b9f9e8d1bd5a8aa5c034b7455d7
Signed-off-by: Stefan Chulski <stefanc@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/34348
Reviewed-by: Omri Itach <omrii@marvell.com>
Tested-by: Omri Itach <omrii@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c |   40 ++++++++++++++++++--
 1 file changed, 36 insertions(+), 4 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
index 913e0c6..91e15b8 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
@@ -863,6 +863,38 @@ int mv_pp2x_txq_reserved_desc_num_proc(
 					struct mv_pp2x_txq_pcpu *txq_pcpu,
 					int num, int cpu)
 {
+	int req;
+
+	if (likely(txq_pcpu->reserved_num >= num))
+		return 0;
+
+	/* Not enough descriptors reserved! Update the reserved descriptor
+	 * count and check again.
+	 */
+
+	/* Entire txq_size is used for SWF . Must be changed when HWF
+	 * is implemented.
+	 * There will always be at least one CHUNK available
+	 */
+
+	req = MVPP2_CPU_DESC_CHUNK;
+
+	txq_pcpu->reserved_num += mv_pp2x_txq_alloc_reserved_desc(priv, txq,
+							req, cpu);
+
+	/* OK, the descriptor cound has been updated: check again. */
+	if (unlikely(txq_pcpu->reserved_num < num))
+		return -ENOMEM;
+
+	return 0;
+}
+
+int mv_pp2x_tso_txq_reserved_desc_num_proc(
+					struct mv_pp2x *priv,
+					struct mv_pp2x_tx_queue *txq,
+					struct mv_pp2x_txq_pcpu *txq_pcpu,
+					int num, int cpu)
+{
 	int req, cpu_desc, desc_count;
 
 	if (txq_pcpu->reserved_num >= num)
@@ -879,7 +911,7 @@ int mv_pp2x_txq_reserved_desc_num_proc(
 
 	req = MVPP2_CPU_DESC_CHUNK;
 
-	if ((num - txq_pcpu->reserved_num) > req) {
+	if (unlikely((num - txq_pcpu->reserved_num) > req)) {
 		req = num - txq_pcpu->reserved_num;
 		desc_count = 0;
 		/* Compute total of used descriptors */
@@ -894,7 +926,7 @@ int mv_pp2x_txq_reserved_desc_num_proc(
 		}
 		desc_count += req;
 
-		if (desc_count > txq->size)
+		if (unlikely(desc_count > txq->size))
 			return -ENOMEM;
 	}
 
@@ -902,7 +934,7 @@ int mv_pp2x_txq_reserved_desc_num_proc(
 							req, cpu);
 
 	/* OK, the descriptor cound has been updated: check again. */
-	if (txq_pcpu->reserved_num < num)
+	if (unlikely(txq_pcpu->reserved_num < num))
 		return -ENOMEM;
 
 	return 0;
@@ -2698,7 +2730,7 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 
 	/* Check number of available descriptors */
 	if (mv_pp2x_aggr_desc_num_check(port->priv, aggr_txq, max_desc_num, cpu) ||
-	    mv_pp2x_txq_reserved_desc_num_proc(port->priv, txq,
+	    mv_pp2x_tso_txq_reserved_desc_num_proc(port->priv, txq,
 						   txq_pcpu, max_desc_num, cpu)) {
 		netif_tx_stop_queue(nq);
 		return 0;
-- 
1.7.9.5

