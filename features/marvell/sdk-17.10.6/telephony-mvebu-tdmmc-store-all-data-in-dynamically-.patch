From 8ae33d2641a144a10957cbc6acc15c4460894135 Mon Sep 17 00:00:00 2001
From: Marcin Wojtas <mw@semihalf.com>
Date: Tue, 27 Dec 2016 18:57:54 +0100
Subject: [PATCH 0690/1345] telephony: mvebu: tdmmc: store all data in
 dynamically allocated structure

commit  d48ed331fc5d0ad036b170f47ec9819175f0d929 from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

This patch is significant, but couldn't be split into smaller ones due to
big amount of global variables. Changes are following:
* Remove all global variables and store them in newly created tdmmc_dev
  structure.
* Structure is dynamically allocated by 'managed' allocator (devm_...)
  after calling tdm_if_init -> ... -> tdmmc_init. In consecutive
  initialization sequences the data are reset to initial values.
* Improve line breaking and alignment of modified code.

Change-Id: Ie5d5266c554f77ed2c622983f3c6d1261cd0b15a
Signed-off-by: Marcin Wojtas <mw@semihalf.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/35154
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Reviewed-by: Hanna Hawa <hannah@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/telephony/mvebu_phone/tdmmc/tdmmc.c |  557 ++++++++++++++-------------
 drivers/telephony/mvebu_phone/tdmmc/tdmmc.h |   33 ++
 2 files changed, 315 insertions(+), 275 deletions(-)

diff --git a/drivers/telephony/mvebu_phone/tdmmc/tdmmc.c b/drivers/telephony/mvebu_phone/tdmmc/tdmmc.c
index f168cb3..5a9d528 100644
--- a/drivers/telephony/mvebu_phone/tdmmc/tdmmc.c
+++ b/drivers/telephony/mvebu_phone/tdmmc/tdmmc.c
@@ -96,60 +96,48 @@
 
 #include "mv_phone.h"
 
-/* globals */
-static int tdm_enable;
-static int pcm_enable;
-static u8 sample_size;
-static u8 sampling_coeff;
-static u16 total_channels;
-static u8 prev_rx_buff, next_tx_buff;
-static u8 *rx_buff_virt[TOTAL_CHAINS], *tx_buff_virt[TOTAL_CHAINS];
-static dma_addr_t rx_buff_phys[TOTAL_CHAINS], tx_buff_phys[TOTAL_CHAINS];
-static struct tdmmc_mcdma_rx_desc *mcdma_rx_desc_ptr[TOTAL_CHAINS];
-static struct tdmmc_mcdma_tx_desc *mcdma_tx_desc_ptr[TOTAL_CHAINS];
-static dma_addr_t mcdma_rx_desc_phys[TOTAL_CHAINS], mcdma_tx_desc_phys[TOTAL_CHAINS];
+/* Globals */
 static struct tdmmc_dram_entry def_dpram_entry = { 0, 0, 0x1, 0x1, 0, 0, 0x1, 0, 0, 0, 0 };
-static enum tdmmc_ip_version ip_ver;
-static struct device *pdev;
-static void __iomem *regs;
+static struct tdmmc_dev *tdmmc;
 
 static void tdmmc_desc_chain_build(void)
 {
 	u32 chan, index, buff_size;
 
 	/* Calculate single Rx/Tx buffer size */
-	buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff);
+	buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES * tdmmc->sampling_coeff);
 
 	/* Initialize descriptors fields */
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		for (index = 0; index < TOTAL_CHAINS; index++) {
 			/* Associate data buffers to descriptors physBuffPtr */
-			((struct tdmmc_mcdma_rx_desc *) (mcdma_rx_desc_ptr[index] + chan))->phys_buff_ptr =
-			    (u32) (rx_buff_phys[index] + (chan * buff_size));
-			((struct tdmmc_mcdma_tx_desc *) (mcdma_tx_desc_ptr[index] + chan))->phys_buff_ptr =
-			    (u32) (tx_buff_phys[index] + (chan * buff_size));
+			((struct tdmmc_mcdma_rx_desc *) (tdmmc->rx_desc_virt[index] + chan))->phys_buff_ptr =
+			    (u32) (tdmmc->rx_buff_phys[index] + (chan * buff_size));
+			((struct tdmmc_mcdma_tx_desc *) (tdmmc->tx_desc_virt[index] + chan))->phys_buff_ptr =
+			    (u32) (tdmmc->tx_buff_phys[index] + (chan * buff_size));
 
 			/* Build cyclic descriptors chain for each channel */
-			((struct tdmmc_mcdma_rx_desc *) (mcdma_rx_desc_ptr[index] + chan))->phys_next_desc_ptr =
-			    (u32) (mcdma_rx_desc_phys[((index + 1) % TOTAL_CHAINS)] +
+			((struct tdmmc_mcdma_rx_desc *) (tdmmc->rx_desc_virt[index] + chan))->phys_next_desc_ptr =
+			    (u32) (tdmmc->rx_desc_phys[((index + 1) % TOTAL_CHAINS)] +
 				      (chan * sizeof(struct tdmmc_mcdma_rx_desc)));
 
-			((struct tdmmc_mcdma_tx_desc *) (mcdma_tx_desc_ptr[index] + chan))->phys_next_desc_ptr =
-			    (u32) (mcdma_tx_desc_phys[((index + 1) % TOTAL_CHAINS)] +
+			((struct tdmmc_mcdma_tx_desc *) (tdmmc->tx_desc_virt[index] + chan))->phys_next_desc_ptr =
+			    (u32) (tdmmc->tx_desc_phys[((index + 1) % TOTAL_CHAINS)] +
 				      (chan * sizeof(struct tdmmc_mcdma_tx_desc)));
 
 			/* Set Byte_Count/Buffer_Size Rx descriptor fields */
-			((struct tdmmc_mcdma_rx_desc *) (mcdma_rx_desc_ptr[index] + chan))->byte_cnt = 0;
-			((struct tdmmc_mcdma_rx_desc *) (mcdma_rx_desc_ptr[index] + chan))->buff_size = buff_size;
+			((struct tdmmc_mcdma_rx_desc *) (tdmmc->rx_desc_virt[index] + chan))->byte_cnt = 0;
+			((struct tdmmc_mcdma_rx_desc *) (tdmmc->rx_desc_virt[index] + chan))->buff_size = buff_size;
 
 			/* Set Shadow_Byte_Count/Byte_Count Tx descriptor fields */
-			((struct tdmmc_mcdma_tx_desc *) (mcdma_tx_desc_ptr[index] + chan))->shadow_byte_cnt = buff_size;
-			((struct tdmmc_mcdma_tx_desc *) (mcdma_tx_desc_ptr[index] + chan))->byte_cnt = buff_size;
+			((struct tdmmc_mcdma_tx_desc *) (tdmmc->tx_desc_virt[index] + chan))->shadow_byte_cnt =
+													 buff_size;
+			((struct tdmmc_mcdma_tx_desc *) (tdmmc->tx_desc_virt[index] + chan))->byte_cnt = buff_size;
 
 			/* Set Command/Status Rx/Tx descriptor fields */
-			((struct tdmmc_mcdma_rx_desc *) (mcdma_rx_desc_ptr[index] + chan))->cmd_status =
+			((struct tdmmc_mcdma_rx_desc *) (tdmmc->rx_desc_virt[index] + chan))->cmd_status =
 			    (CONFIG_MCDMA_DESC_CMD_STATUS);
-			((struct tdmmc_mcdma_tx_desc *) (mcdma_tx_desc_ptr[index] + chan))->cmd_status =
+			((struct tdmmc_mcdma_tx_desc *) (tdmmc->tx_desc_virt[index] + chan))->cmd_status =
 			    (CONFIG_MCDMA_DESC_CMD_STATUS);
 		}
 	}
@@ -163,60 +151,60 @@ static void tdmmc_mcdma_mcsc_start(void)
 	tdmmc_desc_chain_build();
 
 	/* Set current Rx/Tx descriptors  */
-	for (chan = 0; chan < total_channels; chan++) {
-		rx_desc_phys_addr = mcdma_rx_desc_phys[0] + (chan * sizeof(struct tdmmc_mcdma_rx_desc));
-		tx_desc_phys_addr = mcdma_tx_desc_phys[0] + (chan * sizeof(struct tdmmc_mcdma_tx_desc));
-		writel(rx_desc_phys_addr, regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(chan));
-		writel(tx_desc_phys_addr, regs + MCDMA_CURRENT_TRANSMIT_DESC_PTR_REG(chan));
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
+		rx_desc_phys_addr = tdmmc->rx_desc_phys[0] + (chan * sizeof(struct tdmmc_mcdma_rx_desc));
+		tx_desc_phys_addr = tdmmc->tx_desc_phys[0] + (chan * sizeof(struct tdmmc_mcdma_tx_desc));
+		writel(rx_desc_phys_addr, tdmmc->regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(chan));
+		writel(tx_desc_phys_addr, tdmmc->regs + MCDMA_CURRENT_TRANSMIT_DESC_PTR_REG(chan));
 	}
 
 	/* Restore MCDMA Rx/Tx control registers */
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		/* Set RMCCx */
-		writel(CONFIG_RMCCx, regs + MCDMA_RECEIVE_CONTROL_REG(chan));
+		writel(CONFIG_RMCCx, tdmmc->regs + MCDMA_RECEIVE_CONTROL_REG(chan));
 
 		/* Set TMCCx */
-		writel(CONFIG_TMCCx, regs + MCDMA_TRANSMIT_CONTROL_REG(chan));
+		writel(CONFIG_TMCCx, tdmmc->regs + MCDMA_TRANSMIT_CONTROL_REG(chan));
 	}
 
 	/* Set Rx/Tx periodical interrupts */
-	if (ip_ver == TDMMC_REV0)
+	if (tdmmc->ip_ver == TDMMC_REV0)
 		writel(CONFIG_VOICE_PERIODICAL_INT_CONTROL_WA,
-		       regs + VOICE_PERIODICAL_INT_CONTROL_REG);
+		       tdmmc->regs + VOICE_PERIODICAL_INT_CONTROL_REG);
 	else
 		writel(CONFIG_VOICE_PERIODICAL_INT_CONTROL,
-		       regs + VOICE_PERIODICAL_INT_CONTROL_REG);
+		       tdmmc->regs + VOICE_PERIODICAL_INT_CONTROL_REG);
 
 	/* MCSC Global Tx Enable */
-	if (!tdm_enable)
-		mv_phone_set_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TXEN_MASK);
+	if (!tdmmc->tdm_enable)
+		mv_phone_set_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TXEN_MASK);
 
 	/* Enable MCSC-Tx & MCDMA-Rx */
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		/* Enable Tx in TMCCx */
-		if (!tdm_enable)
-			mv_phone_set_bit(regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan), MTCRx_ET_MASK);
+		if (!tdmmc->tdm_enable)
+			mv_phone_set_bit(tdmmc->regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan), MTCRx_ET_MASK);
 
 		/* Enable Rx in: MCRDPx */
-		mv_phone_set_bit(regs + MCDMA_RECEIVE_CONTROL_REG(chan), MCDMA_ERD_MASK);
+		mv_phone_set_bit(tdmmc->regs + MCDMA_RECEIVE_CONTROL_REG(chan), MCDMA_ERD_MASK);
 	}
 
 	/* MCSC Global Rx Enable */
-	if (!tdm_enable)
-		mv_phone_set_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_RXEN_MASK);
+	if (!tdmmc->tdm_enable)
+		mv_phone_set_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_RXEN_MASK);
 
 	/* Enable MCSC-Rx & MCDMA-Tx */
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		/* Enable Rx in RMCCx */
-		if (!tdm_enable)
-			mv_phone_set_bit(regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan), MRCRx_ER_MASK);
+		if (!tdmmc->tdm_enable)
+			mv_phone_set_bit(tdmmc->regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan), MRCRx_ER_MASK);
 
 		/* Enable Tx in MCTDPx */
-		mv_phone_set_bit(regs + MCDMA_TRANSMIT_CONTROL_REG(chan), MCDMA_TXD_MASK);
+		mv_phone_set_bit(tdmmc->regs + MCDMA_TRANSMIT_CONTROL_REG(chan), MCDMA_TXD_MASK);
 	}
 
 	/* Disable Rx/Tx return to half */
-	mv_phone_reset_bit(regs + FLEX_TDM_CONFIG_REG, (TDM_RR2HALF_MASK | TDM_TR2HALF_MASK));
+	mv_phone_reset_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, (TDM_RR2HALF_MASK | TDM_TR2HALF_MASK));
 	/* Wait at least 1 frame */
 	udelay(200);
 }
@@ -226,16 +214,16 @@ static void tdmmc_mcdma_mcsc_abort(void)
 	u32 chan;
 
 	/* Abort MCSC/MCDMA in case we got here from tdmmc_release() */
-	if (!tdm_enable) {
+	if (!tdmmc->tdm_enable) {
 		/* Clear MCSC Rx/Tx channel enable */
-		for (chan = 0; chan < total_channels; chan++) {
-			mv_phone_reset_bit(regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan), MRCRx_ER_MASK);
-			mv_phone_reset_bit(regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan), MTCRx_ET_MASK);
+		for (chan = 0; chan < tdmmc->total_channels; chan++) {
+			mv_phone_reset_bit(tdmmc->regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan), MRCRx_ER_MASK);
+			mv_phone_reset_bit(tdmmc->regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan), MTCRx_ET_MASK);
 		}
 
 		/* MCSC Global Rx/Tx Disable */
-		mv_phone_reset_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_RXEN_MASK);
-		mv_phone_reset_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TXEN_MASK);
+		mv_phone_reset_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_RXEN_MASK);
+		mv_phone_reset_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TXEN_MASK);
 	}
 }
 
@@ -247,84 +235,86 @@ static void tdmmc_mcdma_stop(void)
 	/***************************/
 	/*    Stop MCDMA - Rx/Tx   */
 	/***************************/
-	for (chan = 0; chan < total_channels; chan++) {
-		curr_rx_desc = readl(regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(chan));
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
+		curr_rx_desc = readl(tdmmc->regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(chan));
 		for (index = 0; index < TOTAL_CHAINS; index++) {
-			if (curr_rx_desc == (mcdma_rx_desc_phys[index] + (chan*(sizeof(struct tdmmc_mcdma_rx_desc))))) {
+			if (curr_rx_desc == (tdmmc->rx_desc_phys[index] +
+			    (chan * (sizeof(struct tdmmc_mcdma_rx_desc))))) {
 				next_rx_buff = NEXT_BUFF(index);
 				break;
 			}
 		}
 
 		if (index == TOTAL_CHAINS) {
-			dev_err(pdev, "%s: ERROR, couldn't Rx descriptor match for chan(%d)\n",
+			dev_err(tdmmc->dev, "%s: ERROR, couldn't Rx descriptor match for chan(%d)\n",
 				__func__, chan);
 			break;
 		}
 
 		((struct tdmmc_mcdma_rx_desc *)
-			(mcdma_rx_desc_ptr[next_rx_buff] + chan))->phys_next_desc_ptr = 0;
+			(tdmmc->rx_desc_virt[next_rx_buff] + chan))->phys_next_desc_ptr = 0;
 		((struct tdmmc_mcdma_rx_desc *)
-			(mcdma_rx_desc_ptr[next_rx_buff] + chan))->cmd_status = (LAST_BIT | OWNER);
+			(tdmmc->rx_desc_virt[next_rx_buff] + chan))->cmd_status = (LAST_BIT | OWNER);
 	}
 
-	for (chan = 0; chan < total_channels; chan++) {
-		curr_tx_desc = readl(regs + MCDMA_CURRENT_TRANSMIT_DESC_PTR_REG(chan));
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
+		curr_tx_desc = readl(tdmmc->regs + MCDMA_CURRENT_TRANSMIT_DESC_PTR_REG(chan));
 		for (index = 0; index < TOTAL_CHAINS; index++) {
-			if (curr_tx_desc == (mcdma_tx_desc_phys[index] + (chan*(sizeof(struct tdmmc_mcdma_tx_desc))))) {
+			if (curr_tx_desc == (tdmmc->tx_desc_phys[index] +
+			    (chan * (sizeof(struct tdmmc_mcdma_tx_desc))))) {
 				next_tx_buff = NEXT_BUFF(index);
 				break;
 			}
 		}
 
 		if (index == TOTAL_CHAINS) {
-			dev_err(pdev, "%s: ERROR, couldn't Tx descriptor match for chan(%d)\n",
+			dev_err(tdmmc->dev, "%s: ERROR, couldn't Tx descriptor match for chan(%d)\n",
 				__func__, chan);
 			return;
 		}
 
 		((struct tdmmc_mcdma_tx_desc *)
-			(mcdma_tx_desc_ptr[next_tx_buff] + chan))->phys_next_desc_ptr = 0;
+			(tdmmc->tx_desc_virt[next_tx_buff] + chan))->phys_next_desc_ptr = 0;
 		((struct tdmmc_mcdma_tx_desc *)
-			(mcdma_tx_desc_ptr[next_tx_buff] + chan))->cmd_status = (LAST_BIT | OWNER);
+			(tdmmc->tx_desc_virt[next_tx_buff] + chan))->cmd_status = (LAST_BIT | OWNER);
 	}
 
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		max_poll = 0;
 		while ((max_poll < MAX_POLL_USEC) &&
-			(readl(regs + MCDMA_TRANSMIT_CONTROL_REG(chan)) & MCDMA_TXD_MASK)) {
+			(readl(tdmmc->regs + MCDMA_TRANSMIT_CONTROL_REG(chan)) & MCDMA_TXD_MASK)) {
 			udelay(1);
 			max_poll++;
 		}
 
 		if (max_poll >= MAX_POLL_USEC) {
-			dev_err(pdev, "%s: Error, MCDMA TXD polling timeout(ch%d)\n", __func__, chan);
+			dev_err(tdmmc->dev, "%s: Error, MCDMA TXD polling timeout(ch%d)\n", __func__, chan);
 			return;
 		}
 
 		max_poll = 0;
 		while ((max_poll < MAX_POLL_USEC) &&
-			(readl(regs + MCDMA_RECEIVE_CONTROL_REG(chan)) & MCDMA_ERD_MASK)) {
+			(readl(tdmmc->regs + MCDMA_RECEIVE_CONTROL_REG(chan)) & MCDMA_ERD_MASK)) {
 			udelay(1);
 			max_poll++;
 		}
 
 		if (max_poll >= MAX_POLL_USEC) {
-			dev_err(pdev, "%s: Error, MCDMA ERD polling timeout(ch%d)\n", __func__, chan);
+			dev_err(tdmmc->dev, "%s: Error, MCDMA ERD polling timeout(ch%d)\n", __func__, chan);
 			return;
 		}
 	}
 
 	/* Disable Rx/Tx periodical interrupts */
-	writel(0xffffffff, regs + VOICE_PERIODICAL_INT_CONTROL_REG);
+	writel(0xffffffff, tdmmc->regs + VOICE_PERIODICAL_INT_CONTROL_REG);
 
 	/* Enable Rx/Tx return to half */
-	mv_phone_set_bit(regs + FLEX_TDM_CONFIG_REG, (TDM_RR2HALF_MASK | TDM_TR2HALF_MASK));
+	mv_phone_set_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, (TDM_RR2HALF_MASK | TDM_TR2HALF_MASK));
 	/* Wait at least 1 frame */
 	udelay(200);
 
 	/* Manual reset to channel-balancing mechanism */
-	mv_phone_set_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_MAI_MASK);
+	mv_phone_set_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_MAI_MASK);
 	udelay(1);
 }
 
@@ -342,18 +332,18 @@ void tdmmc_show(void)
 
 	/* Dump data buffers & descriptors addresses */
 	for (index = 0; index < TOTAL_CHAINS; index++) {
-		dev_dbg(pdev, "Rx Buff(%d): virt = 0x%lx, phys = 0x%lx\n",
-			index, (ulong)rx_buff_virt[index],
-			(ulong)rx_buff_phys[index]);
-		dev_dbg(pdev, "Tx Buff(%d): virt = 0x%lx, phys = 0x%lx\n",
-			index, (ulong)tx_buff_virt[index],
-			(ulong)tx_buff_phys[index]);
-		dev_dbg(pdev, "Rx Desc(%d): virt = 0x%lx, phys = 0x%lx\n",
-			index, (ulong)mcdma_rx_desc_ptr[index],
-			(ulong) mcdma_rx_desc_phys[index]);
-		dev_dbg(pdev, "Tx Desc(%d): virt = 0x%lx, phys = 0x%lx\n",
-			index, (ulong)mcdma_tx_desc_ptr[index],
-			(ulong)mcdma_tx_desc_phys[index]);
+		dev_dbg(tdmmc->dev, "Rx Buff(%d): virt = 0x%lx, phys = 0x%lx\n",
+			index, (ulong)tdmmc->rx_buff_virt[index],
+			(ulong)tdmmc->rx_buff_phys[index]);
+		dev_dbg(tdmmc->dev, "Tx Buff(%d): virt = 0x%lx, phys = 0x%lx\n",
+			index, (ulong)tdmmc->tx_buff_virt[index],
+			(ulong)tdmmc->tx_buff_phys[index]);
+		dev_dbg(tdmmc->dev, "Rx Desc(%d): virt = 0x%lx, phys = 0x%lx\n",
+			index, (ulong)tdmmc->rx_desc_virt[index],
+			(ulong) tdmmc->rx_desc_phys[index]);
+		dev_dbg(tdmmc->dev, "Tx Desc(%d): virt = 0x%lx, phys = 0x%lx\n",
+			index, (ulong)tdmmc->tx_desc_virt[index],
+			(ulong)tdmmc->tx_desc_phys[index]);
 	}
 }
 
@@ -367,68 +357,77 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	struct tdmmc_dram_entry *act_dpram_entry;
 	int ret;
 
-	regs = base;
-	/* Initialize driver resources */
-	tdm_enable = 0;
-	pcm_enable = 0;
-	total_channels = tdm_params->total_channels;
-	prev_rx_buff = 0;
-	next_tx_buff = 0;
-	ip_ver = tdmmc_ip_ver;
-	pdev = dev;
+	/* Initialize or reset main structure */
+	if (!tdmmc) {
+		tdmmc = devm_kzalloc(dev, sizeof(struct tdmmc_dev), GFP_KERNEL);
+		if (!tdmmc)
+			return -ENOMEM;
+	} else {
+		memset(tdmmc, 0,  sizeof(struct tdmmc_dev));
+	}
+
+	/* Initialize remaining parameters */
+	tdmmc->regs = base;
+	tdmmc->tdm_enable = false;
+	tdmmc->pcm_enable = false;
+	tdmmc->total_channels = tdm_params->total_channels;
+	tdmmc->prev_rx = 0;
+	tdmmc->next_tx = 0;
+	tdmmc->ip_ver = tdmmc_ip_ver;
+	tdmmc->dev = dev;
 
 	/* Check parameters */
 	if ((tdm_params->total_channels > MV_TDMMC_TOTAL_CHANNELS) ||
 	    (tdm_params->sampling_period > MV_TDM_MAX_SAMPLING_PERIOD)) {
-		dev_err(pdev, "%s: Error, bad parameters\n", __func__);
+		dev_err(tdmmc->dev, "%s: Error, bad parameters\n", __func__);
 		return -EINVAL;
 	}
 
 	/* Extract sampling period coefficient */
-	sampling_coeff = (tdm_params->sampling_period / MV_TDM_BASE_SAMPLING_PERIOD);
+	tdmmc->sampling_coeff = (tdm_params->sampling_period / MV_TDM_BASE_SAMPLING_PERIOD);
 
-	sample_size = tdm_params->pcm_format;
+	tdmmc->sample_size = tdm_params->pcm_format;
 
 	/* Calculate single Rx/Tx buffer size */
-	buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff);
+	buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES * tdmmc->sampling_coeff);
 
 	/* Allocate non-cached data buffers for all channels */
-	dev_dbg(pdev, "%s: allocate 0x%x for data buffers total_channels = %d\n",
-		__func__, (buff_size * total_channels), total_channels);
+	dev_dbg(tdmmc->dev, "%s: allocate 0x%x for data buffers total channels = %d\n",
+		__func__, (buff_size * tdmmc->total_channels), tdmmc->total_channels);
 
 	for (index = 0; index < TOTAL_CHAINS; index++) {
-		rx_buff_virt[index] = dma_alloc_coherent(pdev, buff_size * total_channels,
-						       &rx_buff_phys[index], GFP_KERNEL);
-		tx_buff_virt[index] = dma_alloc_coherent(pdev, buff_size * total_channels,
-						       &tx_buff_phys[index], GFP_KERNEL);
+		tdmmc->rx_buff_virt[index] = dma_alloc_coherent(tdmmc->dev, buff_size * tdmmc->total_channels,
+						       &tdmmc->rx_buff_phys[index], GFP_KERNEL);
+		tdmmc->tx_buff_virt[index] = dma_alloc_coherent(tdmmc->dev, buff_size * tdmmc->total_channels,
+						       &tdmmc->tx_buff_phys[index], GFP_KERNEL);
 
-		if (!rx_buff_virt[index] || !tx_buff_virt[index]) {
+		if (!tdmmc->rx_buff_virt[index] || !tdmmc->tx_buff_virt[index]) {
 			ret = -ENOMEM;
 			goto err_buff_virt;
 		}
 	}
 
 	/* Allocate non-cached MCDMA Rx/Tx descriptors */
-	total_rx_desc_size = total_channels * sizeof(struct tdmmc_mcdma_rx_desc);
-	total_tx_desc_size = total_channels * sizeof(struct tdmmc_mcdma_tx_desc);
+	total_rx_desc_size = tdmmc->total_channels * sizeof(struct tdmmc_mcdma_rx_desc);
+	total_tx_desc_size = tdmmc->total_channels * sizeof(struct tdmmc_mcdma_tx_desc);
 
 	dev_dbg(dev, "%s: allocate %dB for Rx/Tx descriptors\n",
 		__func__, total_tx_desc_size);
 	for (index = 0; index < TOTAL_CHAINS; index++) {
-		mcdma_rx_desc_ptr[index] = dma_alloc_coherent(pdev, total_rx_desc_size,
-							   &mcdma_rx_desc_phys[index], GFP_KERNEL);
-		mcdma_tx_desc_ptr[index] = dma_alloc_coherent(pdev, total_tx_desc_size,
-							   &mcdma_tx_desc_phys[index], GFP_KERNEL);
+		tdmmc->rx_desc_virt[index] = dma_alloc_coherent(tdmmc->dev, total_rx_desc_size,
+							   &tdmmc->rx_desc_phys[index], GFP_KERNEL);
+		tdmmc->tx_desc_virt[index] = dma_alloc_coherent(tdmmc->dev, total_tx_desc_size,
+							   &tdmmc->tx_desc_phys[index], GFP_KERNEL);
 
-		if (!mcdma_rx_desc_ptr[index] || !mcdma_tx_desc_ptr[index]) {
+		if (!tdmmc->rx_desc_virt[index] || !tdmmc->tx_desc_virt[index]) {
 			ret = -ENOMEM;
 			goto err_mcdma_desc;
 		}
 
 		/* Check descriptors alignment */
-		if (((ulong) mcdma_rx_desc_ptr[index] | (ulong)mcdma_tx_desc_ptr[index]) &
+		if (((ulong) tdmmc->rx_desc_virt[index] | (ulong)tdmmc->tx_desc_virt[index]) &
 		    (sizeof(struct tdmmc_mcdma_rx_desc) - 1)) {
-			dev_err(pdev, "%s: Error, unaligned MCDMA Rx/Tx descriptors\n", __func__);
+			dev_err(tdmmc->dev, "%s: Error, unaligned MCDMA Rx/Tx descriptors\n", __func__);
 			ret = -ENOMEM;
 			goto err_mcdma_desc;
 		}
@@ -436,28 +435,28 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 
 	/* Poll MCDMA for reset completion */
 	max_poll = 0;
-	while ((max_poll < MAX_POLL_USEC) && !(readl(regs + MCDMA_GLOBAL_CONTROL_REG) & MCDMA_RID_MASK)) {
+	while ((max_poll < MAX_POLL_USEC) && !(readl(tdmmc->regs + MCDMA_GLOBAL_CONTROL_REG) & MCDMA_RID_MASK)) {
 		udelay(1);
 		max_poll++;
 	}
 
 	if (max_poll >= MAX_POLL_USEC) {
-		dev_err(pdev, "Error, MCDMA reset completion timout\n");
+		dev_err(tdmmc->dev, "Error, MCDMA reset completion timout\n");
 		ret = -ETIME;
 		goto err_mcdma_desc;
 	}
 
 	/* Poll MCSC for RAM initialization done */
-	if (!(readl(regs + MCSC_GLOBAL_INT_CAUSE_REG) & MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK)) {
+	if (!(readl(tdmmc->regs + MCSC_GLOBAL_INT_CAUSE_REG) & MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK)) {
 		max_poll = 0;
 		while ((max_poll < MAX_POLL_USEC) &&
-		       !(readl(regs + MCSC_GLOBAL_INT_CAUSE_REG) & MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK)) {
+		       !(readl(tdmmc->regs + MCSC_GLOBAL_INT_CAUSE_REG) & MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK)) {
 			udelay(1);
 			max_poll++;
 		}
 
 		if (max_poll >= MAX_POLL_USEC) {
-			dev_err(pdev, "Error, MCDMA RAM initialization timout\n");
+			dev_err(tdmmc->dev, "Error, MCDMA RAM initialization timout\n");
 			ret = -ETIME;
 			goto err_mcdma_desc;
 		}
@@ -467,45 +466,46 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	/* MCDMA Configuration(use default MCDMA linked-list settings) */
 	/***************************************************************/
 	/* Set Rx Service Queue Arbiter Weight Register */
-	writel((readl(regs + RX_SERVICE_QUEUE_ARBITER_WEIGHT_REG) & ~(0x1f << 24)), /*| MCDMA_RSQW_MASK));*/
-	       regs + RX_SERVICE_QUEUE_ARBITER_WEIGHT_REG);
+	writel((readl(tdmmc->regs + RX_SERVICE_QUEUE_ARBITER_WEIGHT_REG) & ~(0x1f << 24)),
+	       tdmmc->regs + RX_SERVICE_QUEUE_ARBITER_WEIGHT_REG);
 
 	/* Set Tx Service Queue Arbiter Weight Register */
-	writel((readl(regs + TX_SERVICE_QUEUE_ARBITER_WEIGHT_REG) & ~(0x1f << 24)), /*| MCDMA_TSQW_MASK));*/
-	       regs + TX_SERVICE_QUEUE_ARBITER_WEIGHT_REG);
+	writel((readl(tdmmc->regs + TX_SERVICE_QUEUE_ARBITER_WEIGHT_REG) & ~(0x1f << 24)),
+	       tdmmc->regs + TX_SERVICE_QUEUE_ARBITER_WEIGHT_REG);
 
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		/* Set RMCCx */
-		writel(CONFIG_RMCCx, regs + MCDMA_RECEIVE_CONTROL_REG(chan));
+		writel(CONFIG_RMCCx, tdmmc->regs + MCDMA_RECEIVE_CONTROL_REG(chan));
 
 		/* Set TMCCx */
-		writel(CONFIG_TMCCx, regs + MCDMA_TRANSMIT_CONTROL_REG(chan));
+		writel(CONFIG_TMCCx, tdmmc->regs + MCDMA_TRANSMIT_CONTROL_REG(chan));
 	}
 
 	/**********************/
 	/* MCSC Configuration */
 	/**********************/
 	/* Disable Rx/Tx channel balancing & Linear mode fix */
-	mv_phone_set_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TCBD_MASK);
+	mv_phone_set_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_TCBD_MASK);
 
-	for (chan = 0; chan < total_channels; chan++) {
-		writel(CONFIG_MRCRx, regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan));
-		writel(CONFIG_MTCRx, regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan));
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
+		writel(CONFIG_MRCRx, tdmmc->regs + MCSC_CHx_RECEIVE_CONFIG_REG(chan));
+		writel(CONFIG_MTCRx, tdmmc->regs + MCSC_CHx_TRANSMIT_CONFIG_REG(chan));
 	}
 
 	/* Enable RX/TX linear byte swap, only in linear mode */
 	if (tdm_params->pcm_format == MV_PCM_FORMAT_1BYTE)
-		writel((readl(regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG) & (~CONFIG_LINEAR_BYTE_SWAP)),
-		       regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG);
+		writel((readl(tdmmc->regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG) & (~CONFIG_LINEAR_BYTE_SWAP)),
+		       tdmmc->regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG);
 	else
-		writel((readl(regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG) | CONFIG_LINEAR_BYTE_SWAP),
-		       regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG);
+		writel((readl(tdmmc->regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG) | CONFIG_LINEAR_BYTE_SWAP),
+		       tdmmc->regs + MCSC_GLOBAL_CONFIG_EXTENDED_REG);
 
 	/***********************************************/
 	/* Shared Bus to Crossbar Bridge Configuration */
 	/***********************************************/
 	/* Set Timeout Counter Register */
-	writel((readl(regs + TIME_OUT_COUNTER_REG) | TIME_OUT_THRESHOLD_COUNT_MASK), regs + TIME_OUT_COUNTER_REG);
+	writel((readl(tdmmc->regs + TIME_OUT_COUNTER_REG) | TIME_OUT_THRESHOLD_COUNT_MASK),
+	       tdmmc->regs + TIME_OUT_COUNTER_REG);
 
 	/*************************************************/
 	/* Time Division Multiplexing(TDM) Configuration */
@@ -517,31 +517,31 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	}
 
 	memcpy(act_dpram_entry, &def_dpram_entry, sizeof(struct tdmmc_dram_entry));
-	/* Set repeat mode bits for (sample_size > 1) */
-	act_dpram_entry->rpt = ((sample_size == MV_PCM_FORMAT_1BYTE) ? 0 : 1);
+	/* Set repeat mode bits for (tdmmc->sample_size > 1) */
+	act_dpram_entry->rpt = ((tdmmc->sample_size == MV_PCM_FORMAT_1BYTE) ? 0 : 1);
 
 	/* Reset all Rx/Tx DPRAM entries to default value */
 	for (index = 0; index < (2 * MV_TDM_MAX_HALF_DPRAM_ENTRIES); index++) {
-		writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_RDPR_REG(index));
-		writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_TDPR_REG(index));
+		writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_RDPR_REG(index));
+		writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_TDPR_REG(index));
 	}
 
 	/* Set active Rx/Tx DPRAM entries */
-	for (chan = 0; chan < total_channels; chan++) {
+	for (chan = 0; chan < tdmmc->total_channels; chan++) {
 		/* Same time slot number for both Rx & Tx */
 		pcm_slot = tdm_params->pcm_slot[chan];
 
 		/* Verify time slot is within frame boundries */
 		if (pcm_slot >= frame_ts) {
-			dev_err(pdev, "Error, time slot(%d) exceeded maximum(%d)\n",
+			dev_err(tdmmc->dev, "Error, time slot(%d) exceeded maximum(%d)\n",
 				pcm_slot, frame_ts);
 			ret = -ETIME;
 			goto err_dpram;
 		}
 
 		/* Verify time slot is aligned to sample size */
-		if ((sample_size > MV_PCM_FORMAT_1BYTE) && (pcm_slot & 1)) {
-			dev_err(pdev, "Error, time slot(%d) not aligned to Linear PCM sample size\n",
+		if ((tdmmc->sample_size > MV_PCM_FORMAT_1BYTE) && (pcm_slot & 1)) {
+			dev_err(tdmmc->dev, "Error, time slot(%d) not aligned to Linear PCM sample size\n",
 				pcm_slot);
 			ret = -EINVAL;
 			goto err_dpram;
@@ -552,33 +552,33 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 		act_dpram_entry->mask = 0xff;
 
 		/* Extract physical DPRAM entry id */
-		index = ((sample_size == MV_PCM_FORMAT_1BYTE) ? pcm_slot : (pcm_slot / 2));
+		index = ((tdmmc->sample_size == MV_PCM_FORMAT_1BYTE) ? pcm_slot : (pcm_slot / 2));
 
 		/* DPRAM low half */
-		writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_RDPR_REG(index));
-		writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_TDPR_REG(index));
+		writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_RDPR_REG(index));
+		writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_TDPR_REG(index));
 
 		/* DPRAM high half(mirroring DPRAM low half) */
 		act_dpram_entry->mask = 0;
 		writel(*((u32 *) act_dpram_entry),
-		       regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+		       tdmmc->regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
 		writel(*((u32 *) act_dpram_entry),
-		       regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+		       tdmmc->regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
 
 		/* WideBand mode */
-		if (sample_size == MV_PCM_FORMAT_4BYTES) {
-			index = (index + (frame_ts / sample_size));
+		if (tdmmc->sample_size == MV_PCM_FORMAT_4BYTES) {
+			index = (index + (frame_ts / tdmmc->sample_size));
 			/* DPRAM low half */
 			act_dpram_entry->mask = 0xff;
-			writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_RDPR_REG(index));
-			writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_TDPR_REG(index));
+			writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_RDPR_REG(index));
+			writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_TDPR_REG(index));
 
 			/* DPRAM high half(mirroring DPRAM low half) */
 			act_dpram_entry->mask = 0;
 			writel(*((u32 *) act_dpram_entry),
-			       regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+			       tdmmc->regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
 			writel(*((u32 *) act_dpram_entry),
-			       regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+			       tdmmc->regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
 		}
 	}
 
@@ -588,47 +588,50 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	act_dpram_entry->last = 1;
 
 	/* Index for last entry */
-	if (sample_size == MV_PCM_FORMAT_1BYTE)
+	if (tdmmc->sample_size == MV_PCM_FORMAT_1BYTE)
 		index = (frame_ts - 1);
 	else
 		index = ((frame_ts / 2) - 1);
 
 	/* Low half */
-	writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_TDPR_REG(index));
-	writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_RDPR_REG(index));
+	writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_TDPR_REG(index));
+	writel(*((u32 *) act_dpram_entry), tdmmc->regs + FLEX_TDM_RDPR_REG(index));
 	/* High half */
-	writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
-	writel(*((u32 *) act_dpram_entry), regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+	writel(*((u32 *) act_dpram_entry),
+	       tdmmc->regs + FLEX_TDM_TDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
+	writel(*((u32 *) act_dpram_entry),
+	       tdmmc->regs + FLEX_TDM_RDPR_REG((MV_TDM_MAX_HALF_DPRAM_ENTRIES + index)));
 
 	/* Set TDM_CLK_AND_SYNC_CONTROL register */
-	clk_sync_ctrl_reg = readl(regs + TDM_CLK_AND_SYNC_CONTROL_REG);
+	clk_sync_ctrl_reg = readl(tdmmc->regs + TDM_CLK_AND_SYNC_CONTROL_REG);
 	clk_sync_ctrl_reg &= ~(TDM_TX_FSYNC_OUT_ENABLE_MASK | TDM_RX_FSYNC_OUT_ENABLE_MASK |
 			TDM_TX_CLK_OUT_ENABLE_MASK | TDM_RX_CLK_OUT_ENABLE_MASK);
 	clk_sync_ctrl_reg |= CONFIG_TDM_CLK_AND_SYNC_CONTROL;
-	writel(clk_sync_ctrl_reg, regs + TDM_CLK_AND_SYNC_CONTROL_REG);
+	writel(clk_sync_ctrl_reg, tdmmc->regs + TDM_CLK_AND_SYNC_CONTROL_REG);
 
 	/* Set TDM TCR register */
-	writel((readl(regs + FLEX_TDM_CONFIG_REG) | CONFIG_FLEX_TDM_CONFIG), regs + FLEX_TDM_CONFIG_REG);
+	writel((readl(tdmmc->regs + FLEX_TDM_CONFIG_REG) | CONFIG_FLEX_TDM_CONFIG),
+	       tdmmc->regs + FLEX_TDM_CONFIG_REG);
 
 	/**********************************************************************/
 	/* Time Division Multiplexing(TDM) Interrupt Controller Configuration */
 	/**********************************************************************/
 	/* Clear TDM cause and mask registers */
-	writel(0, regs + COMM_UNIT_TOP_MASK_REG);
-	writel(0, regs + TDM_MASK_REG);
-	writel(0, regs + COMM_UNIT_TOP_CAUSE_REG);
-	writel(0, regs + TDM_CAUSE_REG);
+	writel(0, tdmmc->regs + COMM_UNIT_TOP_MASK_REG);
+	writel(0, tdmmc->regs + TDM_MASK_REG);
+	writel(0, tdmmc->regs + COMM_UNIT_TOP_CAUSE_REG);
+	writel(0, tdmmc->regs + TDM_CAUSE_REG);
 
 	/* Clear MCSC cause and mask registers(except InitDone bit) */
-	writel(0, regs + MCSC_GLOBAL_INT_MASK_REG);
-	writel(0, regs + MCSC_EXTENDED_INT_MASK_REG);
-	writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, regs + MCSC_GLOBAL_INT_CAUSE_REG);
-	writel(0, regs + MCSC_EXTENDED_INT_CAUSE_REG);
+	writel(0, tdmmc->regs + MCSC_GLOBAL_INT_MASK_REG);
+	writel(0, tdmmc->regs + MCSC_EXTENDED_INT_MASK_REG);
+	writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, tdmmc->regs + MCSC_GLOBAL_INT_CAUSE_REG);
+	writel(0, tdmmc->regs + MCSC_EXTENDED_INT_CAUSE_REG);
 
 	/* Set output sync counter bits for FS */
 	count = frame_ts * 8;
 	writel(((count << TDM_SYNC_BIT_RX_OFFS) & TDM_SYNC_BIT_RX_MASK) | (count & TDM_SYNC_BIT_TX_MASK),
-	       regs + TDM_OUTPUT_SYNC_BIT_COUNT_REG);
+	       tdmmc->regs + TDM_OUTPUT_SYNC_BIT_COUNT_REG);
 
 	tdmmc_show();
 
@@ -636,18 +639,18 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	tdmmc_pcm_start();
 
 	/* Mark TDM I/F as enabled */
-	tdm_enable = 1;
+	tdmmc->tdm_enable = true;
 
 	/* Enable PCLK */
-	writel((readl(regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG) | CONFIG_TDM_DATA_DELAY_AND_CLK_CTRL),
-	       regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG);
+	writel((readl(tdmmc->regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG) | CONFIG_TDM_DATA_DELAY_AND_CLK_CTRL),
+	       tdmmc->regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG);
 
 	/* Keep the software workaround to enable TEN while set Fsync for none-ALP chips */
 	/* Enable TDM */
-	if (ip_ver == TDMMC_REV0)
-		mv_phone_set_bit(regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
+	if (tdmmc->ip_ver == TDMMC_REV0)
+		mv_phone_set_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
 
-	dev_dbg(pdev, "%s: Exit\n", __func__);
+	dev_dbg(tdmmc->dev, "%s: Exit\n", __func__);
 
 	kfree(act_dpram_entry);
 	return 0;
@@ -656,21 +659,21 @@ int tdmmc_init(void __iomem *base, struct device *dev,
 	kfree(act_dpram_entry);
 err_mcdma_desc:
 	for (index = 0; index < TOTAL_CHAINS; index++) {
-		if (mcdma_rx_desc_ptr[index])
-			dma_free_coherent(pdev, total_rx_desc_size,
-					  mcdma_rx_desc_ptr[index], mcdma_rx_desc_phys[index]);
-		if (mcdma_tx_desc_ptr[index])
-			dma_free_coherent(pdev, total_tx_desc_size,
-					  mcdma_tx_desc_ptr[index], mcdma_tx_desc_phys[index]);
+		if (tdmmc->rx_desc_virt[index])
+			dma_free_coherent(tdmmc->dev, total_rx_desc_size,
+					  tdmmc->rx_desc_virt[index], tdmmc->rx_desc_phys[index]);
+		if (tdmmc->tx_desc_virt[index])
+			dma_free_coherent(tdmmc->dev, total_tx_desc_size,
+					  tdmmc->tx_desc_virt[index], tdmmc->tx_desc_phys[index]);
 	}
 err_buff_virt:
 	for (index = 0; index < TOTAL_CHAINS; index++) {
-		if (rx_buff_phys[index])
-			dma_free_coherent(pdev, buff_size, rx_buff_virt[index],
-					  rx_buff_phys[index]);
-		if (tx_buff_phys[index])
-			dma_free_coherent(pdev, buff_size, tx_buff_virt[index],
-					  tx_buff_phys[index]);
+		if (tdmmc->rx_buff_phys[index])
+			dma_free_coherent(tdmmc->dev, buff_size, tdmmc->rx_buff_virt[index],
+					  tdmmc->rx_buff_phys[index]);
+		if (tdmmc->tx_buff_phys[index])
+			dma_free_coherent(tdmmc->dev, buff_size, tdmmc->tx_buff_virt[index],
+					  tdmmc->tx_buff_phys[index]);
 	}
 
 	return ret;
@@ -680,46 +683,47 @@ void tdmmc_release(void)
 {
 	u32 buff_size, total_rx_desc_size, total_tx_desc_size, index;
 
-	if (tdm_enable) {
+	if (tdmmc->tdm_enable) {
 
 		/* Mark TDM I/F as disabled */
-		tdm_enable = 0;
+		tdmmc->tdm_enable = false;
 
 		tdmmc_pcm_stop();
 
 		tdmmc_mcdma_mcsc_abort();
 
 		udelay(10);
-		mv_phone_reset_bit(regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_MAI_MASK);
+		mv_phone_reset_bit(tdmmc->regs + MCSC_GLOBAL_CONFIG_REG, MCSC_GLOBAL_CONFIG_MAI_MASK);
 
 		/* Disable TDM */
-		if (ip_ver == TDMMC_REV0)
-			mv_phone_reset_bit(regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
+		if (tdmmc->ip_ver == TDMMC_REV0)
+			mv_phone_reset_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
 
 		/* Disable PCLK */
-		mv_phone_reset_bit(regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG,
+		mv_phone_reset_bit(tdmmc->regs + TDM_DATA_DELAY_AND_CLK_CTRL_REG,
 				   (TX_CLK_OUT_ENABLE_MASK |
 				    RX_CLK_OUT_ENABLE_MASK));
 
 		/* Calculate total Rx/Tx buffer size */
-		buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff * total_channels);
+		buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES *
+			     tdmmc->sampling_coeff * tdmmc->total_channels);
 
 		/* Calculate total MCDMA Rx/Tx descriptors chain size */
-		total_rx_desc_size = total_channels * sizeof(struct tdmmc_mcdma_rx_desc);
-		total_tx_desc_size = total_channels * sizeof(struct tdmmc_mcdma_tx_desc);
+		total_rx_desc_size = tdmmc->total_channels * sizeof(struct tdmmc_mcdma_rx_desc);
+		total_tx_desc_size = tdmmc->total_channels * sizeof(struct tdmmc_mcdma_tx_desc);
 
 		for (index = 0; index < TOTAL_CHAINS; index++) {
 			/* Release Rx/Tx data buffers */
-			dma_free_coherent(pdev, buff_size, rx_buff_virt[index],
-					  rx_buff_phys[index]);
-			dma_free_coherent(pdev, buff_size, tx_buff_virt[index],
-					  tx_buff_phys[index]);
+			dma_free_coherent(tdmmc->dev, buff_size, tdmmc->rx_buff_virt[index],
+					  tdmmc->rx_buff_phys[index]);
+			dma_free_coherent(tdmmc->dev, buff_size, tdmmc->tx_buff_virt[index],
+					  tdmmc->tx_buff_phys[index]);
 
 			/* Release MCDMA Rx/Tx descriptors */
-			dma_free_coherent(pdev, total_rx_desc_size,
-					  mcdma_rx_desc_ptr[index], mcdma_rx_desc_phys[index]);
-			dma_free_coherent(pdev, total_tx_desc_size,
-					  mcdma_tx_desc_ptr[index], mcdma_tx_desc_phys[index]);
+			dma_free_coherent(tdmmc->dev, total_rx_desc_size,
+					  tdmmc->rx_desc_virt[index], tdmmc->rx_desc_phys[index]);
+			dma_free_coherent(tdmmc->dev, total_tx_desc_size,
+					  tdmmc->tx_desc_virt[index], tdmmc->tx_desc_phys[index]);
 		}
 	}
 }
@@ -728,33 +732,33 @@ void tdmmc_pcm_start(void)
 {
 	u32 mask_reg;
 
-	if (!pcm_enable) {
+	if (!tdmmc->pcm_enable) {
 
 		/* Mark PCM I/F as enabled  */
-		pcm_enable = 1;
+		tdmmc->pcm_enable = true;
 
 		tdmmc_mcdma_mcsc_start();
 
 		/* Clear TDM cause and mask registers */
-		writel(0, regs + COMM_UNIT_TOP_MASK_REG);
-		writel(0, regs + TDM_MASK_REG);
-		writel(0, regs + COMM_UNIT_TOP_CAUSE_REG);
-		writel(0, regs + TDM_CAUSE_REG);
+		writel(0, tdmmc->regs + COMM_UNIT_TOP_MASK_REG);
+		writel(0, tdmmc->regs + TDM_MASK_REG);
+		writel(0, tdmmc->regs + COMM_UNIT_TOP_CAUSE_REG);
+		writel(0, tdmmc->regs + TDM_CAUSE_REG);
 
 		/* Clear MCSC cause and mask registers(except InitDone bit) */
-		writel(0, regs + MCSC_GLOBAL_INT_MASK_REG);
-		writel(0, regs + MCSC_EXTENDED_INT_MASK_REG);
-		writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, regs + MCSC_GLOBAL_INT_CAUSE_REG);
-		writel(0, regs + MCSC_EXTENDED_INT_CAUSE_REG);
+		writel(0, tdmmc->regs + MCSC_GLOBAL_INT_MASK_REG);
+		writel(0, tdmmc->regs + MCSC_EXTENDED_INT_MASK_REG);
+		writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, tdmmc->regs + MCSC_GLOBAL_INT_CAUSE_REG);
+		writel(0, tdmmc->regs + MCSC_EXTENDED_INT_CAUSE_REG);
 
 		/* Enable unit interrupts */
-		mask_reg = readl(regs + TDM_MASK_REG);
-		writel(mask_reg | CONFIG_TDM_CAUSE, regs + TDM_MASK_REG);
-		writel(CONFIG_COMM_UNIT_TOP_MASK, regs + COMM_UNIT_TOP_MASK_REG);
+		mask_reg = readl(tdmmc->regs + TDM_MASK_REG);
+		writel(mask_reg | CONFIG_TDM_CAUSE, tdmmc->regs + TDM_MASK_REG);
+		writel(CONFIG_COMM_UNIT_TOP_MASK, tdmmc->regs + COMM_UNIT_TOP_MASK_REG);
 
 		/* Enable TDM */
-		if (ip_ver == TDMMC_REV1)
-			mv_phone_set_bit(regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
+		if (tdmmc->ip_ver == TDMMC_REV1)
+			mv_phone_set_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
 	}
 }
 
@@ -762,34 +766,35 @@ void tdmmc_pcm_stop(void)
 {
 	u32 buff_size, index;
 
-	if (pcm_enable) {
+	if (tdmmc->pcm_enable) {
 		/* Mark PCM I/F as disabled  */
-		pcm_enable = 0;
+		tdmmc->pcm_enable = false;
 
 		/* Clear TDM cause and mask registers */
-		writel(0, regs + COMM_UNIT_TOP_MASK_REG);
-		writel(0, regs + TDM_MASK_REG);
-		writel(0, regs + COMM_UNIT_TOP_CAUSE_REG);
-		writel(0, regs + TDM_CAUSE_REG);
+		writel(0, tdmmc->regs + COMM_UNIT_TOP_MASK_REG);
+		writel(0, tdmmc->regs + TDM_MASK_REG);
+		writel(0, tdmmc->regs + COMM_UNIT_TOP_CAUSE_REG);
+		writel(0, tdmmc->regs + TDM_CAUSE_REG);
 
 		/* Clear MCSC cause and mask registers(except InitDone bit) */
-		writel(0, regs + MCSC_GLOBAL_INT_MASK_REG);
-		writel(0, regs + MCSC_EXTENDED_INT_MASK_REG);
-		writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, regs + MCSC_GLOBAL_INT_CAUSE_REG);
-		writel(0, regs + MCSC_EXTENDED_INT_CAUSE_REG);
+		writel(0, tdmmc->regs + MCSC_GLOBAL_INT_MASK_REG);
+		writel(0, tdmmc->regs + MCSC_EXTENDED_INT_MASK_REG);
+		writel(MCSC_GLOBAL_INT_CAUSE_INIT_DONE_MASK, tdmmc->regs + MCSC_GLOBAL_INT_CAUSE_REG);
+		writel(0, tdmmc->regs + MCSC_EXTENDED_INT_CAUSE_REG);
 
 		tdmmc_mcdma_stop();
 
 		/* Calculate total Rx/Tx buffer size */
-		buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff * total_channels);
+		buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES *
+			     tdmmc->sampling_coeff * tdmmc->total_channels);
 
 		/* Clear Rx buffers */
 		for (index = 0; index < TOTAL_CHAINS; index++)
-			memset(rx_buff_virt[index], 0, buff_size);
+			memset(tdmmc->rx_buff_virt[index], 0, buff_size);
 
 		/* Disable TDM */
-		if (ip_ver == TDMMC_REV1)
-			mv_phone_reset_bit(regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
+		if (tdmmc->ip_ver == TDMMC_REV1)
+			mv_phone_reset_bit(tdmmc->regs + FLEX_TDM_CONFIG_REG, TDM_TEN_MASK);
 	}
 }
 
@@ -799,17 +804,18 @@ int tdmmc_tx(u8 *tdm_tx_buff)
 	u8 tmp;
 
 	/* Calculate total Tx buffer size */
-	buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff * total_channels);
+	buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES *
+		     tdmmc->sampling_coeff * tdmmc->total_channels);
 
-	if (ip_ver == TDMMC_REV0) {
-		if (sample_size > MV_PCM_FORMAT_1BYTE) {
-			dev_dbg(pdev, "Linear mode (Tx): swapping bytes\n");
+	if (tdmmc->ip_ver == TDMMC_REV0) {
+		if (tdmmc->sample_size > MV_PCM_FORMAT_1BYTE) {
+			dev_dbg(tdmmc->dev, "Linear mode (Tx): swapping bytes\n");
 			for (index = 0; index < buff_size; index += 2) {
 				tmp = tdm_tx_buff[index];
 				tdm_tx_buff[index] = tdm_tx_buff[index+1];
 				tdm_tx_buff[index+1] = tmp;
 			}
-			dev_dbg(pdev, "Linear mode (Tx): swapping bytes...done.\n");
+			dev_dbg(tdmmc->dev, "Linear mode (Tx): swapping bytes...done.\n");
 		}
 	}
 
@@ -822,17 +828,18 @@ int tdmmc_rx(u8 *tdm_rx_buff)
 	u8 tmp;
 
 	/* Calculate total Rx buffer size */
-	buff_size = (sample_size * MV_TDM_TOTAL_CH_SAMPLES * sampling_coeff * total_channels);
+	buff_size = (tdmmc->sample_size * MV_TDM_TOTAL_CH_SAMPLES *
+		     tdmmc->sampling_coeff * tdmmc->total_channels);
 
-	if (ip_ver == TDMMC_REV0) {
-		if (sample_size > MV_PCM_FORMAT_1BYTE) {
-			dev_dbg(pdev, "Linear mode (Rx): swapping bytes\n");
+	if (tdmmc->ip_ver == TDMMC_REV0) {
+		if (tdmmc->sample_size > MV_PCM_FORMAT_1BYTE) {
+			dev_dbg(tdmmc->dev, "Linear mode (Rx): swapping bytes\n");
 			for (index = 0; index < buff_size; index += 2) {
 				tmp = tdm_rx_buff[index];
 				tdm_rx_buff[index] = tdm_rx_buff[index+1];
 				tdm_rx_buff[index+1] = tmp;
 			}
-			dev_dbg(pdev, "Linear mode (Rx): swapping bytes...done.\n");
+			dev_dbg(tdmmc->dev, "Linear mode (Rx): swapping bytes...done.\n");
 		}
 	}
 
@@ -846,10 +853,10 @@ int tdmmc_intr_low(struct mv_phone_intr_info *tdm_intr_info)
 	u8 index;
 
 	/* Read TDM cause & mask registers */
-	cause_reg = readl(regs + TDM_CAUSE_REG);
-	mask_reg = readl(regs + TDM_MASK_REG);
+	cause_reg = readl(tdmmc->regs + TDM_CAUSE_REG);
+	mask_reg = readl(tdmmc->regs + TDM_MASK_REG);
 
-	dev_dbg(pdev, "%s: Cause register = 0x%x, Mask register = 0x%x\n",
+	dev_dbg(tdmmc->dev, "%s: Cause register = 0x%x, Mask register = 0x%x\n",
 		__func__, cause_reg, mask_reg);
 
 	/* Refer only to unmasked bits */
@@ -861,34 +868,34 @@ int tdmmc_intr_low(struct mv_phone_intr_info *tdm_intr_info)
 	tdm_intr_info->int_type = MV_EMPTY_INT;
 
 	/* Return in case TDM is disabled */
-	if (!tdm_enable) {
-		dev_dbg(pdev, "%s: TDM is disabled - quit low lever ISR\n", __func__);
-		writel(~int_ack_bits, regs + TDM_CAUSE_REG);
+	if (!tdmmc->tdm_enable) {
+		dev_dbg(tdmmc->dev, "%s: TDM is disabled - quit low lever ISR\n", __func__);
+		writel(~int_ack_bits, tdmmc->regs + TDM_CAUSE_REG);
 		return 0;
 	}
 
 	/* Handle TDM Error/s */
 	if (cause_and_mask & TDM_ERROR_INT) {
-		dev_err(pdev, "TDM Error: TDM_CAUSE_REG = 0x%x\n", cause_reg);
+		dev_err(tdmmc->dev, "TDM Error: TDM_CAUSE_REG = 0x%x\n", cause_reg);
 		int_ack_bits |= (int_ack_bits & TDM_ERROR_INT);
 	}
 
 	if (cause_and_mask & (TDM_TX_INT | TDM_RX_INT)) {
 		/* MCDMA current Tx desc. pointer is unreliable, thus, checking Rx desc. pointer only */
-		curr_desc = readl(regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(0));
-		dev_dbg(pdev, "%s: current descriptor = 0x%x\n", __func__, curr_desc);
+		curr_desc = readl(tdmmc->regs + MCDMA_CURRENT_RECEIVE_DESC_PTR_REG(0));
+		dev_dbg(tdmmc->dev, "%s: current descriptor = 0x%x\n", __func__, curr_desc);
 
 		/* Handle Tx */
 		if (cause_and_mask & TDM_TX_INT) {
 			for (index = 0; index < TOTAL_CHAINS; index++) {
-				if (curr_desc == mcdma_rx_desc_phys[index]) {
-					next_tx_buff = NEXT_BUFF(index);
+				if (curr_desc == tdmmc->rx_desc_phys[index]) {
+					tdmmc->next_tx = NEXT_BUFF(index);
 					break;
 				}
 			}
-			dev_dbg(pdev, "%s: TX interrupt (next_tx_buff = %d\n",
-				__func__, next_tx_buff);
-			tdm_intr_info->tdm_tx_buff = tx_buff_virt[next_tx_buff];
+			dev_dbg(tdmmc->dev, "%s: TX interrupt (next_tx_buff = %d\n",
+				__func__, tdmmc->next_tx);
+			tdm_intr_info->tdm_tx_buff = tdmmc->tx_buff_virt[tdmmc->next_tx];
 			tdm_intr_info->int_type |= MV_TX_INT;
 			int_ack_bits |= TDM_TX_INT;
 		}
@@ -896,21 +903,21 @@ int tdmmc_intr_low(struct mv_phone_intr_info *tdm_intr_info)
 		/* Handle Rx */
 		if (cause_and_mask & TDM_RX_INT) {
 			for (index = 0; index < TOTAL_CHAINS; index++) {
-				if (curr_desc == mcdma_rx_desc_phys[index]) {
-					prev_rx_buff = PREV_BUFF(index);
+				if (curr_desc == tdmmc->rx_desc_phys[index]) {
+					tdmmc->prev_rx = PREV_BUFF(index);
 					break;
 				}
 			}
-			dev_dbg(pdev, "%s: RX interrupt (prev_rx_buff = %d)\n",
-				__func__, prev_rx_buff);
-			tdm_intr_info->tdm_rx_buff = rx_buff_virt[prev_rx_buff];
+			dev_dbg(tdmmc->dev, "%s: RX interrupt (prev_rx_buff = %d)\n",
+				__func__, tdmmc->prev_rx);
+			tdm_intr_info->tdm_rx_buff = tdmmc->rx_buff_virt[tdmmc->prev_rx];
 			tdm_intr_info->int_type |= MV_RX_INT;
 			int_ack_bits |= TDM_RX_INT;
 		}
 	}
 
 	/* Clear TDM interrupts */
-	writel(~int_ack_bits, regs + TDM_CAUSE_REG);
+	writel(~int_ack_bits, tdmmc->regs + TDM_CAUSE_REG);
 
 	return 0;
 }
@@ -918,12 +925,12 @@ int tdmmc_intr_low(struct mv_phone_intr_info *tdm_intr_info)
 int tdmmc_reset_slic(void)
 {
 	/* Enable SLIC reset */
-	mv_phone_reset_bit(regs + TDM_CLK_AND_SYNC_CONTROL_REG, TDM_PROG_TDM_SLIC_RESET_MASK);
+	mv_phone_reset_bit(tdmmc->regs + TDM_CLK_AND_SYNC_CONTROL_REG, TDM_PROG_TDM_SLIC_RESET_MASK);
 
 	udelay(60);
 
 	/* Release SLIC reset */
-	mv_phone_set_bit(regs + TDM_CLK_AND_SYNC_CONTROL_REG, TDM_PROG_TDM_SLIC_RESET_MASK);
+	mv_phone_set_bit(tdmmc->regs + TDM_CLK_AND_SYNC_CONTROL_REG, TDM_PROG_TDM_SLIC_RESET_MASK);
 
 	return 0;
 }
diff --git a/drivers/telephony/mvebu_phone/tdmmc/tdmmc.h b/drivers/telephony/mvebu_phone/tdmmc/tdmmc.h
index 3360711..1916f85 100644
--- a/drivers/telephony/mvebu_phone/tdmmc/tdmmc.h
+++ b/drivers/telephony/mvebu_phone/tdmmc/tdmmc.h
@@ -390,6 +390,39 @@ struct tdmmc_dram_entry {
 	u32 reserved31_27:5;
 };
 
+/* Main TDM structure definition */
+struct tdmmc_dev {
+	/* Resources */
+	void __iomem *regs;
+	struct device *dev;
+
+	/* Silicon revision */
+	enum tdmmc_ip_version ip_ver;
+
+	/* Buffers */
+	u8 *rx_buff_virt[TOTAL_CHAINS];
+	u8 *tx_buff_virt[TOTAL_CHAINS];
+	dma_addr_t rx_buff_phys[TOTAL_CHAINS];
+	dma_addr_t tx_buff_phys[TOTAL_CHAINS];
+	u8 prev_rx;
+	u8 next_tx;
+
+	/* MCDMA descriptors */
+	struct tdmmc_mcdma_rx_desc *rx_desc_virt[TOTAL_CHAINS];
+	struct tdmmc_mcdma_tx_desc *tx_desc_virt[TOTAL_CHAINS];
+	dma_addr_t rx_desc_phys[TOTAL_CHAINS];
+	dma_addr_t tx_desc_phys[TOTAL_CHAINS];
+
+	/* Flags */
+	bool tdm_enable;
+	bool pcm_enable;
+
+	/* Parameters */
+	u8 sample_size;
+	u8 sampling_coeff;
+	u16 total_channels;
+};
+
 /* TDMMC APIs */
 void tdmmc_pcm_start(void);
 void tdmmc_pcm_stop(void);
-- 
1.7.9.5

