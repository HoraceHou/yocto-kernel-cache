From 560fb5a13aa4b23567a43a88e763d08d27220a0e Mon Sep 17 00:00:00 2001
From: Stefan Chulski <stefanc@marvell.com>
Date: Sun, 4 Dec 2016 19:20:57 +0200
Subject: [PATCH 0633/1345] fix: net: mvpp2x: fix TSO skb shadow ring overrun

commit  058776957b840a3087b6407db3300c06823d0d8a from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

- If TSO feature enabled, increase TXQ stop condition
  to 100 descriptors
- DMA unmap shadow external buffer
- Stop TXQ if not enough CPU aggregation_queue descriptors

Signed-off-by: Stefan Chulski <stefanc@marvell.com>

Change-Id: Icaf3414cfbf24c6c22edb1ca6e79b2bb3c741d77
Reviewed-on: http://vgitil04.il.marvell.com:8080/34329
Reviewed-by: Yuval Caduri <cyuval@marvell.com>
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Reviewed-by: Omri Itach <omrii@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h      |    4 ++
 drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c |   49 +++++++++++++++-----
 2 files changed, 41 insertions(+), 12 deletions(-)

diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
index 7092ece..20d7914 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x.h
@@ -36,6 +36,9 @@
 
 #define STATS_DELAY	250
 
+#define TSO_TXQ_LIMIT 100
+#define TXQ_LIMIT (MAX_SKB_FRAGS + 2)
+
 #define MV_ETH_SKB_SHINFO_SIZE	SKB_DATA_ALIGN(sizeof(struct skb_shared_info))
 
 /* START - Taken from mvPp2Commn.h, need to order TODO */
@@ -625,6 +628,7 @@ struct mv_pp2x_port {
 	struct mv_pp2x_bm_pool *pool_short; /* Pointer to the short pool_id */
 
 	struct phy *comphy; /* comphy handler */
+	int txq_stop_limit;
 
 	u32 num_qvector;
 	/* q_vector is the parameter that will be passed to
diff --git a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
index b66d7bf..913e0c6 100644
--- a/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2x/mv_pp2x_main.c
@@ -826,9 +826,8 @@ static inline void *mv_pp2_extra_pool_get(struct mv_pp2x_port *port)
 
 		ext_buf = ext_buf_struct->ext_buf_data;
 
-	} else {
+	} else
 		ext_buf = kmalloc(MVPP2_EXTRA_BUF_SIZE, GFP_ATOMIC);
-	}
 
 	return ext_buf;
 }
@@ -928,15 +927,15 @@ static void mv_pp2x_txq_bufs_free(struct mv_pp2x_port *port,
 
 		mv_pp2x_txq_inc_get(txq_pcpu);
 
+		dma_unmap_single(port->dev->dev.parent, buf_phys_addr,
+				 data_size, DMA_TO_DEVICE);
+
 		if (skb & MVPP2_ETH_SHADOW_EXT) {
 			skb &= ~MVPP2_ETH_SHADOW_EXT;
 			mv_pp2_extra_pool_put(port, (void *)skb);
 			continue;
 		}
 
-		dma_unmap_single(port->dev->dev.parent, buf_phys_addr,
-				 data_size, DMA_TO_DEVICE);
-
 		if (!skb)
 			continue;
 		if (skb & MVPP2_ETH_SHADOW_SKB) {
@@ -949,6 +948,8 @@ static void mv_pp2x_txq_bufs_free(struct mv_pp2x_port *port,
 static void mv_pp2x_txq_buf_free(struct mv_pp2x_port *port, uintptr_t skb,
 				 dma_addr_t  buf_phys_addr, int data_size)
 {
+	dma_unmap_single(port->dev->dev.parent, buf_phys_addr,
+			 data_size, DMA_TO_DEVICE);
 
 	if (skb & MVPP2_ETH_SHADOW_EXT) {
 		skb &= ~MVPP2_ETH_SHADOW_EXT;
@@ -956,9 +957,6 @@ static void mv_pp2x_txq_buf_free(struct mv_pp2x_port *port, uintptr_t skb,
 		return;
 	}
 
-	dma_unmap_single(port->dev->dev.parent, buf_phys_addr,
-			 data_size, DMA_TO_DEVICE);
-
 	if (!skb)
 		return;
 	if (skb & MVPP2_ETH_SHADOW_SKB) {
@@ -992,7 +990,7 @@ static void mv_pp2x_txq_done(struct mv_pp2x_port *port,
 	mv_pp2x_txq_bufs_free(port, txq_pcpu, tx_done);
 
 	if (netif_tx_queue_stopped(nq))
-		if (mv_pp2x_txq_free_count(txq_pcpu) >= (MAX_SKB_FRAGS + 2))
+		if (mv_pp2x_txq_free_count(txq_pcpu) >= port->txq_stop_limit)
 			netif_tx_wake_queue(nq);
 }
 
@@ -2677,7 +2675,7 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 			 struct mv_pp2x_aggr_tx_queue *aggr_txq, int cpu)
 {
 	int frag = 0, i;
-	int total_len, hdr_len, size, frag_size, data_left;
+	int total_len, hdr_len, size, frag_size, data_left, txq_id;
 	int total_desc_num, total_bytes = 0, max_desc_num = 0;
 	char *frag_ptr;
 	struct mv_pp2x_tx_desc *tx_desc;
@@ -2687,20 +2685,29 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 	u32 tcp_seq = 0;
 	skb_frag_t *skb_frag_ptr;
 	const struct tcphdr *th = tcp_hdr(skb);
+	struct netdev_queue *nq;
 
 	if (mv_pp2_tso_validate(skb, dev))
 		return 0;
 
+	txq_id = skb_get_queue_mapping(skb);
+	nq = netdev_get_tx_queue(dev, txq_id);
+
 	/* Calculate expected number of TX descriptors */
 	max_desc_num = skb_shinfo(skb)->gso_segs * 2 + skb_shinfo(skb)->nr_frags;
 
 	/* Check number of available descriptors */
 	if (mv_pp2x_aggr_desc_num_check(port->priv, aggr_txq, max_desc_num, cpu) ||
 	    mv_pp2x_txq_reserved_desc_num_proc(port->priv, txq,
-					     txq_pcpu, max_desc_num, cpu)) {
+						   txq_pcpu, max_desc_num, cpu)) {
+		netif_tx_stop_queue(nq);
 		return 0;
 	}
 
+	if (unlikely(max_desc_num > port->txq_stop_limit))
+		if (mv_pp2x_txq_free_count(txq_pcpu) < max_desc_num)
+			return 0;
+
 	total_len = skb->len;
 	hdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));
 
@@ -2806,6 +2813,11 @@ static inline int mv_pp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 			}
 		}
 	}
+
+	/* Prevent shadow_q override, stop tx_queue until tx_done is called*/
+	if (mv_pp2x_txq_free_count(txq_pcpu) < port->txq_stop_limit)
+		netif_tx_stop_queue(nq);
+
 	/* TCP segment is ready - transmit it */
 	mv_pp2x_aggr_txq_pend_desc_add(port, total_desc_num);
 
@@ -2949,7 +2961,7 @@ static int mv_pp2x_tx(struct sk_buff *skb, struct net_device *dev)
 
 	/* Prevent shadow_q override, stop tx_queue until tx_done is called*/
 
-	if (mv_pp2x_txq_free_count(txq_pcpu) < (MAX_SKB_FRAGS + 2))
+	if (mv_pp2x_txq_free_count(txq_pcpu) < port->txq_stop_limit)
 		netif_tx_stop_queue(nq);
 	/* Enable transmit */
 	if (!skb->xmit_more || netif_xmit_stopped(nq)) {
@@ -3933,6 +3945,13 @@ static int mv_pp2x_netdev_set_features(struct net_device *dev,
 		}
 	}
 
+	if (changed & NETIF_F_TSO) {
+		if (features & NETIF_F_TSO)
+			port->txq_stop_limit = TSO_TXQ_LIMIT;
+		else
+			port->txq_stop_limit = TXQ_LIMIT;
+	}
+
 	dev->features = features;
 
 	return 0;
@@ -4639,6 +4658,12 @@ static int mv_pp2x_port_probe(struct platform_device *pdev,
 	/* Only when multi queue mode, rxhash is supported */
 	if (mv_pp2x_queue_mode)
 		dev->hw_features |= NETIF_F_RXHASH;
+
+	if (dev->features & NETIF_F_TSO)
+		port->txq_stop_limit = TSO_TXQ_LIMIT;
+	else
+		port->txq_stop_limit = TXQ_LIMIT;
+
 	dev->vlan_features |= features;
 
 	dev->priv_flags |= IFF_UNICAST_FLT;
-- 
1.7.9.5

