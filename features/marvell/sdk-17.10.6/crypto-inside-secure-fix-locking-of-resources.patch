From a01a71209e6915dc47854f393547671a630c8d1c Mon Sep 17 00:00:00 2001
From: Ofer Heifetz <oferh@marvell.com>
Date: Wed, 25 Oct 2017 04:48:05 +0300
Subject: [PATCH 1263/1345] crypto: inside-secure: fix locking of resources

commit  50139f06f36e74f9064f9105b591c259845b1558 from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

The egress_lock should be used for egress_count updates,
egress ring list and for egress_count use when updating
the EIP197_HIA_xDR_THRESH register to keep HW and SW in sync.

Change-Id: Ia35a3a81e0b2d2817e8ffac4ae5b27bdd727a4c7
Signed-off-by: Ofer Heifetz <oferh@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/45573
Reviewed-by: Hanna Hawa <hannah@marvell.com>
Tested-by: Hanna Hawa <hannah@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/51644
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/crypto/inside-secure/cipher.c   |    3 +++
 drivers/crypto/inside-secure/hash.c     |    3 +++
 drivers/crypto/inside-secure/safexcel.c |   31 ++++++++++++-------------------
 3 files changed, 18 insertions(+), 19 deletions(-)

diff --git a/drivers/crypto/inside-secure/cipher.c b/drivers/crypto/inside-secure/cipher.c
index 9767e78..8735b8d 100644
--- a/drivers/crypto/inside-secure/cipher.c
+++ b/drivers/crypto/inside-secure/cipher.c
@@ -270,6 +270,9 @@ static int safexcel_aes_send(struct crypto_async_request *async,
 	request->req = &req->base;
 	list_add_tail(&request->list, &priv->ring[ring].list);
 
+	/* update the ring request count */
+	priv->ring[ring].egress_cnt++;
+
 	spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 	*commands = n_cdesc;
diff --git a/drivers/crypto/inside-secure/hash.c b/drivers/crypto/inside-secure/hash.c
index da0db44..f4e6753 100644
--- a/drivers/crypto/inside-secure/hash.c
+++ b/drivers/crypto/inside-secure/hash.c
@@ -278,6 +278,9 @@ static int safexcel_ahash_send_req(struct crypto_async_request *async, int ring,
 
 	list_add_tail(&request->list, &priv->ring[ring].list);
 
+	/* update the ring request count */
+	priv->ring[ring].egress_cnt++;
+
 	spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 	req->len += areq->nbytes;
diff --git a/drivers/crypto/inside-secure/safexcel.c b/drivers/crypto/inside-secure/safexcel.c
index 6718d82..0157889e 100644
--- a/drivers/crypto/inside-secure/safexcel.c
+++ b/drivers/crypto/inside-secure/safexcel.c
@@ -731,10 +731,7 @@ void safexcel_dequeue(struct safexcel_crypto_priv *priv, int ring)
 	priv->ring[ring].backlog = backlog;
 
 finalize:
-	spin_lock_bh(&priv->ring[ring].lock);
-
-	/* update the ring request count */
-	priv->ring[ring].egress_cnt += nreq;
+	spin_lock_bh(&priv->ring[ring].egress_lock);
 
 	if (!priv->ring[ring].busy && priv->ring[ring].egress_cnt) {
 		/* Configure when we want an interrupt */
@@ -746,7 +743,7 @@ void safexcel_dequeue(struct safexcel_crypto_priv *priv, int ring)
 		writel(val, EIP197_HIA_AIC_xDR(priv) + EIP197_HIA_RDR(ring) + EIP197_HIA_xDR_THRESH);
 	}
 
-	spin_unlock_bh(&priv->ring[ring].lock);
+	spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 	if (nreq) {
 		/* let the RDR know we have pending descriptors */
@@ -871,6 +868,9 @@ int safexcel_invalidate_cache(struct crypto_async_request *async,
 	request->req = async;
 	list_add_tail(&request->list, &priv->ring[ring].list);
 
+	/* update the ring request count */
+	priv->ring[ring].egress_cnt++;
+
 	spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 	return 0;
@@ -889,7 +889,7 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 {
 	struct safexcel_request *sreq;
 	struct safexcel_context *ctx;
-	int ret, i, ndesc, ndesc_tot, nreq_cnt, nreq_tot;
+	int ret, i, ndesc, ndesc_tot, nreq_cnt;
 	u32 val, results;
 	bool should_complete;
 	int egress_cnt;
@@ -899,13 +899,13 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 	results = (results >> EIP197_xDR_PROC_xD_PKT_OFFSET) & EIP197_xDR_PROC_xD_PKT_MASK;
 
 	nreq_cnt = 0;
-	nreq_tot = 0;
 	ndesc_tot = 0;
 
 	for (i = 0; i < results; i++) {
 		spin_lock_bh(&priv->ring[ring].egress_lock);
 		sreq = list_first_entry(&priv->ring[ring].list, struct safexcel_request, list);
 		list_del(&sreq->list);
+		priv->ring[ring].egress_cnt--;
 		spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 		ctx = crypto_tfm_ctx(sreq->req->tfm);
@@ -936,20 +936,13 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 
 		writel(val, EIP197_HIA_AIC_xDR(priv) + EIP197_HIA_RDR(ring) +
 		       EIP197_HIA_xDR_PROC_COUNT);
-
-		nreq_tot += nreq_cnt;
 	}
 
-	spin_lock_bh(&priv->ring[ring].lock);
-
-	/* update the ring request count */
-	priv->ring[ring].egress_cnt -= nreq_tot;
-
 	/* more results ready in the ring? */
-	if (results == EIP197_xDR_PROC_xD_PKT_MASK) {
-		spin_unlock_bh(&priv->ring[ring].lock);
+	if (results == EIP197_xDR_PROC_xD_PKT_MASK)
 		goto more_results;
-	}
+
+	spin_lock_bh(&priv->ring[ring].egress_lock);
 
 	/* get the pending request count */
 	egress_cnt = min(priv->ring[ring].egress_cnt, EIP197_MAX_BATCH_SZ);
@@ -957,7 +950,7 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 	if (!egress_cnt) {
 		/* no more request in ring */
 		priv->ring[ring].busy = 0;
-		spin_unlock_bh(&priv->ring[ring].lock);
+		spin_unlock_bh(&priv->ring[ring].egress_lock);
 
 		return;
 	}
@@ -969,7 +962,7 @@ static void safexcel_handle_result_descriptor(struct safexcel_crypto_priv *priv,
 	writel(val, EIP197_HIA_AIC_xDR(priv) + EIP197_HIA_RDR(ring) +
 	       EIP197_HIA_xDR_THRESH);
 
-	spin_unlock_bh(&priv->ring[ring].lock);
+	spin_unlock_bh(&priv->ring[ring].egress_lock);
 }
 
 /* dequeue from Crypto API FIFO and insert requests into HW ring */
-- 
1.7.9.5

