From 7378b9c94a43906a7706c01edc38eb60abb78f26 Mon Sep 17 00:00:00 2001
From: Ofer Heifetz <oferh@marvell.com>
Date: Sun, 14 Jan 2018 10:30:27 +0200
Subject: [PATCH 1286/1345] crypto: inside-secure - avoid unmapping DMA memory
 that was not mapped

commit  b08287e91b3cbe064ebb9fb6dd63864a3de0d0d4 from
https://github.com/MarvellEmbeddedProcessors/linux-marvell.git

This patch adds a parameter in the SafeXcel ahash request structure to
keep track of the number of SG entries mapped. This allows not to call
dma_unmap_sg() when dma_map_sg() wasn't called in the first place. This
also removes a warning when the debugging of the DMA-API is enabled in
the kernel configuration: "DMA-API: device driver tries to free DMA
memory it has not allocated".

Fixes: 1b44c5a ("crypto: inside-secure - add SafeXcel EIP197 crypto engine driver")
Change-Id: I6df6f3fd954bf336575d21e4eee5efa53163889f
Signed-off-by: Antoine Tenart <antoine.tenart@free-electrons.com>
Signed-off-by: Ofer Heifetz <oferh@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/48931
Tested-by: iSoC Platform CI <ykjenk@marvell.com>
Reviewed-by: Hanna Hawa <hannah@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/51667
Tested-by: Hanna Hawa <hannah@marvell.com>
Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/crypto/inside-secure/hash.c |   24 ++++++++++++++----------
 1 file changed, 14 insertions(+), 10 deletions(-)

diff --git a/drivers/crypto/inside-secure/hash.c b/drivers/crypto/inside-secure/hash.c
index 0872a04..2d6737c 100644
--- a/drivers/crypto/inside-secure/hash.c
+++ b/drivers/crypto/inside-secure/hash.c
@@ -31,6 +31,8 @@ struct safexcel_ahash_req {
 	bool hmac;
 	bool needs_inv;
 
+	int nents;
+
 	u8 state_sz;	/* expected sate size, only set once */
 	u32 state[SHA256_DIGEST_SIZE / sizeof(u32)] __aligned(sizeof(u32));
 
@@ -170,8 +172,10 @@ static int safexcel_handle_req_result(struct safexcel_crypto_priv *priv, int rin
 		memcpy(areq->result, sreq->state,
 		       crypto_ahash_digestsize(ahash));
 
-	dma_unmap_sg(priv->dev, areq->src,
-		     sg_nents_for_len(areq->src, areq->nbytes), DMA_TO_DEVICE);
+	if (sreq->nents) {
+		dma_unmap_sg(priv->dev, areq->src, sreq->nents, DMA_TO_DEVICE);
+		sreq->nents = 0;
+	}
 
 	safexcel_free_context(priv, async, sreq->state_sz);
 
@@ -197,7 +201,7 @@ static int safexcel_ahash_send_req(struct crypto_async_request *async, int ring,
 	struct safexcel_command_desc *cdesc, *first_cdesc = NULL;
 	struct safexcel_result_desc *rdesc;
 	struct scatterlist *sg;
-	int i, nents, queued, len, cache_len, extra, n_cdesc = 0, ret = 0;
+	int i, queued, len, cache_len, extra, n_cdesc = 0, ret = 0;
 
 	queued = len = req->len - req->processed;
 	if (queued < crypto_ahash_blocksize(ahash))
@@ -267,13 +271,15 @@ static int safexcel_ahash_send_req(struct crypto_async_request *async, int ring,
 	}
 
 	/* Now handle the current ahash request buffer(s) */
-	nents = sg_nents_for_len(areq->src, areq->nbytes);
-	if (dma_map_sg(priv->dev, areq->src, nents, DMA_TO_DEVICE) <= 0) {
+	req->nents = dma_map_sg(priv->dev, areq->src,
+				sg_nents_for_len(areq->src, areq->nbytes),
+				DMA_TO_DEVICE);
+	if (!req->nents) {
 		ret = -ENOMEM;
 		goto cdesc_rollback;
 	}
 
-	for_each_sg(areq->src, sg, nents, i) {
+	for_each_sg(areq->src, sg, req->nents, i) {
 		int sglen = sg_dma_len(sg);
 
 		/* Do not overflow the request */
@@ -340,10 +346,8 @@ static int safexcel_ahash_send_req(struct crypto_async_request *async, int ring,
 	return 0;
 
 cdesc_rollback:
-	if (nents)
-		dma_unmap_sg(priv->dev, areq->src,
-			     sg_nents_for_len(areq->src, areq->nbytes),
-			     DMA_TO_DEVICE);
+	if (req->nents)
+		dma_unmap_sg(priv->dev, areq->src, req->nents, DMA_TO_DEVICE);
 
 	for (i = 0; i < n_cdesc; i++)
 		safexcel_ring_rollback_wptr(priv, &priv->ring[ring].cdr);
-- 
1.7.9.5

